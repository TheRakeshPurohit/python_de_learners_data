{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da96542-afea-4433-acef-9bc5bf476d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "040d4434-127b-48c8-8866-c378ffd4a1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466590bb-ad19-45c7-83e7-f12fd55b33ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ac0867-3b24-411a-afab-8631bcc6b546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA Graphics Device'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0d9dffe-1e9c-4343-a021-f7366f9d471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Sat Jul 15 21:31:42 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA Graphics...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   39C    P8    10W / 200W |    275MiB / 12282MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1026      G   /usr/lib/xorg/Xorg                173MiB |\n",
      "|    0   N/A  N/A      1593      G   xfwm4                               3MiB |\n",
      "|    0   N/A  N/A      3160      G   ...272016569601147694,262144       94MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5af38b8-5eed-4b3f-8cbe-ebde2bd33e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb4b9c4-24a8-4b94-9651-48478638bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4486d0cb-194c-419a-a988-d577bc706e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.randn(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "456141d8-7416-4a69-bf2a-7f0c4d14bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.randn(1,2).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ab6007-4120-44d7-9fac-29d7ac77d957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0540, 0.5244]])\n"
     ]
    }
   ],
   "source": [
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a9ec992-de0f-489d-9b76-92f31afdf8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8685, -0.1440]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85046698-178f-4b4e-ba1b-1e14f95badd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2080dd41-36b8-4f86-bf73-f0856fdd5b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f135a7b1-7381-41cb-99ee-ee7367809f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamal/jupyter_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab765b5b-f7d7-40ef-a585-448146ab8eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998477697372437}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"This is one of the best systems in this universe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cabd9e-d95a-446c-bb97-69b85981ead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamal/jupyter_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "model_id = \"facebook/opt-350m\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d743b3e4-39cd-4723-a145-6899712e2e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862916c2-759d-4e36-bdc0-92f998483625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248f4f31-8bf3-40d3-b3b7-8d901f59056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Lets do this guys\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be342ba-deb1-41b9-8c8f-addf5612cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_text = tokenizer(text=text,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ccbc892-3555-4a54-bb42-e2fbfd1be976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   2,  574, 2580,  109,   42, 1669]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb96b09-510d-41ea-a011-f27cf66180db",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = model.generate(encode_text['input_ids'],max_new_tokens = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6351940-cd9b-45ae-b63e-ad260b912feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,   574,  2580,   109,    42,  1669,     4, 50118,   100,   437,\n",
       "           159,     4,    38,   581,    28,    15,    11,    10,   367,   722,\n",
       "             4,     2]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6895153-b0f7-4f31-8a93-065a54ad96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_text = tokenizer.batch_decode(generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e190d4e3-fc48-417b-b01b-a8914e649211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"</s>Lets do this guys.\\nI'm down. I'll be on in a few hours.</s>\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29037d1f-6756-4fb8-aa6f-fab8bc336d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed9e4a5b-8ee9-4d87-8857-638676b83f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2a76963-20cb-489b-8554-5f755450c9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using mask_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa96544d-f613-4898-a7fe-f86fb0a5b994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequence = \"This is a nice way of learning Transformers\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f1162a7-079c-4aa8-8947-72938edd2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(\n",
    "    sequence,\n",
    "    padding='max_length',\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "decoder_input = tokenizer(\n",
    "    sequence,\n",
    "    padding='max_length',\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7db18de-6f0c-42b3-8a54-cd376dc7968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = model.generate(input_ids=encoded_input[\"input_ids\"], \n",
    "                                decoder_input_ids=decoder_input[\"input_ids\"],max_length=613)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5db9a45f-39c9-4b2f-a521-d89dc1379bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.decode(\n",
    "    encoder_output[0],\n",
    "    skip_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71b576dd-a3b4-43c4-903e-73f6495697cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a nice way of learning Transformers This is a nice way to learn Transformers: The Transformers: The Movie is a great way to learn the history of the Transformers.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
