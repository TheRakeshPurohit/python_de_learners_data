{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da96542-afea-4433-acef-9bc5bf476d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0bfb5b5-6828-4d61-9898-d462c5a1b164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.31.0.dev0\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /home/kamal/jupyter_env/lib/python3.11/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: peft\n"
     ]
    }
   ],
   "source": [
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25cabd9e-d95a-446c-bb97-69b85981ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"EleutherAI/gpt-neo-1.3B\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d743b3e4-39cd-4723-a145-6899712e2e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "131d47ae-dc57-41e9-9364-e91eda69b7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Mon Jul 17 11:30:43 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA Graphics...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   40C    P8     9W / 200W |   6075MiB / 12282MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       936      G   /usr/lib/xorg/Xorg                200MiB |\n",
      "|    0   N/A  N/A      1706      G   xfwm4                               3MiB |\n",
      "|    0   N/A  N/A      4646      G   ...481282142750804741,262144      120MiB |\n",
      "|    0   N/A  N/A      5440      C   ...al/jupyter_env/bin/python     1132MiB |\n",
      "|    0   N/A  N/A      6723      C   ...al/jupyter_env/bin/python     3612MiB |\n",
      "|    0   N/A  N/A     63529      C   ...al/jupyter_env/bin/python     1002MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "862916c2-759d-4e36-bdc0-92f998483625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id,resume_download=True,\n",
    "                                            torch_dtype=torch.bfloat16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "248f4f31-8bf3-40d3-b3b7-8d901f59056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Lets do this guys\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be342ba-deb1-41b9-8c8f-addf5612cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_text = tokenizer(text=text,return_tensors='pt').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ccbc892-3555-4a54-bb42-e2fbfd1be976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  43, 1039,  466,  428, 3730]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcb96b09-510d-41ea-a011-f27cf66180db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generate_text = model.generate(encode_text['input_ids'],max_new_tokens = 500,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6351940-cd9b-45ae-b63e-ad260b912feb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   43,  1039,   466,   428,  3730,    13,   198,   198,    40,  1101,\n",
       "           407,  1654,   611,   428,   318,   262,   826,  1295,   284,  1281,\n",
       "           428,    11,   475,   314,  1101,   257,   649,  2888,   994,   290,\n",
       "           314,  1101,  2111,   284,   651,   617,  1037,    13,   314,  1101,\n",
       "          2111,   284,   651,   616,  2832,   319,   257,  4866,   286,   262,\n",
       "           983,   290,   314,  1101,  1719,   257,  1327,   640,  4917,   340,\n",
       "            13,   314,  1053,   587, 10342,   329,   340,   329,   257,   981,\n",
       "           783,   290,   314,   460,   470,  1283,   284,  1064,   340,    13,\n",
       "           314,  1053,   587,  2045,   329,   340,   319,   262,  5230,   290,\n",
       "           314,  1053,   587,  2045,   319,   262,   983,   338,  3052,    13,\n",
       "           314,  1053,   587,  2045,   329,   340,   319,   262,   983,   338,\n",
       "          3052,   290,   314,  1053,   587,  2045,   319,   262,   983,   338,\n",
       "          3052,    13,   314,  1053,   587,  2045,   329,   340,   319,   262,\n",
       "           983,   338,  3052,   290,   314,  1053,   587,  2045,   319,   262,\n",
       "           983,   338,  3052,    13,   314,  1053,   587,  2045,   329,   340,\n",
       "           319,   262,   983,   338,  3052,   290,   314,  1053,   587,  2045,\n",
       "           319,   262,   983,   338,  3052,    13,   314,  1053,   587,  2045,\n",
       "           329,   340,   319,   262,   983,   338,  3052,   290,   314,  1053,\n",
       "           587,  2045,   319,   262,   983,   338,  3052,    13,   314,  1053,\n",
       "           587,  2045,   329,   340,   319,   262,   983,   338,  3052,   290,\n",
       "           314,  1053,   587,  2045,   319,   262,   983,   338,  3052,    13,\n",
       "           314,  1053,   587,  2045,   329,   340,   319,   262,   983,   338,\n",
       "          3052,   290,   314,  1053,   587,  2045,   319,   262,   983,   338,\n",
       "          3052,    13,   314,  1053,   587,  2045,   329,   340,   319,   262,\n",
       "           983,   338,  3052,   290,   314,  1053,   587,  2045,   319,   262,\n",
       "           983,   338,  3052,    13,   314,  1053,   587,  2045,   329,   340,\n",
       "           319,   262,   983,   338,  3052,   290,   314,  1053,   587,  2045,\n",
       "           319,   262,   983,   338,  3052,    13,   314,  1053,   587,  2045,\n",
       "           329,   340,   319,   262,   983,   338,  3052,   290,   314,  1053,\n",
       "           587,  2045,   319,   262,   983,   338,  3052,    13,   314,  1053,\n",
       "           587,  2045,   329,   340,   319,   262,   983,   338,  3052,   290,\n",
       "           314,  1053,   587,  2045,   319,   262,   983,   338,  3052,    13,\n",
       "           314,  1053,   587,  2045,   329,   340,   319,   262,   983,   338,\n",
       "          3052,   290,   314,  1053,   587,  2045,   319,   262,   983,   338,\n",
       "          3052,    13,   314,  1053,   587,  2045,   329,   340,   319,   262,\n",
       "           983,   338,  3052,   290,   314,  1053,   587,  2045,   319,   262,\n",
       "           983,   338,  3052,    13,   314,  1053,   587,  2045,   329,   340,\n",
       "           319,   262,   983,   338,  3052,   290,   314,  1053,   587,  2045,\n",
       "           319,   262,   983,   338,  3052,    13,   314,  1053,   587,  2045,\n",
       "           329,   340,   319,   262,   983,   338,  3052,   290,   314,  1053,\n",
       "           587,  2045,   319,   262,   983,   338,  3052,    13,   314,  1053,\n",
       "           587,  2045,   329,   340,   319,   262,   983,   338,  3052,   290,\n",
       "           314,  1053,   587,  2045,   319,   262,   983,   338,  3052,    13,\n",
       "           314,  1053,   587,  2045,   329,   340,   319,   262,   983,   338,\n",
       "          3052,   290,   314,  1053,   587,  2045,   319,   262,   983,   338,\n",
       "          3052,    13,   314,  1053,   587,  2045,   329,   340,   319,   262,\n",
       "           983,   338,  3052,   290,   314,  1053,   587,  2045,   319,   262,\n",
       "           983,   338,  3052,    13,   314,  1053,   587,  2045,   329,   340,\n",
       "           319,   262,   983,   338,  3052,   290,   314,  1053,   587,  2045,\n",
       "           319,   262,   983,   338,  3052,    13,   314,  1053,   587,  2045,\n",
       "           329,   340,   319,   262,   983]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6895153-b0f7-4f31-8a93-065a54ad96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_text = tokenizer.batch_decode(generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e190d4e3-fc48-417b-b01b-a8914e649211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Lets do this guys.\\n\\nI'm not sure if this is the right place to post this, but I'm a new member here and I'm trying to get some help. I'm trying to get my hands on a copy of the game and I'm having a hard time finding it. I've been searching for it for a while now and I can't seem to find it. I've been looking for it on the internet and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game's website and I've been looking on the game's website. I've been looking for it on the game\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e8c343-d936-42c6-8bff-d9fc1ad34883",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29037d1f-6756-4fb8-aa6f-fab8bc336d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed9e4a5b-8ee9-4d87-8857-638676b83f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2a76963-20cb-489b-8554-5f755450c9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using mask_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa96544d-f613-4898-a7fe-f86fb0a5b994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequence = \"This is a nice way of learning Transformers\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f1162a7-079c-4aa8-8947-72938edd2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(\n",
    "    sequence,\n",
    "    padding='max_length',\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "decoder_input = tokenizer(\n",
    "    sequence,\n",
    "    padding='max_length',\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7db18de-6f0c-42b3-8a54-cd376dc7968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = model.generate(input_ids=encoded_input[\"input_ids\"], \n",
    "                                decoder_input_ids=decoder_input[\"input_ids\"],max_length=613)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5db9a45f-39c9-4b2f-a521-d89dc1379bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.decode(\n",
    "    encoder_output[0],\n",
    "    skip_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71b576dd-a3b4-43c4-903e-73f6495697cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a nice way of learning Transformers This is a nice way to learn Transformers: The Transformers: The Movie is a great way to learn the history of the Transformers.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
