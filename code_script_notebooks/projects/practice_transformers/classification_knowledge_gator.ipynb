{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "868effff-eb4f-4257-9acf-b7f894973b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4a317ea-62cd-4897-b1b6-6ec96578b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"roberta-large\"\n",
    "model_path = \"microsoft/deberta-v3-small\"\n",
    "data_path = \"knowledgator/events_classification_biotech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0600f375-4049-461b-aeae-d24372d3c44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamal/jupyter_env/lib/python3.11/site-packages/datasets/load.py:1454: FutureWarning: The repository for knowledgator/events_classification_biotech contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/knowledgator/events_classification_biotech\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "events_class = load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8df55fff-f6cf-4e0a-ac29-1fa97351c1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content', 'target organization', 'all_labels', 'all_labels_concat', 'label 1', 'label 2', 'label 3', 'label 4', 'label 5'],\n",
       "        num_rows: 2759\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'content', 'target organization', 'all_labels', 'all_labels_concat', 'label 1', 'label 2', 'label 3', 'label 4', 'label 5'],\n",
       "        num_rows: 381\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "999fbe81-5600-4021-a6e9-eb245784f719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': \"Sarah Polley's Book Recommendations\",\n",
       " 'content': 'Drive Your Plow Over the Bones of The Dead\\nby Olga Tokarczuk. I am an incredibly slow reader, but the tone and specificity of the world she creates in this book was something I couldnt leave behind until it was done. Also: All We Sawby Anne Michaels, Fight Nightby Miriam Toews, and The Summer Before the Darkby Doris Lessing.\\nId like turned into a Netflix show:\\nby Amia Srinivasan. One of the most brain-shattering books Ive ever read. Her thinking is so electrically rigorous and fearless. (I double DARE them to make this into a Netflix show!)\\n...I last bought:\\n. I rediscovered her poetry lately, and I feel like I dont want to read anything else for a while. She owns desire and submerged things.\\n...has the greatest ending:\\nby J.D. Salinger. The last page always leaves me breathless. The intimacy and truth of that final page is so arresting and almost painful to read.\\nshould be on every college syllabus:\\nby Anton Piatigorsky. A fascinating fictional account of the adolescence of dictators. It is painstakingly researched and so imaginative. He takes on whole histories through a small, specific, human lens.\\n...Ive re-read the most:\\nGilead\\nby Marilynne Robinson. It reminds me of the wild depths of kindness humans are capable of. It helps me get to sleep when Im agitated. It is so incredibly gentle, complex, wise and hopeful. It gives me a glimpse into what faith can feel like.\\n...that holds the recipe to a favorite dish:\\nMarcella Hazans tomato butter onion sauce from Essentials of Classic Italian Cooking I discovered it when I was 17. No matter how much I cook, Ive never found anything that matches the pure magic of what these three simple ingredients do together.\\nBonus question: If I could live in any library or bookstore in the world, it would be:',\n",
       " 'target organization': \"Franny's Farmacy\",\n",
       " 'all_labels': ['other'],\n",
       " 'all_labels_concat': 'other',\n",
       " 'label 1': 24,\n",
       " 'label 2': None,\n",
       " 'label 3': None,\n",
       " 'label 4': None,\n",
       " 'label 5': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_class['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53da8d8f-76a8-43be-bee1-d4cf252ef9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 16, 18, 22, 27, 3, None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([event['label 5'] for event in events_class['train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e403644e-1507-44c5-8eba-9815dc785280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event organization',\n",
       " 'executive statement',\n",
       " 'regulatory approval',\n",
       " 'hiring',\n",
       " 'foundation',\n",
       " 'closing',\n",
       " 'partnerships & alliances',\n",
       " 'expanding industry',\n",
       " 'new initiatives or programs',\n",
       " 'm&a',\n",
       " 'service & product providing',\n",
       " 'event organisation',\n",
       " 'new initiatives & programs',\n",
       " 'subsidiary establishment',\n",
       " 'product launching & presentation',\n",
       " 'product updates',\n",
       " 'executive appointment',\n",
       " 'alliance & partnership',\n",
       " 'ipo exit',\n",
       " 'article publication',\n",
       " 'clinical trial sponsorship',\n",
       " 'company description',\n",
       " 'investment in public company',\n",
       " 'other',\n",
       " 'expanding geography',\n",
       " 'participation in an event',\n",
       " 'support & philanthropy',\n",
       " 'department establishment',\n",
       " 'funding round',\n",
       " 'patent publication']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [class_ for class_ in events_class['train'].features['label 1'].names if class_]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ccae75f-c8be-4dc5-94ae-906d878857ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2id = {class_:id for id, class_ in enumerate(classes)}\n",
    "id2class = {id:class_ for class_, id in class2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbef1fa5-fdee-4b33-bcb8-30a49ce97e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamal/jupyter_env/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aca89031-2c51-4d9c-8daf-d2f49de607d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2Config {\n",
       "  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-07,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"max_relative_positions\": -1,\n",
       "  \"model_type\": \"deberta-v2\",\n",
       "  \"norm_rel_ebd\": \"layer_norm\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_dropout\": 0,\n",
       "  \"pooler_hidden_act\": \"gelu\",\n",
       "  \"pooler_hidden_size\": 768,\n",
       "  \"pos_att_type\": [\n",
       "    \"p2c\",\n",
       "    \"c2p\"\n",
       "  ],\n",
       "  \"position_biased_input\": false,\n",
       "  \"position_buckets\": 256,\n",
       "  \"relative_attention\": true,\n",
       "  \"share_att_key\": true,\n",
       "  \"transformers_version\": \"4.37.2\",\n",
       "  \"type_vocab_size\": 0,\n",
       "  \"vocab_size\": 128100\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "model_config = AutoConfig.from_pretrained(model_path)\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e413d89-c908-4e89-8300-381e1333db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(row):\n",
    "    text = f\"\"\"{row['title']}.\n",
    "            {row['content']}\"\"\"\n",
    "    all_labels = row['all_labels_concat'].split(', ')\n",
    "    labels = [0. for i in range(len(classes))]\n",
    "    for label in all_labels:\n",
    "        label_id = class2id[label]\n",
    "        labels[label_id] = 1  # this is similar to 1-hot encoding\n",
    "    row_tokened = tokenizer(text, truncation=True, max_length=512)\n",
    "    row_tokened['labels'] = labels\n",
    "    return row_tokened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a87767f-c81d-485b-8e61-b6da48d19e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848899d80a294994bb59af8f785959ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2759 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c1e2a007cd44109b5647f26daf3dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/381 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "events_processed = events_class.map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "899f7c75-3025-4292-aecd-e82a1c995377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4657cf7-e2b0-4a57-9b17-15340599f86c",
   "metadata": {},
   "source": [
    "Implementing metrics during training is super helpful for monitoring model performance over time. It can help avoid over-fitting and build a more general model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff814ee0-1292-45d1-a701-c1bc92bebbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def sigmoid(x):\n",
    "   return 1/(1 + np.exp(-x))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "   predictions, labels = eval_pred\n",
    "   predictions = sigmoid(predictions)\n",
    "   predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "   return clf_metrics.compute(predictions=predictions,\n",
    "                              references=labels.astype(int).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5a4a6ec-64f7-48e1-8559-e1e8d429331d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamal/jupyter_env/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path, num_labels=len(classes),\n",
    "    id2label=id2class, label2id=class2id,\n",
    "    problem_type = \"multi_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57675fc7-5fb7-4d60-8971-1c01013527d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "targs = TrainingArguments(\n",
    "    output_dir=\"~/training_files/multi_class\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd6998ab-a07c-4cbd-96a4-dab6194c936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=targs,\n",
    "    eval_dataset=events_processed['test'],\n",
    "    train_dataset=events_processed['train'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e3c350c-636a-4b0d-9338-428560be643b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [920/920 02:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.148101</td>\n",
       "      <td>0.949081</td>\n",
       "      <td>0.338636</td>\n",
       "      <td>0.665179</td>\n",
       "      <td>0.227134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.139258</td>\n",
       "      <td>0.950831</td>\n",
       "      <td>0.386463</td>\n",
       "      <td>0.680769</td>\n",
       "      <td>0.269817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=920, training_loss=0.15845647480176842, metrics={'train_runtime': 166.6283, 'train_samples_per_second': 33.116, 'train_steps_per_second': 5.521, 'total_flos': 730412675431560.0, 'train_loss': 0.15845647480176842, 'epoch': 2.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8da25dbd-b906-4c42-b9f9-d0d4b6355ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = \"/home/kamal/training_files/multi_class/checkpoint-920\"\n",
    "trained_model = AutoModelForSequenceClassification.from_pretrained(trained_model_path,\n",
    "                                                                  num_labels=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bca23e63-8af3-4536-af1a-2b41b1e63529",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_content = \"\"\"The UK says it will provide thousands of \"first-person view\" drones, which give operators the situational awareness to target positions, armoured vehicles, and ships.\n",
    "That type of UAV has proven highly effective on the battlefield since Russia's full-scale invasion of its neighbour two years ago, Britain's defence ministry said.\n",
    "\"The UK continues to do all we can to give Ukraine what it needs,\" Defence Secretary Grant Shapps said in a statement, ahead of meeting NATO counterparts in Brussels on Thursday.\n",
    "Referring to the joint project with Latvia, he added: \"Together, we will give Ukraine the capabilities it needs to defend itself and win this war.\"\n",
    "At Thursday's NATO ministerial meeting, Britain, its 13 allies, and prospective member Sweden, will sign an agreement on two new procurement initiatives for munitions and missiles, London said.\n",
    "Spearheaded by the UK, they aim to increase defence industrial capacity across the Euro-Atlantic area and replenish stockpiles significantly depleted by the war in Ukraine.\n",
    "Other members involved in the procurement plans include France, Germany and Turkey, said defence ministry statement.\n",
    "Britain is also working with alliance members Canada, Denmark, the Netherlands and the United States to deliver air-defence equipment to Ukraine, the ministry added.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a706c70d-e31c-4003-8952-4184b429b7d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     1,    279,   1222,    652,    278,    296,    531,   2113,    265,\n",
       "            307,   9150,    271,   8148,    866,    309,  13909,    261,    319,\n",
       "            527,   6100,    262,  39427,   3250,    264,   1782,   3129,    261,\n",
       "          47605,   2500,    261,    263,   5512,    260,    512,    810,    265,\n",
       "          52305,    303,   3813,   1344,   1287,    277,    262,  17572,    515,\n",
       "           2425,    280,    268,    540,    271,   5609,   9631,    265,    359,\n",
       "          17704,    375,    388,    824,    261,   3491,    280,    268,   6506,\n",
       "           4969,    357,    260,    307,    635,   1222,   2240,    264,    333,\n",
       "            305,    301,    295,    264,    527,   7116,    339,    278,    634,\n",
       "            261,    309,  11972,   3777,   6020,  12239,  40837,    357,    267,\n",
       "            266,   1548,    261,   1645,    265,   1122,  10915,  11912,    267,\n",
       "          10908,    277,   1561,    260,  30783,    264,    262,   3199,    663,\n",
       "            275,  24984,    261,    313,    859,    294,    307,  62072,    261,\n",
       "            301,    296,    527,   7116,    262,   4070,    278,    634,    264,\n",
       "           5595,   1161,    263,   1079,    291,   1442,    260,    309,    620,\n",
       "           1561,    280,    268,  10915,  36527,   1122,    261,   3491,    261,\n",
       "            359,    989,   8098,    261,    263,   7636,   1034,   6903,    261,\n",
       "            296,   1425,    299,   2101,    277,    375,    353,  12311,   5221,\n",
       "            270,  49895,    263,  13926,    261,   1336,    357,    260, 112775,\n",
       "            569,    293,    262,   1222,    261,    306,   3140,    264,    993,\n",
       "           6506,   2746,   2130,    679,    262,   7303,    271,  29884,    537,\n",
       "            263,  33478,  70324,   2806,  25385,    293,    262,   1442,    267,\n",
       "           7116,    260,   1865,    742,   1190,    267,    262,  12311,   1254,\n",
       "            680,   2378,    261,   2439,    263,   4803,    261,    357,   6506,\n",
       "           4969,   1548,    260,   3491,    269,    327,    560,    275,   9981,\n",
       "            742,   1558,    261,  10070,    261,    262,   7060,    263,    262,\n",
       "            780,   1017,    264,   2074,    925,    271,  60273,   1324,    264,\n",
       "           7116,    261,    262,   4969,    859,    260,      2]],\n",
       "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokened_content = tokenizer(test_content, truncation=True, padding=True,\n",
    "                           max_length=512, return_tensors='pt').to('cuda')\n",
    "tokened_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e1c4961-3119-416e-ae29-4fd20a741861",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=30, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2bd23d8-0ef8-403f-98c1-fe11381e0dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = trained_model(**tokened_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "375c9fbc-8673-49db-ad53-9a20eaaf7d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = output.logits.to('cpu').detach().numpy()\n",
    "predictions = sigmoid(preds)\n",
    "predictions = (predictions > 0.5).astype(int).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f9cc342-be41-436f-ba5f-a1ed5d2e4d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'executive statement'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[predictions.argmax()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
