{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pqUlynFMRs5F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qqq accelerate transformers sentence_transformers huggingface_hub langchain==0.0.166 pygpt4all==1.1.0 chromadb==0.3.22 llama-cpp-python==0.1.48 urllib3==1.26.6 pdfminer.six==20221105 > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wFDXLyIbgvL1",
    "outputId": "d57d826d-1f8e-48b1-8e4d-7ea877c4a965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-15 11:30:21--  https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin\n",
      "Resolving gpt4all.io (gpt4all.io)... 104.26.1.159, 104.26.0.159, 172.67.71.169, ...\n",
      "Connecting to gpt4all.io (gpt4all.io)|104.26.1.159|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3785248281 (3.5G)\n",
      "Saving to: ‘ggml-gpt4all-j-v1.3-groovy.bin.1’\n",
      "\n",
      "ggml-gpt4all-j-v1.3 100%[===================>]   3.52G  63.4MB/s    in 78s     \n",
      "\n",
      "2023-05-15 11:31:39 (46.2 MB/s) - ‘ggml-gpt4all-j-v1.3-groovy.bin.1’ saved [3785248281/3785248281]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "X0KCmkl_gU9B"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import GPT4All, LlamaCpp\n",
    "import os\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a7h1UDGciIsE"
   },
   "outputs": [],
   "source": [
    " callbacks = [StreamingStdOutCallbackHandler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "deMs01A4hFvW"
   },
   "outputs": [],
   "source": [
    " llm = GPT4All(model=\"/content/ggml-gpt4all-j-v1.3-groovy.bin\", \n",
    "               n_ctx=1000, \n",
    "               backend='gptj', \n",
    "               callbacks=callbacks, \n",
    "               verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "Kb5lXsByhFrh",
    "outputId": "419a329f-3ba6-4370-d58e-1c1f45961031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "The United States of America."
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'?\\nThe United States of America.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Who landed on the moon on July 21 1969\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7WB1GwVDopM-"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate,  LLMChain\n",
    "\n",
    "template = \"\"\"Use text below and answer the question: {question}\n",
    "{text}\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate(template=template, \n",
    "                        input_variables=[\"question\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6yJ_3UUMosXn"
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "H3CK_O2yk_Ja"
   },
   "outputs": [],
   "source": [
    "question = \"What is electroencephalography?\"\n",
    "text = \"\"\"Electroencephalography (EEG) is a method to record an electrogram of the spontaneous electrical activity of the brain. The biosignals detected by EEG have been shown to represent the postsynaptic potentials of pyramidal neurons in the neocortex and allocortex.[1] It is typically non-invasive, with the EEG electrodes placed along the scalp (commonly called \"scalp EEG\") using the International 10-20 system, or variations of it. Electrocorticography, involving surgical placement of \n",
    "electrodes, is sometimes called \"intracranial EEG\". Clinical interpretation of\n",
    " EEG recordings is most often performed by visual inspection of the\n",
    "  tracing or quantitative EEG analysis.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KE4_tw_b1wJD"
   },
   "outputs": [],
   "source": [
    "print(llm_chain.run(question=question,text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9pJsqla0oWo0"
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ClvIfJGZOjtp"
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\", metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\",\"source\":\"local\"}),\n",
    "    Document(page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\", metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2,\"source\":\"local\"}),\n",
    "    Document(page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\", metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6,\"source\":\"local\"}),\n",
    "    Document(page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\", metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3,\"source\":\"local\"}),\n",
    "    Document(page_content=\"Toys come alive and have a blast doing so\", metadata={\"year\": 1995, \"genre\": \"animated\",\"source\":\"local\"}),\n",
    "    Document(page_content=\"Three men walk into the Zone, three men walk out of the Zone\", metadata={\"year\": 1979, \"rating\": 9.9, \"director\": \"Andrei Tarkovsky\", \"genre\": \"science fiction\", \"rating\": 9.9,\"source\":\"local\"})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wgv5zItqOjow"
   },
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    docs, embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqDgdS3_QWcz",
    "outputId": "69485149-3ccd-4353-c680-877dc46011e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose', metadata={'year': 1993, 'rating': 7.7, 'genre': 'science fiction', 'source': 'local'}),\n",
       " Document(page_content='Toys come alive and have a blast doing so', metadata={'year': 1995, 'genre': 'animated', 'source': 'local'}),\n",
       " Document(page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea', metadata={'year': 2006, 'director': 'Satoshi Kon', 'rating': 8.6, 'source': 'local'}),\n",
       " Document(page_content='Leo DiCaprio gets lost in a dream within a dream within a dream within a ...', metadata={'year': 2010, 'director': 'Christopher Nolan', 'rating': 8.2, 'source': 'local'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(\"Movie on dinosaur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2KZcRV-mTHL9"
   },
   "outputs": [],
   "source": [
    "#from langchain.chains import RetrievalQAWithSourcesChain\n",
    "#chain = RetrievalQAWithSourcesChain.from_chain_type(llm, \n",
    " #                                                   chain_type=\"stuff\", \n",
    "  #                                                  retriever=vectorstore.as_retriever())\n",
    "#chain({\"question\": \"What movie did dinosaur escape\"}, \n",
    " #     return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "x9lxcBQSPtAf"
   },
   "outputs": [],
   "source": [
    "def get_text(question):\n",
    "  similar_data = vectorstore.similarity_search(question)\n",
    "  text = ''\n",
    "  for elem in similar_data:\n",
    "    text = text + elem.page_content\n",
    "  print(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aI9dqgpxTo6I"
   },
   "outputs": [],
   "source": [
    "def retrieve_answer(question):\n",
    "  support_text = get_text(question)\n",
    "  answer = llm_chain.run(question=question, \n",
    "                         text= support_text)\n",
    "  return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91d4_jXoOuGl",
    "outputId": "6db9e6e4-e169-4b8b-8c9d-66030ca7b911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A bunch of scientists bring back dinosaurs and mayhem breaks looseToys come alive and have a blast doing soThree men walk into the Zone, three men walk out of the ZoneA bunch of normal-sized women are supremely wholesome and some men pine after them\n",
      " Who brought"
     ]
    }
   ],
   "source": [
    "retrieve_answer(\"Who brought the dinosaurs back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWEkunjcTGaC"
   },
   "outputs": [],
   "source": [
    "retrieve_answer(\"Dream within Dream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjYL-0hkjAma"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_huggingface_tool\n",
    "\n",
    "tool = load_huggingface_tool(\"lysandre/hf-model-downloads\")\n",
    "\n",
    "print(f\"{tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "RzP7vg_CjAqj",
    "outputId": "f47c4b4c-5d46-457e-fce3-d4e35b2758e0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'gpt2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGhxsX7_jAuv"
   },
   "outputs": [],
   "source": [
    "tool_tg = load_huggingface_tool(\"huggingface-tools/text-download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOAvpYsrjAzS"
   },
   "outputs": [],
   "source": [
    "tool_tg(\"https://python.langchain.com/en/latest/modules/models/llms/integrations/huggingface_pipelines.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5STWcOwqrZx"
   },
   "outputs": [],
   "source": [
    "tool_classify = load_huggingface_tool(\"Sj8287/Sentiment_Classification\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
