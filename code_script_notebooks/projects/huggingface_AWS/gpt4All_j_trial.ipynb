{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq langchain==0.0.166 pygpt4all==1.1.0 chromadb==0.3.22 llama-cpp-python==0.1.48 urllib3==1.26.6 pdfminer.six==20221105"
      ],
      "metadata": {
        "id": "pqUlynFMRs5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin"
      ],
      "metadata": {
        "id": "wFDXLyIbgvL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/Pi3141/alpaca-native-7B-ggml/resolve/397e872bf4c83f4c642317a5bf65ce84a105786e/ggml-model-q4_0.bin"
      ],
      "metadata": {
        "id": "IUGXTfcEgvBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.embeddings import LlamaCppEmbeddings\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.llms import GPT4All, LlamaCpp\n",
        "import os"
      ],
      "metadata": {
        "id": "X0KCmkl_gU9B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " callbacks = [StreamingStdOutCallbackHandler()]"
      ],
      "metadata": {
        "id": "a7h1UDGciIsE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " llm = GPT4All(model=\"/content/ggml-gpt4all-j-v1.3-groovy.bin\", \n",
        "               n_ctx=512, \n",
        "               backend='gptj', \n",
        "               callbacks=callbacks, \n",
        "               verbose=False)"
      ],
      "metadata": {
        "id": "deMs01A4hFvW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"When did man land on moon?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb5lXsByhFrh",
        "outputId": "cbc42dcb-aed7-4d44-a2e2-0f2ca86aebcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The first landing on the moon"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BhJSFYo0hFlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IjYL-0hkjAma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RzP7vg_CjAqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OGhxsX7_jAuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOAvpYsrjAzS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}