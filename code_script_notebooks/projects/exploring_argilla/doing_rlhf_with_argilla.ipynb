{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\argenv\\Lib\\site-packages\\argilla\\client\\client.py:167: UserWarning: Default user was detected and no workspace configuration was provided, so the default 'argilla' workspace will be used. If you want to setup another workspace, use the `rg.set_workspace` function or provide a different one on `rg.init`\n",
      "  warnings.warn(\n",
      "d:\\argenv\\Lib\\site-packages\\argilla\\client\\client.py:195: UserWarning: You're connecting to Argilla Server 1.26.1 using a different client version (1.23.1).\n",
      "This may lead to potential compatibility issues during your experience.\n",
      "To ensure a seamless and optimized connection, we highly recommend aligning your client version with the server version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argilla as rg \n",
    "localuser = \"argilla\"\n",
    "password = \"1234\"\n",
    "apikey = \"argilla.apikey\"\n",
    "url = \"http://aicontroller:6900/\"\n",
    "\n",
    "rg.init(api_key=apikey,\n",
    "        api_url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "localgilla = \"localgilla\"\n",
    "rg.set_workspace(localgilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataset as a framework\n",
    "\n",
    "dataset_fw = rg.FeedbackDataset(\n",
    "    guidelines=\"Please read the prompt carefully\",\n",
    "    questions=[\n",
    "        rg.TextQuestion(\n",
    "            name=\"prompt\",\n",
    "            title=\"Please write a harmless reply\",\n",
    "            required=True,\n",
    "        )\n",
    "    ],\n",
    "    fields=[\n",
    "        rg.TextField(name=\"prompt\", required=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are following ways to collect the datasets \n",
    "\n",
    "# The steps here can include: \n",
    "# (1) finding an open dataset that might contain prompts related to your use \n",
    "# case\n",
    "# (2) performing** exploratory data** analysis and topic extraction** to understand\n",
    "#  the data\n",
    "# (3) filtering and selecting prompts based on topic, quality,\n",
    "# text descriptiveness, etc.\n",
    "# (4) Asking humans to write prompts for your usecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be populated from the list of writing topics you create\n",
    "fields = [\n",
    "    rg.TextField(name=\"writing-topic\", required=True)\n",
    "]\n",
    "\n",
    "# we will ask the labeler to write a possible prompt or instruction\n",
    "question = rg.TextQuestion(\n",
    "\tname=\"prompt\",\n",
    "\ttitle=\"Imagine and write a possible instruction for the given topic:\",\n",
    "\trequired=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\argenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "prompts = load_dataset(\"HuggingFaceH4/mt_bench_prompts\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [\n",
    "    rg.FeedbackRecord(fields={\"prompt\": rek['prompt'][0]}) for rek in prompts\n",
    "]\n",
    "records\n",
    "dataset_fw.add_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\argenv\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d:\\argenv\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/30/24 16:53:30] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:argilla.client.feedback.dataset.local.mixins:✓ Dataset succesfully  <a href=\"file://d:\\argenv\\Lib\\site-packages\\argilla\\client\\feedback\\dataset\\local\\mixins.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">mixins.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\argenv\\Lib\\site-packages\\argilla\\client\\feedback\\dataset\\local\\mixins.py#281\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">281</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         pushed to Argilla                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/30/24 16:53:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:argilla.client.feedback.dataset.local.mixins:✓ Dataset succesfully  \u001b]8;id=634227;file://d:\\argenv\\Lib\\site-packages\\argilla\\client\\feedback\\dataset\\local\\mixins.py\u001b\\\u001b[2mmixins.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=559924;file://d:\\argenv\\Lib\\site-packages\\argilla\\client\\feedback\\dataset\\local\\mixins.py#281\u001b\\\u001b[2m281\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         pushed to Argilla                                                        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:argilla.client.feedback.dataset.local.mixins:<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RemoteFeedbackDataset</span><span style=\"font-weight: bold\">(</span> <a href=\"file://d:\\argenv\\Lib\\site-packages\\argilla\\client\\feedback\\dataset\\local\\mixins.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">mixins.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\argenv\\Lib\\site-packages\\argilla\\client\\feedback\\dataset\\local\\mixins.py#282\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">282</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #ffff00; text-decoration-color: #ffff00\">480681ab</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-0a8b-48dc-ac20-65672ddb0973</span>                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">rlhf_demo</span>                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            <span style=\"color: #808000; text-decoration-color: #808000\">workspace</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Workspace</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #ffff00; text-decoration-color: #ffff00\">d56c5067</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-b7d6-46ac-a5e1-759124e3542e</span>,          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">localgilla</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inserted_at</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:11:30</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">153391</span>,                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #808000; text-decoration-color: #808000\">updated_at</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:11:30</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">153391</span><span style=\"font-weight: bold\">)</span>                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://aicontroller:6900/dataset/480681ab-0a8b-48dc-ac20-65672ddb</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">0973/annotation-mode</span>                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            <span style=\"color: #808000; text-decoration-color: #808000\">fields</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RemoteTextField</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UUID</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'5a2e15e7-32c5-42a8-bcfe-016d9fcd61a5</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">client</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'prompt'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Prompt'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">required</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">use_markdown</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)]</span>                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            <span style=\"color: #808000; text-decoration-color: #808000\">questions</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RemoteTextQuestion</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UUID</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'dd696635-556f-4314-9c91-374273</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">6cc6d4'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">client</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'prompt'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write a harmless </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">reply'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">description</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">required</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #808000; text-decoration-color: #808000\">use_markdown</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)]</span>                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            <span style=\"color: #808000; text-decoration-color: #808000\">guidelines</span>=<span style=\"color: #800080; text-decoration-color: #800080\">Please</span> read the prompt carefully                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            <span style=\"color: #808000; text-decoration-color: #808000\">metadata_properties</span>=<span style=\"font-weight: bold\">[]</span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            <span style=\"color: #808000; text-decoration-color: #808000\">vectors_settings</span>=<span style=\"font-weight: bold\">[]</span>                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">)</span>                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:argilla.client.feedback.dataset.local.mixins:\u001b[1;35mRemoteFeedbackDataset\u001b[0m\u001b[1m(\u001b[0m \u001b]8;id=53050;file://d:\\argenv\\Lib\\site-packages\\argilla\\client\\feedback\\dataset\\local\\mixins.py\u001b\\\u001b[2mmixins.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=409010;file://d:\\argenv\\Lib\\site-packages\\argilla\\client\\feedback\\dataset\\local\\mixins.py#282\u001b\\\u001b[2m282\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m            \u001b[33mid\u001b[0m=\u001b[93m480681ab\u001b[0m\u001b[93m-0a8b-48dc-ac20-65672ddb0973\u001b[0m                               \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            \u001b[33mname\u001b[0m=\u001b[35mrlhf_demo\u001b[0m                                                        \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            \u001b[33mworkspace\u001b[0m=\u001b[1;35mWorkspace\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[93md56c5067\u001b[0m\u001b[93m-b7d6-46ac-a5e1-759124e3542e\u001b[0m,          \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[33mname\u001b[0m=\u001b[35mlocalgilla\u001b[0m, \u001b[33minserted_at\u001b[0m=\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m11:11:30\u001b[0m.\u001b[1;36m153391\u001b[0m,                 \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[33mupdated_at\u001b[0m=\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m11:11:30\u001b[0m.\u001b[1;36m153391\u001b[0m\u001b[1m)\u001b[0m                                   \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            \u001b[33murl\u001b[0m=\u001b[4;94mhttp\u001b[0m\u001b[4;94m://aicontroller:6900/dataset/480681ab-0a8b-48dc-ac20-65672ddb\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94m0973/annotation-mode\u001b[0m                                                     \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            \u001b[33mfields\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mRemoteTextField\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[1;35mUUID\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'5a2e15e7-32c5-42a8-bcfe-016d9fcd61a5\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mclient\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mname\u001b[0m=\u001b[32m'prompt'\u001b[0m, \u001b[33mtitle\u001b[0m=\u001b[32m'Prompt'\u001b[0m, \u001b[33mrequired\u001b[0m=\u001b[3;92mTrue\u001b[0m,           \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m, \u001b[33muse_markdown\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m                                        \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            \u001b[33mquestions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mRemoteTextQuestion\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[1;35mUUID\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'dd696635-556f-4314-9c91-374273\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m6cc6d4'\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mclient\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mname\u001b[0m=\u001b[32m'prompt'\u001b[0m, \u001b[33mtitle\u001b[0m=\u001b[32m'Please write a harmless \u001b[0m    \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mreply'\u001b[0m, \u001b[33mdescription\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrequired\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m,                    \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[33muse_markdown\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m                                                     \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            \u001b[33mguidelines\u001b[0m=\u001b[35mPlease\u001b[0m read the prompt carefully                           \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            \u001b[33mmetadata_properties\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m                                                \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            \u001b[33mvectors_settings\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m                                                   \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m)\u001b[0m                                                                        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This publishes the dataset with its records to Argilla and returns the dataset in Argilla\n",
    "remote_dataset = dataset_fw.push_to_argilla(name=\"rlhf_demo\", workspace=localgilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we distribute the workload in one dataset with several labelers\n",
    "feedback_five = rg.FeedbackDataset.from_argilla(\n",
    "\tname=\"rlhf_demo\",\n",
    "\tworkspace=localgilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_five.filter_by(response_status=\"submitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the datasets to rank the responses\n",
    "\n",
    "questions = [\n",
    "    rg.RankingQuestion(\n",
    "        name=\"response_ranking\",\n",
    "        title=\"order the responses based on their accuracy & helpfulness\",\n",
    "        required=True,\n",
    "        values={\"res1\":\"Nice\", \"res2\": \"Okay\"}\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = [\n",
    "    rg.RatingQuestion(\n",
    "        name=\"rate_resp\",\n",
    "        title=\"Select accurate response between (2) and (3). If same then select (1).\",\n",
    "        required=True,\n",
    "        values=[1, 2, 3]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_collect_ds = rg.FeedbackDataset(\n",
    "    guidelines=\"Please read prompt, its response below and provide feedback\",\n",
    "    questions=question,\n",
    "    fields=[\n",
    "        rg.TextField(name=\"prompt1\", required=True),\n",
    "        rg.TextField(name=\"response1\", required=True),\n",
    "        rg.TextField(name=\"response2\", required=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a pipeline for text generation\n",
    "gen_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "records = []\n",
    "for record in prompts:\n",
    "    prompt = record[\"prompt\"]\n",
    "\n",
    "    # Generate two responses in one call\n",
    "    outputs = gen_pipeline(\n",
    "        prompt,\n",
    "        max_length=100,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=2,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    responses = [output[\"generated_text\"] for output in outputs]\n",
    "\n",
    "    record = rg.FeedbackRecord(fields={\"prompt\": prompt, \"response 1\": responses[0], \"response 2\": responses[1]})\n",
    "    records.append(record)\n",
    "\n",
    "# Add records to the dataset\n",
    "response_collect_ds.add_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_rem_ds = response_collect_ds.push_to_argilla(name=\"response_collect\", workspace=\"argilla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_ds = rg.FeedbackDataset.from_argilla(\n",
    "        name=\"response_collect\",\n",
    "        workspace=\"argilla\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty list to store the triplets\n",
    "triplets = []\n",
    "\n",
    "# Loop over all records in the dataset\n",
    "for record in feedback_ds.records:\n",
    "    # Ensure that the record has responses\n",
    "    if record.responses is None or len(record.responses) == 0:\n",
    "        continue\n",
    "\n",
    "    # Ensure the response has been submitted (not discarded)\n",
    "    response = record.responses[0]\n",
    "\n",
    "    if response.status == 'submitted':\n",
    "        # Get the ranking value from the response for the preferred and least preferred\n",
    "        # responses, assuming there are no ties\n",
    "        preferred_rank = response.values[\"response_ranking\"].value[0][\"value\"]\n",
    "        least_preferred_rank = response.values[\"response_ranking\"].value[1][\"value\"]\n",
    "\n",
    "        # Construct the triplet and append to the list\n",
    "        triplets.append({\n",
    "            \"prompt\": record.fields[\"prompt\"],\n",
    "            \"preferred_response\": record.fields[preferred_rank],\n",
    "            \"least_preferred_response\": record.fields[least_preferred_rank],\n",
    "        })\n",
    "\n",
    "# Now, \"triplets\" is a list of dictionaries, each containing a prompt and the associated\n",
    "# preferred and less preferred responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
