{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "localuser = \"argilla\"\n",
    "password = \"1234\"\n",
    "apikey = \"argilla.apikey\"\n",
    "url = \"http://aicontroller:6900/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfuser = \"owner\"\n",
    "password = \"12345678\"\n",
    "apikey = \"owner.apikey\"\n",
    "# Kamaljp/yttutorialserver\n",
    "url = \"https://kamaljp-yttutorialserver.hf.space/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\argenv\\Lib\\site-packages\\argilla\\client\\client.py:167: UserWarning: Default user was detected and no workspace configuration was provided, so the default 'argilla' workspace will be used. If you want to setup another workspace, use the `rg.set_workspace` function or provide a different one on `rg.init`\n",
      "  warnings.warn(\n",
      "d:\\argenv\\Lib\\site-packages\\argilla\\client\\client.py:195: UserWarning: You're connecting to Argilla Server 1.26.1 using a different client version (1.23.1).\n",
      "This may lead to potential compatibility issues during your experience.\n",
      "To ensure a seamless and optimized connection, we highly recommend aligning your client version with the server version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argilla as rg\n",
    "# get the docs here https://.hf.space/api/docs\n",
    "# need to signin as owner with 12345678 to proceed the following.\n",
    "# https://docs.argilla.io/en/latest/getting_started/installation/configurations/user_management.html\n",
    "rg.init(\n",
    "    api_url=url,\n",
    "    api_key=apikey\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace(id=5ed06c89-dbe5-47a8-a9d0-5b59872481a6, name=localgilla, inserted_at=2024-04-02 07:18:14.945504, updated_at=2024-04-02 07:18:14.945504)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.Workspace.create(\"localgilla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = rg.User.create(\n",
    "    username=\"new-user\",\n",
    "    first_name=\"New\",\n",
    "    last_name=\"User\",\n",
    "    password=\"12345678\",\n",
    "    role=\"annotator\",\n",
    "    workspaces=[\"localgilla\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rg.FeedbackDataset.for_text_classification(\n",
    "    labels=[\"sadness\", \"joy\"],\n",
    "    multi_label=False,\n",
    "    use_markdown=True,\n",
    "    guidelines=None,\n",
    "    metadata_properties=None,\n",
    "    vectors_settings=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedbackDataset(\n",
       "   fields=[TextField(name='text', title='Text', required=True, type='text', use_markdown=True)]\n",
       "   questions=[LabelQuestion(name='label', title='Label', description='Classify the text by selecting the correct label from the given list of labels.', required=True, type='label_selection', labels=['sadness', 'joy'], visible_labels=None)]\n",
       "   guidelines=This is a text classification dataset that contains texts and labels. Given a set of texts and a predefined set of labels, the goal of text classification is to assign one label to each text based on its content. Please classify the texts by making the correct selection.)\n",
       "   metadata_properties=[])\n",
       "   vectors_settings=[])\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "localgilla = \"localgilla\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_argilla(name=\"ds-1\", workspace=localgilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = rg.FeedbackDataset.from_argilla(name='ds-1', workspace=localgilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [\n",
    "    rg.FeedbackRecord(\n",
    "        fields={\n",
    "            \"text\": \"I am so happy today\",\n",
    "        },\n",
    "    ),\n",
    "    rg.FeedbackRecord(\n",
    "        fields={\n",
    "            \"text\": \"I feel sad today\",\n",
    "        },\n",
    "    )\n",
    "]\n",
    "dataset.add_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeedbackRecord(fields={'text': 'I am so happy today'}, metadata={}, vectors={}, responses=[], suggestions=(), external_id=None),\n",
       " FeedbackRecord(fields={'text': 'I feel sad today'}, metadata={}, vectors={}, responses=[], suggestions=(), external_id=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds1.add_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hf = rg.FeedbackDataset.from_huggingface(\"argilla/emotion\", split=\"train[1:101]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hf.push_to_argilla(name=\"emogilla\", workspace=localgilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.feedback import TrainingTask\n",
    "\n",
    "task = TrainingTask.for_text_classification(\n",
    "    text=dataset_hf.field_by_name('text'),\n",
    "    label=dataset_hf.question_by_name(\"label\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.feedback import ArgillaTrainer\n",
    "\n",
    "trainer = ArgillaTrainer(\n",
    "    dataset=dataset_hf,\n",
    "    task=task,\n",
    "    framework=\"transformers\",\n",
    "    train_size=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.get_trainer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.get_trainer_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.get_model_kwargs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(output_dir=\"train_arg_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uploading Data\n",
    "\n",
    "# Three types of Record, depending on the tasks support TextClassificationRecord, \n",
    "# TokenClassificationRecord and Text2TextRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rg.FeedbackDataset.for_text_classification(\n",
    "    labels=[\"good\", \"bad\"],\n",
    "    multi_label=False,\n",
    "    use_markdown=True,\n",
    "    guidelines=None,\n",
    "    metadata_properties=None,\n",
    "    vectors_settings=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical attrs for the record are text, annotation, prediction and metadata\n",
    "\n",
    "textcat_rec = rg.TextClassificationRecord(\n",
    "    text='Hello there. Its me',\n",
    "    prediction=[(\"LABEL1\", 0.8), (\"LABEL2\", 0.2)],\n",
    "    annotation='LABEL1',\n",
    "    multi_label=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokencat_rec = rg.TokenClassificationRecord(\n",
    "    text='Argilla is a super awesome library that speeds up annotation',\n",
    "    tokens=[\"Argilla\", \"is\", \"a\", \"super\", \"awesome\", \"library\", \"that\", \"speeds\",\n",
    "            \"up\", \"annotation\"],\n",
    "    prediction=[(\"Name\", 0, 7), (\"ADJ\", 19, 26)],  # look at the indices, it matters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2text = rg.Text2TextRecord(\n",
    "    text='Argilla is a super awesome library that speeds up annotation',\n",
    "    prediction=[\"More we use it faster we understand it\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.set_workspace(localgilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.log(textcat_rec, 'my_cat_ds')\n",
    "rg.log(text2text, 'my_t2t_ds')\n",
    "rg.log(tokencat_rec, 'my_tokenclass_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"imdb\", split='train').shuffle(seed=42).select(range(100))\n",
    "ds.rename_column(\"label\", \"annotation\")\n",
    "df_rg = rg.read_datasets(ds,task=\"TextClassification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_in_arg = rg.log(df_rg, \"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_in_arg.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"pos\", \"neg\"]\n",
    "settings = rg.TextClassificationSettings(label_schema=labels)\n",
    "rg.configure_dataset_settings(name=\"imdb\", settings=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenclassification task\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "tokenDs = load_dataset(\"ag_news\", split=\"train\").shuffle(70).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_dict(row):\n",
    "    metadata = {}\n",
    "    metadata['label'] = row[\"label\"]\n",
    "    row[\"metadata\"] = metadata\n",
    "    return row\n",
    "\n",
    "dataset = tokenDs.map(metadata_dict, remove_columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(row):\n",
    "    tokens = [token.text for token in nlp(row[\"text\"])]\n",
    "    return {\"tokens\": tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenDs = tokenDs.map(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_rg = rg.read_datasets(tokenDs, task=\"TokenClassification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.log(token_rg, 'ag_news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"PER\", \"LOC\", \"ORG\", \"MISC\"]\n",
    "\n",
    "settings = rg.TokenClassificationSettings(label_schema=labels)\n",
    "rg.configure_dataset_settings(name=\"ag_news\", settings=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2tds = load_dataset(\"europa_ecdc_tm\", \"en2fr\", split=\"train\").shuffle(25).select(range(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(row):\n",
    "    return {\"text\": row[\"translation\"][\"en\"],\n",
    "            \"prediction\": row[\"translation\"][\"fr\"]}\n",
    "\n",
    "t2tds = t2tds.map(extract, remove_columns=['translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2trg = rg.read_datasets(t2tds, task=\"Text2Text\")\n",
    "rg.log(t2trg, \"ecdc_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "# need to provide the reconrds\n",
    "dataset = rg.FeedbackDataset(\n",
    "    guidelines=\"Add some guidelines for the annotation team here.\",\n",
    "    fields=[\n",
    "        rg.TextField(name=\"prompt\", title=\"Human prompt\"),\n",
    "        rg.TextField(name=\"output\", title=\"Generated output\", use_markdown=True)\n",
    "    ],\n",
    "    questions =[\n",
    "        rg.RatingQuestion(\n",
    "            name=\"rating\",\n",
    "            title=\"Rate the quality of the response:\",\n",
    "            description=\"1 = very bad - 5= very good\",\n",
    "            required=True,\n",
    "            values=[1,2,3,4,5]\n",
    "        ),\n",
    "        rg.TextQuestion(\n",
    "            name=\"corrected-text\",\n",
    "            title=\"Provide a correction to the response:\",\n",
    "            required=False,\n",
    "            use_markdown=True\n",
    "        ),\n",
    "        rg.LabelQuestion(\n",
    "            name=\"relevant\",\n",
    "            title=\"Is the response relevant for the given prompt?\",\n",
    "            labels={\"YES\": \"Yes\", \"NO\": \"No\"}, # or [\"YES\",\"NO\"]\n",
    "            required=True,\n",
    "            visible_labels=None\n",
    "        ),\n",
    "        rg.MultiLabelQuestion(\n",
    "            name=\"content_class\",\n",
    "            title=\"Does the response include any of the following?\",\n",
    "            description=\"Select all that apply\",\n",
    "            labels={\"hate\": \"Hate Speech\" , \"sexual\": \"Sexual content\", \"violent\": \"Violent content\", \"pii\": \"Personal information\", \"untruthful\": \"Untruthful info\", \"not_english\": \"Not English\", \"inappropriate\": \"Inappropriate content\"}, # or [\"hate\", \"sexual\", \"violent\", \"pii\", \"untruthful\", \"not_english\", \"inappropriate\"]\n",
    "            required=False,\n",
    "            visible_labels=4\n",
    "        ),\n",
    "        rg.RankingQuestion(\n",
    "            name=\"preference\",\n",
    "            title=\"Order replies based on your preference\",\n",
    "            description=\"1 = best, 3 = worst. Ties are allowed.\",\n",
    "            required=True,\n",
    "            values={\"reply-1\": \"Reply 1\", \"reply-2\": \"Reply 2\", \"reply-3\": \"Reply 3\"} # or [\"reply-1\", \"reply-2\", \"reply-3\"]\n",
    "        ),\n",
    "        rg.MultiLabelQuestion(\n",
    "            name=\"entities\",\n",
    "            title=\"Highlight the entities in the text:\",\n",
    "            labels={\"PER\": \"Person\", \"ORG\": \"Organization\", \"EVE\": \"Event\"},\n",
    "            # or [\"PER\", \"ORG\", \"EVE\"],\n",
    "            # field=\"text\",\n",
    "            required=True\n",
    "        ),\n",
    "\n",
    "    ]\n",
    ")\n",
    "# SpanQuestion errored out, so used MultiLabel question in its place\n",
    "dataset.push_to_argilla(name=\"feedback_ds\", workspace=\"argilla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query the rg.Dataset, you need to be able to write Lucene Query Language (LQL), which is native to Elastic Search and Open Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data record\n",
    "\n",
    "record = rg.load(name=\"imdb\", vector=(\"new_vector\", [0, 43, 1985]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = rg.TextClassificationRecord(\n",
    "    text=\"Hello world, I am a vector record!\",\n",
    "    vectors= {\"my_vector_name\": [0, 42, 1984]}\n",
    ")\n",
    "rg.log(name=\"withvek\", records=record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.labeling.text_classification import add_rules, delete_rules, Rule, update_rules\n",
    "\n",
    "# Create\n",
    "rule = Rule(query=\"positive impact\", label=\"optimism\")\n",
    "add_rules(dataset=\"withvek\", rules=[rule])\n",
    "\n",
    "# Update\n",
    "rule.label = \"pessimism\"\n",
    "update_rules(dataset=\"withvek\", rules=[rule])\n",
    "\n",
    "# Delete\n",
    "# delete_rules(dataset=\"withvek\", rules=[rule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeedbackRecord(fields={'text': 'I am so happy today'}, metadata={}, vectors={}, responses=[], suggestions=(), external_id=None),\n",
       " FeedbackRecord(fields={'text': 'I feel sad today'}, metadata={}, vectors={}, responses=[], suggestions=(), external_id=None)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\argenv\\Lib\\site-packages\\argilla\\client\\feedback\\dataset\\remote\\dataset.py:1000: UserWarning: Already pushed datasets cannot be pushed to Argilla again because they are synced automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RemoteFeedbackDataset(\n",
       "   id=7c84a580-aedc-4bee-a1bb-7dde00e83bdd\n",
       "   name=ds-1\n",
       "   workspace=Workspace(id=5ed06c89-dbe5-47a8-a9d0-5b59872481a6, name=localgilla, inserted_at=2024-04-02 07:18:14.945504, updated_at=2024-04-02 07:18:14.945504)\n",
       "   url=https://kamaljp-yttutorialserver.hf.space/dataset/7c84a580-aedc-4bee-a1bb-7dde00e83bdd/annotation-mode\n",
       "   fields=[RemoteTextField(id=UUID('3f0de2e8-48f5-4e7e-8bd9-b7897ca630d0'), client=None, name='text', title='Text', required=True, type='text', use_markdown=True)]\n",
       "   questions=[RemoteLabelQuestion(id=UUID('3a243fd3-6d6d-4b35-ba75-74be2ac33f1c'), client=None, name='label', title='Label', description=None, required=True, type='label_selection', labels=['sadness', 'joy'], visible_labels=None)]\n",
       "   guidelines=This is a text classification dataset that contains texts and labels. Given a set of texts and a predefined set of labels, the goal of text classification is to assign one label to each text based on its content. Please classify the texts by making the correct selection.\n",
       "   metadata_properties=[]\n",
       "   vectors_settings=[]\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1.push_to_argilla(name='ds-1',workspace=localgilla)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
