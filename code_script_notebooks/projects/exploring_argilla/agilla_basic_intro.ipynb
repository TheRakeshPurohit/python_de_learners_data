{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localuser = \"argilla\"\n",
    "password = \"1234\"\n",
    "apikey = \"argilla.apikey\"\n",
    "url = \"http://aicontroller:6900/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "# get the docs here https://.hf.space/api/docs\n",
    "# need to signin as owner with 12345678 to proceed the following.\n",
    "# https://docs.argilla.io/en/latest/getting_started/installation/configurations/user_management.html\n",
    "rg.init(\n",
    "    api_url=url,\n",
    "    api_key=apikey\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = rg.User.create(\n",
    "    username=\"new-user\",\n",
    "    first_name=\"New\",\n",
    "    last_name=\"User\",\n",
    "    password=\"12345678\",\n",
    "    role=\"annotator\",\n",
    "    workspaces=[\"argilla\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.Workspace.create(\"localgilla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rg.FeedbackDataset.for_text_classification(\n",
    "    labels=[\"sadness\", \"joy\"],\n",
    "    multi_label=False,\n",
    "    use_markdown=True,\n",
    "    guidelines=None,\n",
    "    metadata_properties=None,\n",
    "    vectors_settings=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localgilla = \"localgilla\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_argilla(name=\"ds-1\", workspace=localgilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [\n",
    "    rg.FeedbackRecord(\n",
    "        fields={\n",
    "            \"text\": \"I am so happy today\",\n",
    "        },\n",
    "    ),\n",
    "    rg.FeedbackRecord(\n",
    "        fields={\n",
    "            \"text\": \"I feel sad today\",\n",
    "        },\n",
    "    )\n",
    "]\n",
    "dataset.add_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hf = rg.FeedbackDataset.from_huggingface(\"argilla/emotion\", split=\"train[1:101]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hf.push_to_argilla(name=\"emogilla\", workspace=localgilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.feedback import TrainingTask\n",
    "\n",
    "task = TrainingTask.for_text_classification(\n",
    "    text=dataset_hf.field_by_name('text'),\n",
    "    label=dataset_hf.question_by_name(\"label\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.feedback import ArgillaTrainer\n",
    "\n",
    "trainer = ArgillaTrainer(\n",
    "    dataset=dataset_hf,\n",
    "    task=task,\n",
    "    framework=\"transformers\",\n",
    "    train_size=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.get_trainer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.get_trainer_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.get_model_kwargs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(output_dir=\"train_arg_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uploading Data\n",
    "\n",
    "# Three types of Record, depending on the tasks support TextClassificationRecord, \n",
    "# TokenClassificationRecord and Text2TextRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rg.FeedbackDataset.for_text_classification(\n",
    "    labels=[\"good\", \"bad\"],\n",
    "    multi_label=False,\n",
    "    use_markdown=True,\n",
    "    guidelines=None,\n",
    "    metadata_properties=None,\n",
    "    vectors_settings=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical attrs for the record are text, annotation, prediction and metadata\n",
    "\n",
    "textcat_rec = rg.TextClassificationRecord(\n",
    "    text='Hello there. Its me',\n",
    "    prediction=[(\"LABEL1\", 0.8), (\"LABEL2\", 0.2)],\n",
    "    annotation='LABEL1',\n",
    "    multi_label=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokencat_rec = rg.TokenClassificationRecord(\n",
    "    text='Argilla is a super awesome library that speeds up annotation',\n",
    "    tokens=[\"Argilla\", \"is\", \"a\", \"super\", \"awesome\", \"library\", \"that\", \"speeds\",\n",
    "            \"up\", \"annotation\"],\n",
    "    prediction=[(\"Name\", 0, 7), (\"ADJ\", 19, 26)],  # look at the indices, it matters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2text = rg.Text2TextRecord(\n",
    "    text='Argilla is a super awesome library that speeds up annotation',\n",
    "    prediction=[\"More we use it faster we understand it\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.set_workspace(localgilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.log(textcat_rec, 'my_cat_ds')\n",
    "rg.log(text2text, 'my_t2t_ds')\n",
    "rg.log(tokencat_rec, 'my_tokenclass_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"imdb\", split='train').shuffle(seed=42).select(range(100))\n",
    "ds.rename_column(\"label\", \"annotation\")\n",
    "df_rg = rg.read_datasets(ds,task=\"TextClassification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_in_arg = rg.log(df_rg, \"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_in_arg.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"pos\", \"neg\"]\n",
    "settings = rg.TextClassificationSettings(label_schema=labels)\n",
    "rg.configure_dataset_settings(name=\"imdb\", settings=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenclassification task\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "tokenDs = load_dataset(\"ag_news\", split=\"train\").shuffle(70).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_dict(row):\n",
    "    metadata = {}\n",
    "    metadata['label'] = row[\"label\"]\n",
    "    row[\"metadata\"] = metadata\n",
    "    return row\n",
    "\n",
    "dataset = tokenDs.map(metadata_dict, remove_columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(row):\n",
    "    tokens = [token.text for token in nlp(row[\"text\"])]\n",
    "    return {\"tokens\": tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenDs = tokenDs.map(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_rg = rg.read_datasets(tokenDs, task=\"TokenClassification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.log(token_rg, 'ag_news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"PER\", \"LOC\", \"ORG\", \"MISC\"]\n",
    "\n",
    "settings = rg.TokenClassificationSettings(label_schema=labels)\n",
    "rg.configure_dataset_settings(name=\"ag_news\", settings=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2tds = load_dataset(\"europa_ecdc_tm\", \"en2fr\", split=\"train\").shuffle(25).select(range(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(row):\n",
    "    return {\"text\": row[\"translation\"][\"en\"],\n",
    "            \"prediction\": row[\"translation\"][\"fr\"]}\n",
    "\n",
    "t2tds = t2tds.map(extract, remove_columns=['translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2trg = rg.read_datasets(t2tds, task=\"Text2Text\")\n",
    "rg.log(t2trg, \"ecdc_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "# need to provide the reconrds\n",
    "dataset = rg.FeedbackDataset(\n",
    "    guidelines=\"Add some guidelines for the annotation team here.\",\n",
    "    fields=[\n",
    "        rg.TextField(name=\"prompt\", title=\"Human prompt\"),\n",
    "        rg.TextField(name=\"output\", title=\"Generated output\", use_markdown=True)\n",
    "    ],\n",
    "    questions =[\n",
    "        rg.RatingQuestion(\n",
    "            name=\"rating\",\n",
    "            title=\"Rate the quality of the response:\",\n",
    "            description=\"1 = very bad - 5= very good\",\n",
    "            required=True,\n",
    "            values=[1,2,3,4,5]\n",
    "        ),\n",
    "        rg.TextQuestion(\n",
    "            name=\"corrected-text\",\n",
    "            title=\"Provide a correction to the response:\",\n",
    "            required=False,\n",
    "            use_markdown=True\n",
    "        ),\n",
    "        rg.LabelQuestion(\n",
    "            name=\"relevant\",\n",
    "            title=\"Is the response relevant for the given prompt?\",\n",
    "            labels={\"YES\": \"Yes\", \"NO\": \"No\"}, # or [\"YES\",\"NO\"]\n",
    "            required=True,\n",
    "            visible_labels=None\n",
    "        ),\n",
    "        rg.MultiLabelQuestion(\n",
    "            name=\"content_class\",\n",
    "            title=\"Does the response include any of the following?\",\n",
    "            description=\"Select all that apply\",\n",
    "            labels={\"hate\": \"Hate Speech\" , \"sexual\": \"Sexual content\", \"violent\": \"Violent content\", \"pii\": \"Personal information\", \"untruthful\": \"Untruthful info\", \"not_english\": \"Not English\", \"inappropriate\": \"Inappropriate content\"}, # or [\"hate\", \"sexual\", \"violent\", \"pii\", \"untruthful\", \"not_english\", \"inappropriate\"]\n",
    "            required=False,\n",
    "            visible_labels=4\n",
    "        ),\n",
    "        rg.RankingQuestion(\n",
    "            name=\"preference\",\n",
    "            title=\"Order replies based on your preference\",\n",
    "            description=\"1 = best, 3 = worst. Ties are allowed.\",\n",
    "            required=True,\n",
    "            values={\"reply-1\": \"Reply 1\", \"reply-2\": \"Reply 2\", \"reply-3\": \"Reply 3\"} # or [\"reply-1\", \"reply-2\", \"reply-3\"]\n",
    "        ),\n",
    "        rg.MultiLabelQuestion(\n",
    "            name=\"entities\",\n",
    "            title=\"Highlight the entities in the text:\",\n",
    "            labels={\"PER\": \"Person\", \"ORG\": \"Organization\", \"EVE\": \"Event\"},\n",
    "            # or [\"PER\", \"ORG\", \"EVE\"],\n",
    "            # field=\"text\",\n",
    "            required=True\n",
    "        ),\n",
    "\n",
    "    ]\n",
    ")\n",
    "# SpanQuestion errored out, so used MultiLabel question in its place\n",
    "dataset.push_to_argilla(name=\"feedback_ds\", workspace=\"argilla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query the rg.Dataset, you need to be able to write Lucene Query Language (LQL), which is native to Elastic Search and Open Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data record\n",
    "\n",
    "record = rg.load(name=\"imdb\", vector=(\"new_vector\", [0, 43, 1985]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = rg.TextClassificationRecord(\n",
    "    text=\"Hello world, I am a vector record!\",\n",
    "    vectors= {\"my_vector_name\": [0, 42, 1984]}\n",
    ")\n",
    "rg.log(name=\"withvek\", records=record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.labeling.text_classification import add_rules, delete_rules, Rule, update_rules\n",
    "\n",
    "# Create\n",
    "rule = Rule(query=\"positive impact\", label=\"optimism\")\n",
    "add_rules(dataset=\"withvek\", rules=[rule])\n",
    "\n",
    "# Update\n",
    "rule.label = \"pessimism\"\n",
    "update_rules(dataset=\"withvek\", rules=[rule])\n",
    "\n",
    "# Delete\n",
    "# delete_rules(dataset=\"withvek\", rules=[rule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
