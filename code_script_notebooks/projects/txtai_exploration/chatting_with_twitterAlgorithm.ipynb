{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kvvihmmJa4c-"
      },
      "outputs": [],
      "source": [
        "!pip -q install txtai[all] langchain pypdf > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from txtai.embeddings import Embeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "import glob"
      ],
      "metadata": {
        "id": "fH4H2mk9bKdB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/twitter/the-algorithm # replace any repository of your choice"
      ],
      "metadata": {
        "id": "5IrfyHlwtp7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "root_dir = './the-algorithm'\n",
        "docs = []\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    for file in filenames:\n",
        "        try: \n",
        "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
        "            docs.extend(loader.load_and_split())\n",
        "        except Exception as e: \n",
        "            pass"
      ],
      "metadata": {
        "id": "WOxG-Yk8bKpb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_splitter = RecursiveCharacterTextSplitter(chunk_size=350,\n",
        "                                                   chunk_overlap=25,\n",
        "                                                   length_function=len)"
      ],
      "metadata": {
        "id": "GNZjPSfodTBw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_data = []\n",
        "for doc in docs:\n",
        "  #print(docs)\n",
        "  temp_split = document_splitter.split_text(doc.page_content)\n",
        "  split_data.extend(temp_split)"
      ],
      "metadata": {
        "id": "rOtX8eJCdS20"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(split_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI7JAJcOvMCC",
        "outputId": "4926d84f-b689-43b3-97cd-d884ef13c5e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79720"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embeddings index with content enabled. The default behavior is to only store indexed vectors.\n",
        "embeddings = Embeddings({\"path\": \"sentence-transformers/nli-mpnet-base-v2\", \n",
        "                         \"content\": True, \n",
        "                         \"objects\": True})"
      ],
      "metadata": {
        "id": "WpVyMy51bKwN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an index for the list of text\n",
        "embeddings.index([(uid, \n",
        "                   text, \n",
        "                   None) for uid, text in enumerate(split_data[:500])])"
      ],
      "metadata": {
        "id": "kGTzfLp6bK3M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.save(\"algo_index\")"
      ],
      "metadata": {
        "id": "jvkZJeb_uR6m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_retrieved = embeddings.search(\"What are the top classes?\",4)"
      ],
      "metadata": {
        "id": "ef81hpEAfqI1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Submits a series of prompts to the Hugging Face API.\n",
        "# This call can easily be switched to use the OpenAI API (GPT-3), Cohere API or a library like langchain.\n",
        "import requests\n",
        "\n",
        "def api(prompts):\n",
        "  response = requests.post(\"https://api-inference.huggingface.co/models/google/flan-t5-base\",\n",
        "                           json={\"inputs\": prompts})\n",
        "\n",
        "  return [x[\"generated_text\"] for x in response.json()]"
      ],
      "metadata": {
        "id": "dzJIKSQfyHDl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from txtai.pipeline import Extractor\n",
        "\n",
        "# Create extractor instance, submit prompts to the Hugging Face inference API\n",
        "extractor = Extractor(embeddings, api)"
      ],
      "metadata": {
        "id": "AIYuwbnpyQrv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt(question):\n",
        "  return f\"\"\"\n",
        "    Answer the following question using the context below.\n",
        "    Question: {question}\n",
        "    Context:\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "Ffn-jNNJzNat"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is clusterTweet\""
      ],
      "metadata": {
        "id": "I1OQ99I5_Py1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n"
      ],
      "metadata": {
        "id": "K1ZnV57TAIj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4z0WmG1Nk-u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cs-jJRc6k-kk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}