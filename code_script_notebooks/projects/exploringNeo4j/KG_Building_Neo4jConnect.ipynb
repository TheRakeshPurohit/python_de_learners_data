{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/extract-knowledge-from-text-end-to-end-information-extraction-pipeline-with-spacy-and-neo4j-502b2b1e0754\n",
        "\n",
        "https://github.com/tomasonjo/blogs/blob/master/ie_pipeline/SpaCy_informationextraction.ipynb"
      ],
      "metadata": {
        "id": "oCt14ZG0Nrya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crosslingual-coreference > /dev/null"
      ],
      "metadata": {
        "id": "X1MocPtMOXyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy-transformers > /dev/null"
      ],
      "metadata": {
        "id": "XTOfMjBMdhGu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy > /dev/null"
      ],
      "metadata": {
        "id": "VvN9_PxBenku"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy-transformers wikipedia neo4j > /dev/null\n",
        "!pip install --upgrade google-cloud-storage > /dev/null\n",
        "!pip install transformers==4.18.0 > /dev/null\n",
        "!python -m spacy download en_core_web_sm > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXC51UIgNqXd",
        "outputId": "60f5964c-2c3d-4b4d-9577-dddadb361d94"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.2.0 Requires-Python ==3.6; 0.2.6 Requires-Python >=3.7.1,<3.8.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch<1.11.0,>=1.10.0 (from crosslingual-coreference) (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch<1.11.0,>=1.10.0\u001b[0m\u001b[31m\n",
            "\u001b[0m2023-06-21 04:30:57.616001: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-21 04:30:58.765261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f9NHrriEOxS",
        "outputId": "127bfd9f-8f56-4a07-a125-3924d0a93573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import crosslingual_coreference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add rebel component https://github.com/Babelscape/rebel/blob/main/spacy_component.py\n",
        "import requests\n",
        "import re\n",
        "import hashlib\n",
        "from spacy import Language\n",
        "from typing import List\n",
        "\n",
        "from spacy.tokens import Doc, Span\n",
        "\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "2JUaR_ATQDAB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_wiki_api(item):\n",
        "  try:\n",
        "    url = f\"https://www.wikidata.org/w/api.php?action=wbsearchentities&search={item}&language=en&format=json\"\n",
        "    data = requests.get(url).json()\n",
        "    # Return the first id (Could upgrade this in the future)\n",
        "    return data['search'][0]['id']\n",
        "  except:\n",
        "    return 'id-less'\n"
      ],
      "metadata": {
        "id": "aEbL_MDlQC9r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_triplets(text):\n",
        "    \"\"\"\n",
        "    Function to parse the generated text and extract the triplets\n",
        "    \"\"\"\n",
        "    triplets = []\n",
        "    relation, subject, relation, object_ = '', '', '', ''\n",
        "    text = text.strip()\n",
        "    current = 'x'\n",
        "    for token in text.replace(\"\", \"\").replace(\"\", \"\").replace(\"\", \"\").split():\n",
        "        if token == \"\":\n",
        "            current = 't'\n",
        "            if relation != '':\n",
        "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
        "                relation = ''\n",
        "            subject = ''\n",
        "        elif token == \"\":\n",
        "            current = 's'\n",
        "            if relation != '':\n",
        "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
        "            object_ = ''\n",
        "        elif token == \"\":\n",
        "            current = 'o'\n",
        "            relation = ''\n",
        "        else:\n",
        "            if current == 't':\n",
        "                subject += ' ' + token\n",
        "            elif current == 's':\n",
        "                object_ += ' ' + token\n",
        "            elif current == 'o':\n",
        "                relation += ' ' + token\n",
        "    if subject != '' and relation != '' and object_ != '':\n",
        "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
        "\n",
        "    return triplets"
      ],
      "metadata": {
        "id": "2JigtW9EQC7X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Language.factory(\n",
        "    \"rebel\",\n",
        "    requires=[\"doc.sents\"],\n",
        "    assigns=[\"doc._.rel\"],\n",
        "    default_config={\n",
        "        \"model_name\": \"Babelscape/rebel-large\",\n",
        "        \"device\": 0,\n",
        "    },\n",
        ")\n",
        "class RebelComponent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        nlp,\n",
        "        name,\n",
        "        model_name: str,\n",
        "        device: int,\n",
        "    ):\n",
        "        assert model_name is not None, \"\"\n",
        "        self.triplet_extractor = pipeline(\"text2text-generation\", model=model_name, tokenizer=model_name, device=device)\n",
        "        self.entity_mapping = {}\n",
        "        # Register custom extension on the Doc\n",
        "        if not Doc.has_extension(\"rel\"):\n",
        "          Doc.set_extension(\"rel\", default={})\n",
        "\n",
        "    def get_wiki_id(self, item: str):\n",
        "        mapping = self.entity_mapping.get(item)\n",
        "        if mapping:\n",
        "          return mapping\n",
        "        else:\n",
        "          res = call_wiki_api(item)\n",
        "          self.entity_mapping[item] = res\n",
        "          return res\n",
        "\n",
        "\n",
        "    def _generate_triplets(self, sent: Span) -> List[dict]:\n",
        "          output_ids = self.triplet_extractor(sent.text, return_tensors=True, return_text=False)[0][\"generated_token_ids\"][\"output_ids\"]\n",
        "          extracted_text = self.triplet_extractor.tokenizer.batch_decode(output_ids[0])\n",
        "          extracted_triplets = extract_triplets(extracted_text[0])\n",
        "          return extracted_triplets\n",
        "\n",
        "    def set_annotations(self, doc: Doc, triplets: List[dict]):\n",
        "        for triplet in triplets:\n",
        "\n",
        "            # Remove self-loops (relationships that start and end at the entity)\n",
        "            if triplet['head'] == triplet['tail']:\n",
        "                continue\n",
        "\n",
        "            # Use regex to search for entities\n",
        "            head_span = re.search(triplet[\"head\"], doc.text)\n",
        "            tail_span = re.search(triplet[\"tail\"], doc.text)\n",
        "\n",
        "            # Skip the relation if both head and tail entities are not present in the text\n",
        "            # Sometimes the Rebel model hallucinates some entities\n",
        "            if not head_span or not tail_span:\n",
        "              continue\n",
        "\n",
        "            index = hashlib.sha1(\"\".join([triplet['head'], triplet['tail'], triplet['type']]).encode('utf-8')).hexdigest()\n",
        "            if index not in doc._.rel:\n",
        "                # Get wiki ids and store results\n",
        "                doc._.rel[index] = {\"relation\": triplet[\"type\"], \"head_span\": {'text': triplet['head'], 'id': self.get_wiki_id(triplet['head'])}, \"tail_span\": {'text': triplet['tail'], 'id': self.get_wiki_id(triplet['tail'])}}\n",
        "\n",
        "    def __call__(self, doc: Doc) -> Doc:\n",
        "        for sent in doc.sents:\n",
        "            sentence_triplets = self._generate_triplets(sent)\n",
        "            self.set_annotations(doc, sentence_triplets)\n",
        "        return doc"
      ],
      "metadata": {
        "id": "K74L3Sv2QC48"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = -1 # Number of the GPU, -1 if want to use CPU"
      ],
      "metadata": {
        "id": "bIOc-C_XceNo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add coreference resolution model\n",
        "coref = spacy.load('en_core_web_sm')\n",
        "\n",
        "coref.add_pipe(\"xx_coref\",\n",
        "               config={\"chunk_size\": 2500,\n",
        "                       \"chunk_overlap\": 2,\n",
        "                       \"device\": DEVICE})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAAe6vvPchVB",
        "outputId": "ea5168f2-e79e-4795-9e51-ac6f2ca6961e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<crosslingual_coreference.CrossLingualPredictorSpacy.CrossLingualPredictorSpacy at 0x7f2f8e877be0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coref(\"What is the subject of this line\")"
      ],
      "metadata": {
        "id": "oiPYuhz7k41k",
        "outputId": "75fc75e2-6db7-49a9-92c4-6414220d99b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "What is the subject of this line"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define rel extraction model\n",
        "rel_ext = spacy.load('en_core_web_sm', disable=['ner', 'lemmatizer', 'attribute_rules', 'tagger'])\n",
        "rel_ext.add_pipe(\"rebel\", config={\n",
        "    'device':DEVICE, # Number of the GPU, -1 if want to use CPU\n",
        "    'model_name':'Babelscape/rebel-large'} # Model used, will default to 'Babelscape/rebel-large' if not given\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXjHiJtFQC28",
        "outputId": "c63e1a53-22d4-41dc-b32c-4e616a4d5e84"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.RebelComponent at 0x7f2f99369c30>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Why no data is getting populated.\"\n",
        "\n",
        "coref_text = coref(input_text)._.resolved_text\n",
        "\n",
        "doc = rel_ext(coref_text)"
      ],
      "metadata": {
        "id": "6LQvb0PbQCyQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc._.rel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgLvm_CXftSf",
        "outputId": "c948bcfb-bdaf-49d2-cab6-0c5e07ce5caa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for value, rel_dict in doc._.rel.items():\n",
        "    print(f\"{value}: {rel_dict}\")"
      ],
      "metadata": {
        "id": "qPy7_0D6QCt_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "triplet_extractor = pipeline('text2text-generation', model='Babelscape/rebel-large',\n",
        "                             tokenizer='Babelscape/rebel-large')\n",
        "text = \"Punta Cana is a resort town in the municipality of Higuey, in La Altagracia Province, the eastern most province of the Dominican Republic\"\n",
        "\n",
        "# We need to use the tokenizer manually since we need special tokens.\n",
        "extracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(text,\n",
        "                                                                             return_tensors=True,\n",
        "                                                                             return_text=False)[0][\"generated_token_ids\"]])\n",
        "\n",
        "print(extracted_text[0])\n"
      ],
      "metadata": {
        "id": "ZFTbaxYynH5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9gG1utACnH2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GUK9_3ConH0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zA0DajWinHxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4D2EvDRWnHvL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}