{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "TbNHzwH3kU4f"
      },
      "outputs": [],
      "source": [
        "!pip install transformers wikipedia neo4j kuzu langchain > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "oMVVc3epkQbC"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import math\n",
        "import torch\n",
        "import wikipedia\n",
        "import IPython\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkU8C2qVsLBh"
      },
      "source": [
        "# Load the REBEL model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "3DUOJhoVltPg"
      },
      "outputs": [],
      "source": [
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"This notebook shows how to use LLMs to provide a natural language interface to KÃ¹zu database.\""
      ],
      "metadata": {
        "id": "k5Ub8ApKEofA"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer text\n",
        "model_inputs = tokenizer(test_text,\n",
        "                          max_length=512,\n",
        "                          padding=True,\n",
        "                          truncation=True,\n",
        "                        return_tensors='pt')\n",
        "\n",
        "print(f\"Num tokens: {len(model_inputs['input_ids'][0])}\")\n",
        "\n",
        "# Generate\n",
        "gen_kwargs = {\n",
        "    \"max_length\": 216,\n",
        "    \"length_penalty\": 0,\n",
        "    \"num_beams\": 5,\n",
        "    \"num_return_sequences\": 4\n",
        "}\n",
        "generated_tokens = model.generate(\n",
        "    **model_inputs,\n",
        "    **gen_kwargs,\n",
        ")\n",
        "decoded_preds = tokenizer.batch_decode(generated_tokens,\n",
        "                                        skip_special_tokens=False)\n",
        "\n",
        "decoded_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9uxgToRHPzq",
        "outputId": "18822910-2aaf-4b24-9173-a4f0cab56014"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num tokens: 23\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s><triplet> LLMs <subj> natural language interface <obj> use</s>',\n",
              " '<s><triplet> LLMs <subj> natural language <obj> use</s><pad>',\n",
              " '<s><triplet> LLM <subj> natural language interface <obj> use</s>',\n",
              " '<s><triplet> LLMs <subj> natural language <obj> subclass of</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "h-DboLAHkj_G"
      },
      "outputs": [],
      "source": [
        "def extract_relations_from_model_output(text):\n",
        "    relations = []\n",
        "    relation, subject, relation, object_ = '', '', '', ''\n",
        "    text = text.strip()\n",
        "    current = 'x'\n",
        "    text_replaced = text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n",
        "    for token in text_replaced.split():\n",
        "        if token == \"<triplet>\":\n",
        "            current = 't'\n",
        "            if relation != '':\n",
        "                relations.append({\n",
        "                    'head': subject.strip(),\n",
        "                    'type': relation.strip(),\n",
        "                    'tail': object_.strip()\n",
        "                })\n",
        "                relation = ''\n",
        "            subject = ''\n",
        "        elif token == \"<subj>\":\n",
        "            current = 's'\n",
        "            if relation != '':\n",
        "                relations.append({\n",
        "                    'head': subject.strip(),\n",
        "                    'type': relation.strip(),\n",
        "                    'tail': object_.strip()\n",
        "                })\n",
        "            object_ = ''\n",
        "        elif token == \"<obj>\":\n",
        "            current = 'o'\n",
        "            relation = ''\n",
        "        else:\n",
        "            if current == 't':\n",
        "                subject += ' ' + token\n",
        "            elif current == 's':\n",
        "                object_ += ' ' + token\n",
        "            elif current == 'o':\n",
        "                relation += ' ' + token\n",
        "    if subject != '' and relation != '' and object_ != '':\n",
        "        relations.append({\n",
        "            'head': subject.strip(),\n",
        "            'type': relation.strip(),\n",
        "            'tail': object_.strip()\n",
        "        })\n",
        "    return relations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "8WxoMskYHgsm"
      },
      "outputs": [],
      "source": [
        "class KB():\n",
        "    def __init__(self):\n",
        "        self.relations = []\n",
        "\n",
        "    def are_relations_equal(self, r1, r2):\n",
        "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
        "\n",
        "    def exists_relation(self, r1):\n",
        "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
        "\n",
        "    def add_relation(self, r):\n",
        "        if not self.exists_relation(r):\n",
        "            self.relations.append(r)\n",
        "\n",
        "    def print(self):\n",
        "        print(\"Relations:\")\n",
        "        for r in self.relations:\n",
        "            print(f\"  {r}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ijyjp6r1kg2V"
      },
      "outputs": [],
      "source": [
        "def from_small_text_to_kb(text, verbose=False):\n",
        "    kb = KB()\n",
        "\n",
        "    # Tokenizer text\n",
        "    model_inputs = tokenizer(text,\n",
        "                             max_length=512,\n",
        "                             padding=True,\n",
        "                             truncation=True,\n",
        "                            return_tensors='pt')\n",
        "    if verbose:\n",
        "        print(f\"Num tokens: {len(model_inputs['input_ids'][0])}\")\n",
        "\n",
        "    # Generate\n",
        "    gen_kwargs = {\n",
        "        \"max_length\": 216,\n",
        "        \"length_penalty\": 0,\n",
        "        \"num_beams\": 3,\n",
        "        \"num_return_sequences\": 3\n",
        "    }\n",
        "    generated_tokens = model.generate(\n",
        "        **model_inputs,\n",
        "        **gen_kwargs,\n",
        "    )\n",
        "    decoded_preds = tokenizer.batch_decode(generated_tokens,\n",
        "                                           skip_special_tokens=False)\n",
        "\n",
        "    # create kb\n",
        "    for sentence_pred in decoded_preds:\n",
        "        relations = extract_relations_from_model_output(sentence_pred)\n",
        "        for r in relations:\n",
        "            kb.add_relation(r)\n",
        "\n",
        "    return kb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_kb = from_small_text_to_kb(test_text)"
      ],
      "metadata": {
        "id": "fN-J_PKeEtD-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_kb.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLkS-gGTL6Vq",
        "outputId": "10fe8645-ee3f-49c8-8f6c-f2ba7414b055"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relations:\n",
            "  {'head': 'LLMs', 'type': 'use', 'tail': 'natural language interface'}\n",
            "  {'head': 'LLMs', 'type': 'use', 'tail': 'natural language'}\n",
            "  {'head': 'LLM', 'type': 'use', 'tail': 'natural language interface'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPWvl_78kUBX",
        "outputId": "a7d54ccc-e0a3-4a38-ec2f-eba18a21fcbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num tokens: 62\n",
            "Relations:\n",
            "  {'head': 'Get started with chains', 'type': 'subclass of', 'tail': 'Chain'}\n",
            "  {'head': 'Get started with chains', 'type': 'uses', 'tail': 'Chain'}\n",
            "  {'head': 'Get started with chains', 'type': 'instance of', 'tail': 'Chain'}\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"If you are just getting started,\n",
        "and you have relatively simple apis,\n",
        "you should get started with chains.\n",
        "Chains are a sequence of predetermined steps,\n",
        "so they are good to get started with as they\n",
        "give you more control and let you understand\n",
        "what is happening better.\"\"\"\n",
        "\n",
        "kb = from_small_text_to_kb(text,\n",
        "                           verbose=True)\n",
        "kb.print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqhLveaeuJNk"
      },
      "source": [
        "# Split spans: from long text to KB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "i0L2Lw9vJ6-I"
      },
      "outputs": [],
      "source": [
        "class SpankB():\n",
        "    def __init__(self):\n",
        "        self.relations = []\n",
        "\n",
        "    def are_relations_equal(self, r1, r2):\n",
        "        return all(r1[attr] == r2[attr] for attr in [\"head\",\n",
        "                                                     \"type\",\n",
        "                                                     \"tail\"])\n",
        "\n",
        "    def exists_relation(self, r1):\n",
        "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
        "\n",
        "    def merge_relations(self, r1):\n",
        "        r2 = [r for r in self.relations\n",
        "              if self.are_relations_equal(r1, r)][0]\n",
        "        spans_to_add = [span for span in r1[\"meta\"][\"spans\"]\n",
        "                        if span not in r2[\"meta\"][\"spans\"]]\n",
        "        r2[\"meta\"][\"spans\"] += spans_to_add\n",
        "\n",
        "    def add_relation(self, r):\n",
        "        if not self.exists_relation(r):\n",
        "            self.relations.append(r)\n",
        "        else:\n",
        "            self.merge_relations(r)\n",
        "\n",
        "    def print(self):\n",
        "        print(\"Relations:\")\n",
        "        for r in self.relations:\n",
        "            print(f\"  {r}\")\n",
        "\n",
        "    def save_csv(self,file_name):\n",
        "        print(f\"Saving to file {file_name}\")\n",
        "        reln_df = pd.DataFrame(self.relations)\n",
        "        reln_df.to_csv(file_name,index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "HlnLhlSmuUCs"
      },
      "outputs": [],
      "source": [
        "def from_text_to_kb(text,\n",
        "                    span_length=50,\n",
        "                    verbose=False):\n",
        "    # tokenize whole text\n",
        "    inputs = tokenizer([text], return_tensors=\"pt\")\n",
        "\n",
        "    # compute span boundaries\n",
        "    num_tokens = len(inputs[\"input_ids\"][0])\n",
        "    if verbose:\n",
        "        print(f\"Input has {num_tokens} tokens\")\n",
        "    num_spans = math.ceil(num_tokens / span_length)\n",
        "    if verbose:\n",
        "        print(f\"Input has {num_spans} spans\")\n",
        "    overlap = math.ceil((num_spans * span_length - num_tokens) /\n",
        "                        max(num_spans - 1, 1))\n",
        "    spans_boundaries = []\n",
        "    start = 0\n",
        "    for i in range(num_spans):\n",
        "        spans_boundaries.append([start + span_length * i,\n",
        "                                 start + span_length * (i + 1)])\n",
        "        start -= overlap\n",
        "    if verbose:\n",
        "        print(f\"Span boundaries are {spans_boundaries}\")\n",
        "\n",
        "    # transform input with spans\n",
        "    tensor_ids = [inputs[\"input_ids\"][0][boundary[0]:boundary[1]]\n",
        "                  for boundary in spans_boundaries]\n",
        "    tensor_masks = [inputs[\"attention_mask\"][0][boundary[0]:boundary[1]]\n",
        "                    for boundary in spans_boundaries]\n",
        "    inputs = {\n",
        "        \"input_ids\": torch.stack(tensor_ids),\n",
        "        \"attention_mask\": torch.stack(tensor_masks)\n",
        "    }\n",
        "\n",
        "    # generate relations\n",
        "    num_return_sequences = 3\n",
        "    gen_kwargs = {\n",
        "        \"max_length\": 256,\n",
        "        \"length_penalty\": 0,\n",
        "        \"num_beams\": 3,\n",
        "        \"num_return_sequences\": num_return_sequences\n",
        "    }\n",
        "    generated_tokens = model.generate(\n",
        "        **inputs,\n",
        "        **gen_kwargs,\n",
        "    )\n",
        "\n",
        "    # decode relations\n",
        "    decoded_preds = tokenizer.batch_decode(generated_tokens,\n",
        "                                           skip_special_tokens=False)\n",
        "\n",
        "    # create kb\n",
        "    kb = SpankB()\n",
        "    i = 0\n",
        "    for sentence_pred in decoded_preds:\n",
        "        current_span_index = i // num_return_sequences\n",
        "        relations = extract_relations_from_model_output(sentence_pred)\n",
        "        for relation in relations:\n",
        "            relation[\"meta\"] = {\n",
        "                \"spans\": [spans_boundaries[current_span_index]]\n",
        "            }\n",
        "            kb.add_relation(relation)\n",
        "        i += 1\n",
        "\n",
        "    return kb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "halo_text = \"\"\"The Didact, born Shadow-of-Sundered-Star,[3] is a Forerunner Promethean who held an extremely high status in the Forerunner society as protector of the ecumene,[9] head of the Warrior-Servant rate and supreme commander of the entire Forerunner military.[10] He wholeheartedly believed in the Mantle the Forerunners held to protect life, and fervently opposed the Halo Array as a sin beyond measure. He was also the lover and husband of the Librarian.\n",
        "\n",
        "Originally thought to have been killed by the Master Builder, Faber,[11] the Didact effectively existed as two individuals during the final days of the Forerunner-Flood war; his original self, as well as his implanted consciousness within a young Forerunner known as Bornstellar Makes Eternal Lasting. To differentiate these two incarnations, the original Didact was referred to as the Ur-Didact, while his other incarnation was known as the IsoDidact.[12] The Ur-Didact was eventually exiled on Requiem, not to be awakened until 2557;[13] meanwhile, the IsoDidact served until the final days of the Flood conflict and was responsible for activating the Halo Array.[14]\n",
        "\n",
        "After being released from his Cryptum many millennia later, the Ur-Didact resumed his war against humanity. Spartan John-117 and Cortana fought him on his ship, and sent him falling into slipspace, seemingly defeating him. After surviving slipspace, John-117 faced him again, this time with the rest of Blue Team. After a long and perilous battle, the Ur-Didact's biological form was destroyed under the combined power of several Composers. While he is considered \"contained\" by the Office of Naval Intelligence, his digitized consciousness apparently survives.[2] \"\"\""
      ],
      "metadata": {
        "id": "1pb0s8hDO9Li"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "sXz06j_dne1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486e3530-6475-47a3-f1ee-babf8c4f8e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input has 375 tokens\n",
            "Input has 8 spans\n",
            "Span boundaries are [[0, 50], [46, 96], [92, 142], [138, 188], [184, 234], [230, 280], [276, 326], [322, 372]]\n"
          ]
        }
      ],
      "source": [
        "kb = from_text_to_kb(halo_text,\n",
        "                     verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kb.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_hKSCtFdOur",
        "outputId": "e47a42d5-2e70-40d9-beba-41650d23e5b0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relations:\n",
            "  {'head': 'Didact', 'type': 'instance of', 'tail': 'Promethean', 'meta': {'spans': [[0, 50]]}}\n",
            "  {'head': 'Didact', 'type': 'instance of', 'tail': 'Forerunner Promethean', 'meta': {'spans': [[0, 50]]}}\n",
            "  {'head': 'Forerunner', 'type': 'subclass of', 'tail': 'Promethean', 'meta': {'spans': [[0, 50]]}}\n",
            "  {'head': 'Warrior-Servant', 'type': 'instance of', 'tail': 'Mantle', 'meta': {'spans': [[46, 96]]}}\n",
            "  {'head': 'Warrior-Servant', 'type': 'instance of', 'tail': 'rate', 'meta': {'spans': [[46, 96]]}}\n",
            "  {'head': 'Warrior-Servant rate', 'type': 'instance of', 'tail': 'Mantle', 'meta': {'spans': [[46, 96]]}}\n",
            "  {'head': 'Didact', 'type': 'spouse', 'tail': 'Librarian', 'meta': {'spans': [[92, 142]]}}\n",
            "  {'head': 'Librarian', 'type': 'spouse', 'tail': 'Didact', 'meta': {'spans': [[92, 142]]}}\n",
            "  {'head': 'Faber', 'type': 'occupation', 'tail': 'Master Builder', 'meta': {'spans': [[92, 142]]}}\n",
            "  {'head': 'Bornstellar Makes Eternal Lasting', 'type': 'instance of', 'tail': 'Forerunner', 'meta': {'spans': [[138, 188]]}}\n",
            "  {'head': 'Forerunner', 'type': 'has part', 'tail': 'Bornstellar Makes Eternal Lasting', 'meta': {'spans': [[138, 188]]}}\n",
            "  {'head': 'Flood war', 'type': 'participant', 'tail': 'runner', 'meta': {'spans': [[138, 188]]}}\n",
            "  {'head': '2557', 'type': 'point in time', 'tail': '2557', 'meta': {'spans': [[184, 234]]}}\n",
            "  {'head': 'Requiem', 'type': 'point in time', 'tail': '2557', 'meta': {'spans': [[184, 234]]}}\n",
            "  {'head': 'Ur-Didact', 'type': 'date of death', 'tail': '2557', 'meta': {'spans': [[184, 234]]}}\n",
            "  {'head': 'IsoDidact', 'type': 'conflict', 'tail': 'Flood conflict', 'meta': {'spans': [[230, 280]]}}\n",
            "  {'head': 'Halo Array', 'type': 'conflict', 'tail': 'Flood conflict', 'meta': {'spans': [[230, 280]]}}\n",
            "  {'head': 'Flood conflict', 'type': 'participant', 'tail': 'IsoDidact', 'meta': {'spans': [[230, 280]]}}\n",
            "  {'head': 'John-117', 'type': 'member of', 'tail': 'Blue Team', 'meta': {'spans': [[276, 326]]}}\n",
            "  {'head': 'Blue Team', 'type': 'has part', 'tail': 'John-117', 'meta': {'spans': [[276, 326]]}}\n",
            "  {'head': 'Blue Team', 'type': 'has part', 'tail': 'Cortana', 'meta': {'spans': [[276, 326]]}}\n",
            "  {'head': 'Ur-Didact', 'type': 'member of', 'tail': 'Composers', 'meta': {'spans': [[322, 372]]}}\n",
            "  {'head': 'Ur-Didact', 'type': 'instance of', 'tail': 'Composers', 'meta': {'spans': [[322, 372]]}}\n",
            "  {'head': 'Composers', 'type': 'has part', 'tail': 'Ur-Didact', 'meta': {'spans': [[322, 372]]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kb.save_csv(\"relations.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-glp2afW6BP",
        "outputId": "64207b2a-d6b8-4539-adb0-5dc861766c91"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving to file relations.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Owtye8Nq9qg"
      },
      "execution_count": 61,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}