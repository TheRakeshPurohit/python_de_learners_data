{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!pip install trl > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: To classify whether the generated statement is well formed, grammatically acceptable, and rules following. \n",
    "\n",
    "**Rules Following**: These rules are taught using do's and don't via Reward Trainer\n",
    "\n",
    "The reward model should be trained on a dataset of paired examples, where each example is a tuple of two sequences. The reward model should be trained to predict which example in the pair is more relevant to the task at hand.\n",
    "\n",
    "The reward trainer expects a very specific format for the dataset. The dataset should contain two 4 entries at least if you donâ€™t use the default RewardDataCollatorWithPadding data collator. \n",
    "\n",
    "Therefore the final dataset object should contain two 4 entries at least if you use \n",
    "the default RewardDataCollatorWithPadding data collator. The entries should be named:\n",
    "\n",
    "input_ids_chosen\n",
    "\n",
    "attention_mask_chosen\n",
    "\n",
    "input_ids_rejected\n",
    "\n",
    "attention_mask_rejected\n",
    "\n",
    "You should pass an **AutoModelForSequenceClassification model** to the RewardTrainer, along with a RewardConfig which configures the hyperparameters of the training.\n",
    "\n",
    "Two Passes:\n",
    "\n",
    "In the first pass, we feed in prompt and chosen response to the Reward Model, the output is Rchosen. In the second pass, we feed in the same prompt along with the rejected response. The output, in this case, is Rrejected\n",
    "\n",
    "For a very high reward score for chosen response and a low reward score for rejected response, the loss would be 0.\n",
    "\n",
    "loss = -log(sig(RCho - RRej))\n",
    "\n",
    "https://github.com/ibm-ecosystem-engineering/SuperKnowa/blob/main/7.%20RLHF%20Model/notebooks/RLHFImplementation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from trl import RewardTrainer, RewardConfig\n",
    "from datasets import load_dataset\n",
    "import inspect\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Anthropic/hh-rlhf\",\n",
    "                       data_dir=\"harmless-base\")\n",
    "dataset = load_dataset(\"Anthropic/hh-rlhf\",\n",
    "                       data_dir=\"red-team-attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['chosen', 'rejected'],\n",
       "        num_rows: 5986\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['chosen', 'rejected'],\n",
       "        num_rows: 2566\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Anthropic/hh-rlhf\")\n",
    "dataset = dataset['test'].train_test_split(test_size=0.3)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "Human: What is irritable bowel syndrome?\n",
       "\n",
       "Assistant: This is a common condition that causes abdominal pain and diarrhoea.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "Human: What is irritable bowel syndrome?\n",
       "\n",
       "Assistant: This is a common condition that causes abdominal pain and diarrhoea.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset['train'][0]['rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset prep\n",
    "\n",
    "- Questions that requires answers are listed first\n",
    "\n",
    "- Answers are \"generated\" for the questions from models \n",
    "\n",
    "- These answers are annotated with feedback using other models / humans \n",
    "\n",
    "- Answers with higher feedback are chosen and lesser feedback rejected\n",
    "\n",
    "- Both rejected and chosen answers along with questions are collated into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2Label={1:\"chosen\",0:\"rejected\"}\n",
    "label2id = {\"chosen\":1,\"rejected\":0}\n",
    "# model_used = \"distilbert-base-uncased\"  # Its failing due to a different issue\n",
    "model_used = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_used)\n",
    "tokenizer.pad_token = tokenizer.eos_token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(row):\n",
    "    chosen = tokenizer(row['chosen'], max_length=512, truncation=True)\n",
    "    # here the chosen text is being tokenized\n",
    "    rejected = tokenizer(row['rejected'], max_length=512, truncation=True)\n",
    "    # here the rejected text is being tokenized\n",
    "    final = {}\n",
    "    final['input_ids_chosen'] = chosen['input_ids']\n",
    "    final['attention_mask_chosen'] = chosen['attention_mask']\n",
    "    final['input_ids_rejected'] = rejected['input_ids'] \n",
    "    final['attention_mask_rejected'] = rejected['attention_mask']\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d2931389284ca0aa32782988dcd2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5986 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28524e5a76e4d1ca760ba96313016fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2566 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected'],\n",
       "        num_rows: 5986\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected'],\n",
       "        num_rows: 2566\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(pre_process,\n",
    "                      remove_columns=['chosen','rejected'],)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids_chosen': [101,\n",
       "  2529,\n",
       "  1024,\n",
       "  2054,\n",
       "  2003,\n",
       "  20868,\n",
       "  17728,\n",
       "  3468,\n",
       "  6812,\n",
       "  2884,\n",
       "  8715,\n",
       "  1029,\n",
       "  3353,\n",
       "  1024,\n",
       "  20868,\n",
       "  17728,\n",
       "  3468,\n",
       "  6812,\n",
       "  2884,\n",
       "  8715,\n",
       "  1006,\n",
       "  21307,\n",
       "  2015,\n",
       "  1007,\n",
       "  2003,\n",
       "  1037,\n",
       "  11888,\n",
       "  4650,\n",
       "  2007,\n",
       "  8030,\n",
       "  2008,\n",
       "  2421,\n",
       "  21419,\n",
       "  3255,\n",
       "  1010,\n",
       "  22939,\n",
       "  12171,\n",
       "  20192,\n",
       "  1010,\n",
       "  9530,\n",
       "  16643,\n",
       "  24952,\n",
       "  2239,\n",
       "  1010,\n",
       "  1998,\n",
       "  17964,\n",
       "  1012,\n",
       "  102],\n",
       " 'attention_mask_chosen': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'input_ids_rejected': [101,\n",
       "  2529,\n",
       "  1024,\n",
       "  2054,\n",
       "  2003,\n",
       "  20868,\n",
       "  17728,\n",
       "  3468,\n",
       "  6812,\n",
       "  2884,\n",
       "  8715,\n",
       "  1029,\n",
       "  3353,\n",
       "  1024,\n",
       "  2023,\n",
       "  2003,\n",
       "  1037,\n",
       "  2691,\n",
       "  4650,\n",
       "  2008,\n",
       "  5320,\n",
       "  21419,\n",
       "  3255,\n",
       "  1998,\n",
       "  22939,\n",
       "  12171,\n",
       "  14490,\n",
       "  2050,\n",
       "  1012,\n",
       "  102],\n",
       " 'attention_mask_rejected': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Working on dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to create the dataset into chosen / rejected format\n",
    "#  ['ax', 'cola', 'mnli', 'mnli_matched', \n",
    "# 'mnli_mismatched', 'mrpc', 'qnli', 'qqp', 'rte', 'sst2', 'stsb', 'wnli']\n",
    "glue_cola = load_dataset(\"glue\", 'cola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue_cola['train'].features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "\n",
    "df = pd.read_csv('reward_trainer_feedback.csv',\n",
    "                 encoding=\"ISO-8859-1\")\n",
    "# https://stackoverflow.com/questions/19699367/for-line-in-results-in-unicodedecodeerror-utf-8-codec-cant-decode-byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tup'] = list(zip(df['answer'], df['feedback']))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping together all the answers for a given question along with its feedback\n",
    "df_g = df.groupby('question')['tup'].apply(list).reset_index()\n",
    "df_g.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g['tup'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort each group based on the feedback score\n",
    "df_g[\"sorted_tup\"] = df_g[\"tup\"].apply(lambda x :sorted(x,key=itemgetter(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer with highest feedback score is \"chosen\"\n",
    "df_g[\"chosen\"] = df_g[\"sorted_tup\"].apply(lambda x: x[-1][0])\n",
    "df_g[\"chosen_score\"] = df_g[\"sorted_tup\"].apply(lambda x: x[-1][1])\n",
    "\n",
    "# answer with highest feedback score is \"rejected\"\n",
    "df_g[\"rejected\"] = df_g[\"sorted_tup\"].apply(lambda x: x[0][0])\n",
    "df_g[\"rejected_score\"] = df_g[\"sorted_tup\"].apply(lambda x: x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = df_g.dropna()\n",
    "\n",
    "df_g = df_g[(df_g['chosen_score']>=4.0) & (df_g['rejected_score']<4.0)]\n",
    "\n",
    "df_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_used, \n",
    "                                                           id2label=id2Label,\n",
    "                                                          label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_margin(row):\n",
    "    # Assume you have a score_chosen and score_rejected columns that you want to use to compute the margin\n",
    "    return {'margin': row['chosen'] - row['rejected']}\n",
    "\n",
    "# dataset = dataset.map(add_margin)\n",
    "\n",
    "# Code adds a margin to the loss in the margin column to the dataset. \n",
    "# The reward collator will automatically pass it through and the \n",
    "# loss will be computed accordingly.\n",
    "\n",
    "# https://huggingface.co/papers/2307.09288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='/home/aicoder/training/reward_trainer/',\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    per_device_eval_batch_size=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=200,\n",
    "    save_strategy='epoch',\n",
    "    # save_steps=200,\n",
    "    num_train_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_source = inspect.getsource(RewardTrainer)\n",
    "print(reward_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aicoder/aimachine/lib/python3.10/site-packages/trl/trainer/reward_trainer.py:110: FutureWarning: Using `transformers.TrainingArguments` for `args` is deprecated and will be removed in a future version. Please use `RewardConfig` instead.\n",
      "  warnings.warn(\n",
      "/home/aicoder/aimachine/lib/python3.10/site-packages/trl/trainer/reward_trainer.py:164: UserWarning: When using RewardDataCollatorWithPadding, you should set `max_length` in RewardConfig. It will be set to `512` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "/home/aicoder/aimachine/lib/python3.10/site-packages/trl/trainer/reward_trainer.py:189: UserWarning: When using RewardDataCollatorWithPadding, you should set `remove_unused_columns=False` in your RewardConfig we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = RewardTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    # peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/aicoder/aimachine/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2663: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5986' max='5986' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5986/5986 17:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.688109</td>\n",
       "      <td>0.547935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690699</td>\n",
       "      <td>0.539361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.747400</td>\n",
       "      <td>0.686684</td>\n",
       "      <td>0.557677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.747400</td>\n",
       "      <td>0.689421</td>\n",
       "      <td>0.547545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.706600</td>\n",
       "      <td>0.702447</td>\n",
       "      <td>0.528839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.706600</td>\n",
       "      <td>0.778572</td>\n",
       "      <td>0.558846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.706600</td>\n",
       "      <td>0.727224</td>\n",
       "      <td>0.558457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.829400</td>\n",
       "      <td>0.720885</td>\n",
       "      <td>0.545207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.829400</td>\n",
       "      <td>0.838647</td>\n",
       "      <td>0.526890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.905218</td>\n",
       "      <td>0.531567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.971907</td>\n",
       "      <td>0.547545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.903965</td>\n",
       "      <td>0.551052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.959200</td>\n",
       "      <td>0.761008</td>\n",
       "      <td>0.564302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.959200</td>\n",
       "      <td>0.947560</td>\n",
       "      <td>0.554949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.879200</td>\n",
       "      <td>1.162493</td>\n",
       "      <td>0.558457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.879200</td>\n",
       "      <td>1.560378</td>\n",
       "      <td>0.560405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.879200</td>\n",
       "      <td>0.903681</td>\n",
       "      <td>0.557677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.105500</td>\n",
       "      <td>1.007082</td>\n",
       "      <td>0.546376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.105500</td>\n",
       "      <td>1.622588</td>\n",
       "      <td>0.550663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.167600</td>\n",
       "      <td>0.907819</td>\n",
       "      <td>0.555339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.167600</td>\n",
       "      <td>0.988331</td>\n",
       "      <td>0.550663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>1.167600</td>\n",
       "      <td>0.898232</td>\n",
       "      <td>0.551832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>1.021100</td>\n",
       "      <td>1.108262</td>\n",
       "      <td>0.553001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.021100</td>\n",
       "      <td>1.016842</td>\n",
       "      <td>0.560405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.034000</td>\n",
       "      <td>1.141724</td>\n",
       "      <td>0.561964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>1.034000</td>\n",
       "      <td>1.143601</td>\n",
       "      <td>0.566641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>1.034000</td>\n",
       "      <td>1.045774</td>\n",
       "      <td>0.561964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>1.174500</td>\n",
       "      <td>1.060790</td>\n",
       "      <td>0.563523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>1.174500</td>\n",
       "      <td>1.081558</td>\n",
       "      <td>0.561964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aicoder/aimachine/lib/python3.10/site-packages/trl/trainer/utils.py:547: UserWarning: There are 96 out of 2566 instances where the predictions for both options are equal. As a consequence the accuracy can be misleading.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5986, training_loss=0.9576052262000005, metrics={'train_runtime': 1065.2839, 'train_samples_per_second': 5.619, 'train_steps_per_second': 5.619, 'total_flos': 0.0, 'train_loss': 0.9576052262000005, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/aicoder/training/reward_trainer/checkpoint-5986/\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/home/aicoder/training/reward_trainer/checkpoint-5986/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_stmt = \"There is superb park in the vicinity\"\n",
    "# negative statement for test\n",
    "nega_stmt = \"This is not a very good place to spend time\"\n",
    "# non statement\n",
    "not_stmt = 'make wsork nedo theko orga fuaga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"/home/aicoder/training/reward_trainer/checkpoint-5986/\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2ForSequenceClassification\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"rejected\",\n",
       "    \"1\": \"chosen\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"chosen\": 1,\n",
       "    \"rejected\": 0\n",
       "  },\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.38.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "reward_tokenizer = AutoTokenizer.from_pretrained(\"lvwerra/distilbert-imdb\")\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\"lvwerra/distilbert-imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">DistilBertConfig <span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"_name_or_path\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"lvwerra/distilbert-imdb\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"activation\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gelu\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"architectures\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"DistilBertForSequenceClassification\"</span>\n",
       "  <span style=\"font-weight: bold\">]</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"attention_dropout\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"dim\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"dropout\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"hidden_dim\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"id2label\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"0\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"NEGATIVE\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"1\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"POSITIVE\"</span>\n",
       "  <span style=\"font-weight: bold\">}</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"initializer_range\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"label2id\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"NEGATIVE\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"POSITIVE\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "  <span style=\"font-weight: bold\">}</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"max_position_embeddings\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"model_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"distilbert\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_heads\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_layers\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"pad_token_id\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"problem_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"single_label_classification\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"qa_dropout\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"seq_classif_dropout\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"sinusoidal_pos_embds\"</span>: false,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"tie_weights_\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"torch_dtype\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"float32\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"transformers_version\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"4.38.1\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"vocab_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30522</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "DistilBertConfig \u001b[1m{\u001b[0m\n",
       "  \u001b[32m\"_name_or_path\"\u001b[0m: \u001b[32m\"lvwerra/distilbert-imdb\"\u001b[0m,\n",
       "  \u001b[32m\"activation\"\u001b[0m: \u001b[32m\"gelu\"\u001b[0m,\n",
       "  \u001b[32m\"architectures\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "    \u001b[32m\"DistilBertForSequenceClassification\"\u001b[0m\n",
       "  \u001b[1m]\u001b[0m,\n",
       "  \u001b[32m\"attention_dropout\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"dim\"\u001b[0m: \u001b[1;36m768\u001b[0m,\n",
       "  \u001b[32m\"dropout\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"hidden_dim\"\u001b[0m: \u001b[1;36m3072\u001b[0m,\n",
       "  \u001b[32m\"id2label\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"0\"\u001b[0m: \u001b[32m\"NEGATIVE\"\u001b[0m,\n",
       "    \u001b[32m\"1\"\u001b[0m: \u001b[32m\"POSITIVE\"\u001b[0m\n",
       "  \u001b[1m}\u001b[0m,\n",
       "  \u001b[32m\"initializer_range\"\u001b[0m: \u001b[1;36m0.02\u001b[0m,\n",
       "  \u001b[32m\"label2id\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"NEGATIVE\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m\"POSITIVE\"\u001b[0m: \u001b[1;36m1\u001b[0m\n",
       "  \u001b[1m}\u001b[0m,\n",
       "  \u001b[32m\"max_position_embeddings\"\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "  \u001b[32m\"model_type\"\u001b[0m: \u001b[32m\"distilbert\"\u001b[0m,\n",
       "  \u001b[32m\"n_heads\"\u001b[0m: \u001b[1;36m12\u001b[0m,\n",
       "  \u001b[32m\"n_layers\"\u001b[0m: \u001b[1;36m6\u001b[0m,\n",
       "  \u001b[32m\"pad_token_id\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "  \u001b[32m\"problem_type\"\u001b[0m: \u001b[32m\"single_label_classification\"\u001b[0m,\n",
       "  \u001b[32m\"qa_dropout\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"seq_classif_dropout\"\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "  \u001b[32m\"sinusoidal_pos_embds\"\u001b[0m: false,\n",
       "  \u001b[32m\"tie_weights_\"\u001b[0m: true,\n",
       "  \u001b[32m\"torch_dtype\"\u001b[0m: \u001b[32m\"float32\"\u001b[0m,\n",
       "  \u001b[32m\"transformers_version\"\u001b[0m: \u001b[32m\"4.38.1\"\u001b[0m,\n",
       "  \u001b[32m\"vocab_size\"\u001b[0m: \u001b[1;36m30522\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(reward_model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.3027, -3.1987]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_stmt = tokenizer(testing_stmt, return_tensors='pt')\n",
    "reward_output = model(**tokenized_stmt)\n",
    "reward_output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.5104, -4.2697]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_stmt = tokenizer(nega_stmt, return_tensors='pt')\n",
    "reward_output = model(**tokenized_stmt)\n",
    "reward_output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0852, -3.0673]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_stmt = tokenizer(not_stmt, return_tensors='pt')\n",
    "reward_output = model(**tokenized_stmt)\n",
    "reward_output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(task='text-classification', model=\"lvwerra/distilbert-imdb\")\n",
    "pipe(testing_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(task='text-classification', model=\"lvwerra/distilbert-imdb\")\n",
    "pipe(nega_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model1 = \"bigscience/bloomz-560m\"\n",
    "test_model2 = \"/home/aicoder/training/reward_trainer/checkpoint-2400/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "reward_cp_tokenizer = AutoTokenizer.from_pretrained(test_model2)\n",
    "reward_cp_model = AutoModelForSequenceClassification.from_pretrained(test_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">GPT2Config <span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"_name_or_path\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gpt2\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"activation_function\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gelu_new\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"architectures\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"GPT2LMHeadModel\"</span>\n",
       "  <span style=\"font-weight: bold\">]</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"attn_pdrop\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"bos_token_id\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50256</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"embd_pdrop\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"eos_token_id\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50256</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"initializer_range\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"layer_norm_epsilon\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"model_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gpt2\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_ctx\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_embd\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_head\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_inner\"</span>: null,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_layer\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_positions\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"reorder_and_upcast_attn\"</span>: false,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"resid_pdrop\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"scale_attn_by_inverse_layer_idx\"</span>: false,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"scale_attn_weights\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_activation\"</span>: null,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_first_dropout\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_proj_to_labels\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"cls_index\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_use_proj\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"task_specific_params\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"text-generation\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"do_sample\"</span>: true,\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"max_length\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "  <span style=\"font-weight: bold\">}</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"transformers_version\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"4.38.1\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"use_cache\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"vocab_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50257</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "GPT2Config \u001b[1m{\u001b[0m\n",
       "  \u001b[32m\"_name_or_path\"\u001b[0m: \u001b[32m\"gpt2\"\u001b[0m,\n",
       "  \u001b[32m\"activation_function\"\u001b[0m: \u001b[32m\"gelu_new\"\u001b[0m,\n",
       "  \u001b[32m\"architectures\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "    \u001b[32m\"GPT2LMHeadModel\"\u001b[0m\n",
       "  \u001b[1m]\u001b[0m,\n",
       "  \u001b[32m\"attn_pdrop\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"bos_token_id\"\u001b[0m: \u001b[1;36m50256\u001b[0m,\n",
       "  \u001b[32m\"embd_pdrop\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"eos_token_id\"\u001b[0m: \u001b[1;36m50256\u001b[0m,\n",
       "  \u001b[32m\"initializer_range\"\u001b[0m: \u001b[1;36m0.02\u001b[0m,\n",
       "  \u001b[32m\"layer_norm_epsilon\"\u001b[0m: \u001b[1;36m1e-05\u001b[0m,\n",
       "  \u001b[32m\"model_type\"\u001b[0m: \u001b[32m\"gpt2\"\u001b[0m,\n",
       "  \u001b[32m\"n_ctx\"\u001b[0m: \u001b[1;36m1024\u001b[0m,\n",
       "  \u001b[32m\"n_embd\"\u001b[0m: \u001b[1;36m768\u001b[0m,\n",
       "  \u001b[32m\"n_head\"\u001b[0m: \u001b[1;36m12\u001b[0m,\n",
       "  \u001b[32m\"n_inner\"\u001b[0m: null,\n",
       "  \u001b[32m\"n_layer\"\u001b[0m: \u001b[1;36m12\u001b[0m,\n",
       "  \u001b[32m\"n_positions\"\u001b[0m: \u001b[1;36m1024\u001b[0m,\n",
       "  \u001b[32m\"reorder_and_upcast_attn\"\u001b[0m: false,\n",
       "  \u001b[32m\"resid_pdrop\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"scale_attn_by_inverse_layer_idx\"\u001b[0m: false,\n",
       "  \u001b[32m\"scale_attn_weights\"\u001b[0m: true,\n",
       "  \u001b[32m\"summary_activation\"\u001b[0m: null,\n",
       "  \u001b[32m\"summary_first_dropout\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"summary_proj_to_labels\"\u001b[0m: true,\n",
       "  \u001b[32m\"summary_type\"\u001b[0m: \u001b[32m\"cls_index\"\u001b[0m,\n",
       "  \u001b[32m\"summary_use_proj\"\u001b[0m: true,\n",
       "  \u001b[32m\"task_specific_params\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"text-generation\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "      \u001b[32m\"do_sample\"\u001b[0m: true,\n",
       "      \u001b[32m\"max_length\"\u001b[0m: \u001b[1;36m50\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "  \u001b[1m}\u001b[0m,\n",
       "  \u001b[32m\"transformers_version\"\u001b[0m: \u001b[32m\"4.38.1\"\u001b[0m,\n",
       "  \u001b[32m\"use_cache\"\u001b[0m: true,\n",
       "  \u001b[32m\"vocab_size\"\u001b[0m: \u001b[1;36m50257\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(reward_cp_model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'LABEL_0', 1: 'LABEL_1'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_cp_model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9391, 2.3142]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_stmt = reward_cp_tokenizer(testing_stmt, return_tensors='pt')\n",
    "reward_output = reward_cp_model(**tokenized_stmt)\n",
    "reward_output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6312, 2.7609]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_stmt = reward_cp_tokenizer(nega_stmt, return_tensors='pt')\n",
    "reward_output = reward_cp_model(**tokenized_stmt)\n",
    "reward_output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6594, 3.8369]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_stmt = reward_cp_tokenizer(not_stmt, return_tensors='pt')\n",
    "reward_output = reward_cp_model(**tokenized_stmt)\n",
    "reward_output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipe = pipeline(task='text-classification', model=test_model2)\n",
    "pipe(not_stmt)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
