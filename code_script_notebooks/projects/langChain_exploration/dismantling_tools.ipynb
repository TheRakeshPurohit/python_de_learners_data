{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets dismantle the tools\n",
    "\n",
    "Tools are interfaces that an agent can use to interact with the world.\n",
    "\n",
    "> The name of the tool\n",
    "\n",
    "> A description of what the tool is\n",
    "\n",
    "> JSON schema of what the inputs to the tool are\n",
    "\n",
    "> The function to call\n",
    "\n",
    "> Whether the result of a tool should be returned directly to the user\n",
    "\n",
    "To dismantle and understand the tools, we need to learn how agents are integrating with Agents. Lets dive into Tools First\n",
    "\n",
    "pip install langchain langchain-openai beautifulsoup4 wikipedia langchainhub langserve[all] langchain-community python-dotenv tavily-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community import (\n",
    "    tools,\n",
    "    agent_toolkits,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AINAppOps',\n",
       " 'AINOwnerOps',\n",
       " 'AINRuleOps',\n",
       " 'AINTransfer',\n",
       " 'AINValueOps',\n",
       " 'AIPluginTool',\n",
       " 'APIOperation',\n",
       " 'ArxivQueryRun',\n",
       " 'AzureCogsFormRecognizerTool',\n",
       " 'AzureCogsImageAnalysisTool',\n",
       " 'AzureCogsSpeech2TextTool',\n",
       " 'AzureCogsText2SpeechTool',\n",
       " 'AzureCogsTextAnalyticsHealthTool',\n",
       " 'BaseGraphQLTool',\n",
       " 'BaseRequestsTool',\n",
       " 'BaseSQLDatabaseTool',\n",
       " 'BaseSparkSQLTool',\n",
       " 'BaseTool',\n",
       " 'BearlyInterpreterTool',\n",
       " 'BingSearchResults',\n",
       " 'BingSearchRun',\n",
       " 'BraveSearch',\n",
       " 'ClickTool',\n",
       " 'CogniswitchKnowledgeRequest',\n",
       " 'CogniswitchKnowledgeSourceFile',\n",
       " 'CogniswitchKnowledgeSourceURL',\n",
       " 'CogniswitchKnowledgeStatus',\n",
       " 'ConneryAction',\n",
       " 'CopyFileTool',\n",
       " 'CurrentWebPageTool',\n",
       " 'DeleteFileTool',\n",
       " 'DuckDuckGoSearchResults',\n",
       " 'DuckDuckGoSearchRun',\n",
       " 'E2BDataAnalysisTool',\n",
       " 'EdenAiExplicitImageTool',\n",
       " 'EdenAiObjectDetectionTool',\n",
       " 'EdenAiParsingIDTool',\n",
       " 'EdenAiParsingInvoiceTool',\n",
       " 'EdenAiSpeechToTextTool',\n",
       " 'EdenAiTextModerationTool',\n",
       " 'EdenAiTextToSpeechTool',\n",
       " 'EdenaiTool',\n",
       " 'ElevenLabsText2SpeechTool',\n",
       " 'ExtractHyperlinksTool',\n",
       " 'ExtractTextTool',\n",
       " 'FileSearchTool',\n",
       " 'GetElementsTool',\n",
       " 'GmailCreateDraft',\n",
       " 'GmailGetMessage',\n",
       " 'GmailGetThread',\n",
       " 'GmailSearch',\n",
       " 'GmailSendMessage',\n",
       " 'GoogleCloudTextToSpeechTool',\n",
       " 'GooglePlacesTool',\n",
       " 'GoogleSearchResults',\n",
       " 'GoogleSearchRun',\n",
       " 'GoogleSerperResults',\n",
       " 'GoogleSerperRun',\n",
       " 'HumanInputRun',\n",
       " 'IFTTTWebhook',\n",
       " 'InfoPowerBITool',\n",
       " 'InfoSQLDatabaseTool',\n",
       " 'InfoSparkSQLTool',\n",
       " 'JiraAction',\n",
       " 'JsonGetValueTool',\n",
       " 'JsonListKeysTool',\n",
       " 'ListDirectoryTool',\n",
       " 'ListPowerBITool',\n",
       " 'ListSQLDatabaseTool',\n",
       " 'ListSparkSQLTool',\n",
       " 'MerriamWebsterQueryRun',\n",
       " 'MetaphorSearchResults',\n",
       " 'MoveFileTool',\n",
       " 'NasaAction',\n",
       " 'NavigateBackTool',\n",
       " 'NavigateTool',\n",
       " 'O365CreateDraftMessage',\n",
       " 'O365SearchEmails',\n",
       " 'O365SearchEvents',\n",
       " 'O365SendEvent',\n",
       " 'O365SendMessage',\n",
       " 'OpenAPISpec',\n",
       " 'OpenWeatherMapQueryRun',\n",
       " 'PolygonAggregates',\n",
       " 'PolygonFinancials',\n",
       " 'PolygonLastQuote',\n",
       " 'PolygonTickerNews',\n",
       " 'PubmedQueryRun',\n",
       " 'QueryCheckerTool',\n",
       " 'QueryPowerBITool',\n",
       " 'QuerySQLCheckerTool',\n",
       " 'QuerySQLDataBaseTool',\n",
       " 'QuerySparkSQLTool',\n",
       " 'ReadFileTool',\n",
       " 'RedditSearchRun',\n",
       " 'RedditSearchSchema',\n",
       " 'RequestsDeleteTool',\n",
       " 'RequestsGetTool',\n",
       " 'RequestsPatchTool',\n",
       " 'RequestsPostTool',\n",
       " 'RequestsPutTool',\n",
       " 'SceneXplainTool',\n",
       " 'SearchAPIResults',\n",
       " 'SearchAPIRun',\n",
       " 'SearxSearchResults',\n",
       " 'SearxSearchRun',\n",
       " 'ShellTool',\n",
       " 'SlackGetChannel',\n",
       " 'SlackGetMessage',\n",
       " 'SlackScheduleMessage',\n",
       " 'SlackSendMessage',\n",
       " 'SleepTool',\n",
       " 'StackExchangeTool',\n",
       " 'StdInInquireTool',\n",
       " 'SteamWebAPIQueryRun',\n",
       " 'SteamshipImageGenerationTool',\n",
       " 'StructuredTool',\n",
       " 'Tool',\n",
       " 'VectorStoreQATool',\n",
       " 'VectorStoreQAWithSourcesTool',\n",
       " 'WikipediaQueryRun',\n",
       " 'WolframAlphaQueryRun',\n",
       " 'WriteFileTool',\n",
       " 'YahooFinanceNewsTool',\n",
       " 'YouSearchTool',\n",
       " 'YouTubeSearchTool',\n",
       " 'ZapierNLAListActions',\n",
       " 'ZapierNLARunAction',\n",
       " 'authenticate',\n",
       " 'format_tool_to_openai_function',\n",
       " 'tool']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.__all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tools.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AINetworkToolkit',\n",
       " 'AmadeusToolkit',\n",
       " 'AzureCognitiveServicesToolkit',\n",
       " 'CogniswitchToolkit',\n",
       " 'ConneryToolkit',\n",
       " 'FileManagementToolkit',\n",
       " 'GmailToolkit',\n",
       " 'JiraToolkit',\n",
       " 'JsonToolkit',\n",
       " 'MultionToolkit',\n",
       " 'NLAToolkit',\n",
       " 'NasaToolkit',\n",
       " 'O365Toolkit',\n",
       " 'OpenAPIToolkit',\n",
       " 'PlayWrightBrowserToolkit',\n",
       " 'PolygonToolkit',\n",
       " 'PowerBIToolkit',\n",
       " 'SQLDatabaseToolkit',\n",
       " 'SlackToolkit',\n",
       " 'SparkSQLToolkit',\n",
       " 'SteamToolkit',\n",
       " 'ZapierToolkit',\n",
       " 'create_json_agent',\n",
       " 'create_openapi_agent',\n",
       " 'create_pbi_agent',\n",
       " 'create_pbi_chat_agent',\n",
       " 'create_spark_sql_agent',\n",
       " 'create_sql_agent']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_toolkits.__all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent_toolkits.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import (\n",
    "    WikipediaQueryRun,\n",
    ")\n",
    "from langchain_community.utilities import (\n",
    "    WikipediaAPIWrapper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class WikipediaQueryRun(BaseTool):\n",
      "    \"\"\"Tool that searches the Wikipedia API.\"\"\"\n",
      "\n",
      "    name: str = \"wikipedia\"\n",
      "    description: str = (\n",
      "        \"A wrapper around Wikipedia. \"\n",
      "        \"Useful for when you need to answer general questions about \"\n",
      "        \"people, places, companies, facts, historical events, or other subjects. \"\n",
      "        \"Input should be a search query.\"\n",
      "    )\n",
      "    api_wrapper: WikipediaAPIWrapper\n",
      "\n",
      "    def _run(\n",
      "        self,\n",
      "        query: str,\n",
      "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
      "    ) -> str:\n",
      "        \"\"\"Use the Wikipedia tool.\"\"\"\n",
      "        return self.api_wrapper.run(query)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from inspect import getsource\n",
    "print(getsource(WikipediaQueryRun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class WikipediaAPIWrapper(BaseModel):\n",
      "    \"\"\"Wrapper around WikipediaAPI.\n",
      "\n",
      "    To use, you should have the ``wikipedia`` python package installed.\n",
      "    This wrapper will use the Wikipedia API to conduct searches and\n",
      "    fetch page summaries. By default, it will return the page summaries\n",
      "    of the top-k results.\n",
      "    It limits the Document content by doc_content_chars_max.\n",
      "    \"\"\"\n",
      "\n",
      "    wiki_client: Any  #: :meta private:\n",
      "    top_k_results: int = 3\n",
      "    lang: str = \"en\"\n",
      "    load_all_available_meta: bool = False\n",
      "    doc_content_chars_max: int = 4000\n",
      "\n",
      "    @root_validator()\n",
      "    def validate_environment(cls, values: Dict) -> Dict:\n",
      "        \"\"\"Validate that the python package exists in environment.\"\"\"\n",
      "        try:\n",
      "            import wikipedia\n",
      "\n",
      "            wikipedia.set_lang(values[\"lang\"])\n",
      "            values[\"wiki_client\"] = wikipedia\n",
      "        except ImportError:\n",
      "            raise ImportError(\n",
      "                \"Could not import wikipedia python package. \"\n",
      "                \"Please install it with `pip install wikipedia`.\"\n",
      "            )\n",
      "        return values\n",
      "\n",
      "    def run(self, query: str) -> str:\n",
      "        \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
      "        page_titles = self.wiki_client.search(\n",
      "            query[:WIKIPEDIA_MAX_QUERY_LENGTH], results=self.top_k_results\n",
      "        )\n",
      "        summaries = []\n",
      "        for page_title in page_titles[: self.top_k_results]:\n",
      "            if wiki_page := self._fetch_page(page_title):\n",
      "                if summary := self._formatted_page_summary(page_title, wiki_page):\n",
      "                    summaries.append(summary)\n",
      "        if not summaries:\n",
      "            return \"No good Wikipedia Search Result was found\"\n",
      "        return \"\\n\\n\".join(summaries)[: self.doc_content_chars_max]\n",
      "\n",
      "    @staticmethod\n",
      "    def _formatted_page_summary(page_title: str, wiki_page: Any) -> Optional[str]:\n",
      "        return f\"Page: {page_title}\\nSummary: {wiki_page.summary}\"\n",
      "\n",
      "    def _page_to_document(self, page_title: str, wiki_page: Any) -> Document:\n",
      "        main_meta = {\n",
      "            \"title\": page_title,\n",
      "            \"summary\": wiki_page.summary,\n",
      "            \"source\": wiki_page.url,\n",
      "        }\n",
      "        add_meta = (\n",
      "            {\n",
      "                \"categories\": wiki_page.categories,\n",
      "                \"page_url\": wiki_page.url,\n",
      "                \"image_urls\": wiki_page.images,\n",
      "                \"related_titles\": wiki_page.links,\n",
      "                \"parent_id\": wiki_page.parent_id,\n",
      "                \"references\": wiki_page.references,\n",
      "                \"revision_id\": wiki_page.revision_id,\n",
      "                \"sections\": wiki_page.sections,\n",
      "            }\n",
      "            if self.load_all_available_meta\n",
      "            else {}\n",
      "        )\n",
      "        doc = Document(\n",
      "            page_content=wiki_page.content[: self.doc_content_chars_max],\n",
      "            metadata={\n",
      "                **main_meta,\n",
      "                **add_meta,\n",
      "            },\n",
      "        )\n",
      "        return doc\n",
      "\n",
      "    def _fetch_page(self, page: str) -> Optional[str]:\n",
      "        try:\n",
      "            return self.wiki_client.page(title=page, auto_suggest=False)\n",
      "        except (\n",
      "            self.wiki_client.exceptions.PageError,\n",
      "            self.wiki_client.exceptions.DisambiguationError,\n",
      "        ):\n",
      "            return None\n",
      "\n",
      "    def load(self, query: str) -> List[Document]:\n",
      "        \"\"\"\n",
      "        Run Wikipedia search and get the article text plus the meta information.\n",
      "        See\n",
      "\n",
      "        Returns: a list of documents.\n",
      "\n",
      "        \"\"\"\n",
      "        return list(self.lazy_load(query))\n",
      "\n",
      "    def lazy_load(self, query: str) -> Iterator[Document]:\n",
      "        \"\"\"\n",
      "        Run Wikipedia search and get the article text plus the meta information.\n",
      "        See\n",
      "\n",
      "        Returns: a list of documents.\n",
      "\n",
      "        \"\"\"\n",
      "        page_titles = self.wiki_client.search(\n",
      "            query[:WIKIPEDIA_MAX_QUERY_LENGTH], results=self.top_k_results\n",
      "        )\n",
      "        for page_title in page_titles[: self.top_k_results]:\n",
      "            if wiki_page := self._fetch_page(page_title):\n",
      "                if doc := self._page_to_document(page_title, wiki_page):\n",
      "                    yield doc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(getsource(WikipediaAPIWrapper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_client = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=150)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n",
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "False\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(wiki_tool.name)\n",
    "print(wiki_tool.description)\n",
    "print(wiki_tool.return_direct)\n",
    "print(wiki_tool.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tempVids\\onlylc\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file d:\\tempVids\\onlylc\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No good Wikipedia Search Result was found'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.run(\"Interstellar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents can wield tools, and these can be custom built also\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"lookup results online\"\"\"\n",
    "    return 'This is search return'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> str:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n",
      "search(query: str) -> str - lookup results online\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(search.name)\n",
    "print(search.description)\n",
    "print(search.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is search return'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub-classing BaseTool\n",
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description='A number to get product')\n",
    "    b: int = Field(description='Another number to get product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCalculatorTool(BaseTool):\n",
    "    name = \"calculator\"\n",
    "    description = \"useful class that helps in math calculations\"\n",
    "    args_schema = CalculatorInput\n",
    "    return_direct = True\n",
    "\n",
    "    def _run(self, a, b, run_manager):\n",
    "        \"\"\"Use the tool\"\"\"\n",
    "        return a * b\n",
    "    \n",
    "    async def _arun(self, a, b, run_manager):\n",
    "        \"\"\"Use the tool only Asynchronously\"\"\"\n",
    "        raise NotImplementedError(\"Calc doesnt support Async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_calc = CustomCalculatorTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculator\n",
      "useful class that helps in math calculations\n",
      "{'a': {'title': 'A'}, 'b': {'title': 'B'}}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(cust_calc.name)\n",
    "print(cust_calc.description)\n",
    "print(cust_calc.args)\n",
    "print(cust_calc.return_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a function and make it to tool using structured tool\n",
    "\n",
    "def make_name(fname):\n",
    "    return f\"my_file_{fname}.json\"\n",
    "\n",
    "\n",
    "name_tool = StructuredTool.from_function(\n",
    "    func=make_name,\n",
    "    name=\"Make filename\",\n",
    "    description=\"Tool that makes a file name\",\n",
    "    handle_tool_error=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_file_SuperNice.json'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_tool.run(tool_input='SuperNice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"D:\\\\gitFolders\\\\python_de_learners_data\\\\.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "import os\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo',\n",
    "                 api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x000001E764A1B290> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001E7649EE050> openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'make_name',\n",
       " 'description': '',\n",
       " 'parameters': {'type': 'object', 'properties': {}, 'required': ['fname']}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "openai_nametool = convert_to_openai_function(make_name)\n",
    "openai_nametool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'wikipedia',\n",
       " 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.',\n",
       " 'parameters': {'properties': {'__arg1': {'title': '__arg1',\n",
       "    'type': 'string'}},\n",
       "  'required': ['__arg1'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_openai = convert_to_openai_function(wiki_tool)\n",
    "wiki_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "message = llm.invoke([HumanMessage(\"Get wiki results\")],\n",
    "                     functions=[wiki_openai])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text,id='a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Rainbow Toes Co.', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 22, 'total_tokens': 28}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diving into Agents\n",
    "\n",
    "AgentAction: Represents Action to be taken, with a tool and tool_input property\n",
    "\n",
    "AgentFinish: Represents final results from an agent, contain return_values (dict) which contains 'output' key\n",
    "\n",
    "Intermediate Steps: Represents 'Prev actions' & corresponding outputs from this Current Agent Run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent : Is a Chain \n",
    "\n",
    "LLM --> Prompt --> Output Parser\n",
    "\n",
    "AgentInput: KV mapping which requires 'Intermediate_steps' key\n",
    "\n",
    "AgentOutput: Next Action to take or Final Outputs to send to User (AgentAction, \n",
    "AgentFinish)\n",
    "\n",
    "Main thing affects Agent is the prompting strategy used\n",
    "\n",
    "The goal of the OpenAI tools APIs is to more reliably return valid and useful function calls than what can be done using a generic text completion or chat API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tavily_search_results_json'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://science.nasa.gov/moon/facts/',\n",
       "  'content': \"Water on the Moon\\nDuring the initial exploration of the Moon, and the analysis of all the returned samples from the Apollo and the Luna missions, we thought that the surface of the Moon was dry.\\n Discover More Topics From NASA\\nSun\\nPlanets\\nAsteroids, Comets & Meteors\\nKuiper Belt\\nThe National Aeronautics and Space Administration\\nNASA explores the unknown in air and space, innovates for the benefit of humanity, and inspires the world through discovery.\\n While you were there, you'd notice that the gravity on the surface of the Moon is one-sixth of Earth's, which is why in footage of moonwalks, astronauts appear to almost bounce across the surface.\\n Missions such as Lunar Prospector, LCROSS, and Lunar Reconnaissance Orbiter, have not only shown that the surface of the Moon has global hydration but there are actually high concentrations of ice water in the permanently shadowed regions of the lunar poles.\\n The discovery that the Moon harbors water ice, and that the highest concentrations occur within darkened craters at the poles, makes the Moon a little more hospitable for future human colonists.\\n\"}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].run(tool_input=\"Where is moon\",\n",
    "             color='yellow',\n",
    "             run_name='tester')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "myagent = create_openai_tools_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myagent.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RunnableSequence'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myagent.get_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(nodes={'7ca6493e1020495b9d23ab454f3ef663': Node(id='7ca6493e1020495b9d23ab454f3ef663', data=<class 'pydantic.v1.main.RunnableParallel<agent_scratchpad>Input'>), '8c27ce82eb1241eda4913011b29bebb9': Node(id='8c27ce82eb1241eda4913011b29bebb9', data=<class 'pydantic.v1.main.RunnableParallel<agent_scratchpad>Output'>), 'e316ff9aeb5c4ce382b128e32ce46371': Node(id='e316ff9aeb5c4ce382b128e32ce46371', data=RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))), '5429921429aa47f28434cf5c839f30b9': Node(id='5429921429aa47f28434cf5c839f30b9', data=RunnablePassthrough()), '913c40c7eaee428f984db3bb358bda2f': Node(id='913c40c7eaee428f984db3bb358bda2f', data=ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])), 'c35789b6bc75491d943aab92eea574bf': Node(id='c35789b6bc75491d943aab92eea574bf', data=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001B9DA0FA390>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001B9DA105550>, openai_api_key=SecretStr('**********'), openai_proxy='')), 'bb45907e13584f21825fa44d99547d18': Node(id='bb45907e13584f21825fa44d99547d18', data=OpenAIToolsAgentOutputParser()), 'f757fb4a55f24eeba73dc3f4b73232b3': Node(id='f757fb4a55f24eeba73dc3f4b73232b3', data=<class 'pydantic.v1.main.OpenAIToolsAgentOutputParserOutput'>)}, edges=[Edge(source='7ca6493e1020495b9d23ab454f3ef663', target='e316ff9aeb5c4ce382b128e32ce46371', data=None), Edge(source='e316ff9aeb5c4ce382b128e32ce46371', target='8c27ce82eb1241eda4913011b29bebb9', data=None), Edge(source='7ca6493e1020495b9d23ab454f3ef663', target='5429921429aa47f28434cf5c839f30b9', data=None), Edge(source='5429921429aa47f28434cf5c839f30b9', target='8c27ce82eb1241eda4913011b29bebb9', data=None), Edge(source='8c27ce82eb1241eda4913011b29bebb9', target='913c40c7eaee428f984db3bb358bda2f', data=None), Edge(source='913c40c7eaee428f984db3bb358bda2f', target='c35789b6bc75491d943aab92eea574bf', data=None), Edge(source='bb45907e13584f21825fa44d99547d18', target='f757fb4a55f24eeba73dc3f4b73232b3', data=None), Edge(source='c35789b6bc75491d943aab92eea574bf', target='bb45907e13584f21825fa44d99547d18', data=None)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myagent.get_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc_hub_owner': 'hwchase17',\n",
       " 'lc_hub_repo': 'openai-tools-agent',\n",
       " 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myagent.get_prompts()[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myagent.get_prompts()[0].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['langchain', 'schema', 'runnable', 'RunnableSequence']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myagent.lc_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_execution_env = AgentExecutor(agent=myagent,\n",
    "                                    tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_execution_env.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TavilySearchResults(max_results=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_execution_env.lookup_tool('tavily_search_results_json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_execution_env.agent.save('newagent.agent')\n",
    "# agent_execution_env.save_agent('newagent.agent')\n",
    "# agent_execution_env.update_forward_refs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.agents.agent.AgentExecutor"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(agent_execution_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'next near earth comet arrival date'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.space.com/comet-coming-2024-could-be-bright', 'content': 'Such ices vaporize far from the sun, giving a distant comet a short-lived surge in brightness that in turn, raises unrealistic expectations.\\nAlready been \"around the block\"\\nIf, on the other hand, the latest calculations showed that Tsuchinshan–ATLAS was traveling in an elliptical orbit and returning to the sun from the distant past, its coating of highly volatile materials would have already been shed, and what we are now seeing is the true underlying level of activity. More likely a dud\\nUnfortunately, it would seem more likely that Tsuchinshan–ATLAS, like Kohoutek and other comets with a similar lineage (Cunningham in 1940-41, Austin in 1990 and ISON in 2013), could ultimately fizzle, because it is a \"new\" comet coming out of the Oort cloud, the spherical shell surrounding the rest of the solar system that consists of pieces of icy space debris that be as large as mountains. What we will ultimately see depends on many variables — the comet\\'s orbit, the relative locations of the comet, Earth and sun, and of course the size and composition of that icy clumping of solar system rubble that forms the comet\\'s nucleus, usually only a few kilometers across. In the spring of 1957, Comet Arend-Roland was a first-timer that turned out to be quite spectacular, becoming as bright as first magnitude and shedding a tail as long as 30 degrees and in addition, also producing a tail directed toward the sun measuring 15 degrees in length.\\n If Comet Tsuchinshan–ATLAS lives up to its most optimistic expectations, it should put on its best show in 2024, between Oct. 12 — when it will pass closest to Earth at a distance of 44 million miles (71 million km) — and Oct. 19, when it will appear low in the west-southwest evening sky from 1 to 3 hours after sunset.'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe next near-Earth comet, Comet Tsuchinshan–ATLAS, is expected to pass closest to Earth at a distance of 44 million miles (71 million km) between October 12 and October 19, 2024. If it lives up to its most optimistic expectations, it should put on its best show during this time. You can read more about it [here](https://www.space.com/comet-coming-2024-could-be-bright).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'When will the next near earth comet will arrive',\n",
       " 'output': 'The next near-Earth comet, Comet Tsuchinshan–ATLAS, is expected to pass closest to Earth at a distance of 44 million miles (71 million km) between October 12 and October 19, 2024. If it lives up to its most optimistic expectations, it should put on its best show during this time. You can read more about it [here](https://www.space.com/comet-coming-2024-could-be-bright).'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The AgentExecutor class doesn't have invoke method, so where is the invoke coming into picture\n",
    "# if you follow with invoke method below, it will go to lc/chains/base.py /Chain class\n",
    "# The above Chain class is ABC, so need to find which kind of agent_chain is working when calling AgentExecutor\n",
    "# The AgentExecutor itself is completely abstracted out, and trying to understand where it is origin was a challenge\n",
    "# Decided to use the VsCode search option\n",
    "# Then located the below \"Invoking: \" inside the openai_tools.py and openai_multi_agent/base.py\n",
    "# format_scratchpad/log_to_messages.py contains the implementation of agent_scratchpad\n",
    "\n",
    "agent_execution_env.invoke({\"input\": \"When will the next near earth comet will arrive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TavilySearchResults(max_results=1)]\n"
     ]
    }
   ],
   "source": [
    "print(agent_execution_env.tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agent_scratchpad', 'input', 'tools']\n",
      "{'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'xml-agent-convo', 'lc_hub_commit_hash': '00f6b7470fa25a24eef6e4e3c1e44ba07189f3e91c4d987223ad232490673be8'}\n",
      "You are a helpful assistant. Help the user answer any questions.\n",
      "\n",
      "You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "In order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\n",
      "For example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n",
      "\n",
      "<tool>search</tool><tool_input>weather in SF</tool_input>\n",
      "<observation>64 degrees</observation>\n",
      "\n",
      "When you are done, respond with a final answer between <final_answer></final_answer>. For example:\n",
      "\n",
      "<final_answer>The weather in SF is 64 degrees</final_answer>\n",
      "\n",
      "Begin!\n",
      "\n",
      "Previous Conversation:\n",
      "{chat_history}\n",
      "\n",
      "Question: {input}\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "xml_prompt = hub.pull(\"hwchase17/xml-agent-convo\")\n",
    "print(xml_prompt.input_variables)\n",
    "print(xml_prompt.metadata)\n",
    "print(xml_prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agent_scratchpad', 'input', 'tool_names', 'tools']\n",
      "{'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react-chat-json', 'lc_hub_commit_hash': '9c1258e8aa8ce33bebbd62e077c143d0b06c81f3c7de732187ee61c70c1254c7'}\n",
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n"
     ]
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "jsonprompt = hub.pull(\"hwchase17/react-chat-json\")\n",
    "print(jsonprompt.input_variables)\n",
    "print(jsonprompt.metadata)\n",
    "print(jsonprompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input'] input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]} partial_variables={'tools': 'tavily_search_results_json: A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'tool_names': 'tavily_search_results_json'} metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react-chat-json', 'lc_hub_commit_hash': '9c1258e8aa8ce33bebbd62e077c143d0b06c81f3c7de732187ee61c70c1254c7'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'tool_names', 'tools'], template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n{tools}\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string, \\\\ The action to take. Must be one of {tool_names}\\n    \"action_input\": string \\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_json_chat_agent\n",
    "\n",
    "json_agent = create_json_chat_agent(llm, tools, jsonprompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=json_agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"tavily_search_results_json\",\n",
      "    \"action_input\": \"LangChain\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://en.wikipedia.org/wiki/LangChain', 'content': 'In October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[6] to store and retrieve vector embeddings; Weaviate vector database[7] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered popularity, with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project\\'s Discord server, many YouTube tutorials, and meetups in San Francisco and London. As of April 2023, it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal links[edit]'}]\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"LangChain is a deployment tool introduced in October 2023 that facilitates the transition from LCEL prototypes to production-ready applications. It includes integrations with various systems such as cloud storage services, API wrappers for news, movie information, and weather, Bash for summarization and execution of shell scripts, web scraping subsystems, few-shot learning prompt generation support, and more. LangChain was launched in October 2022 as an open source project and quickly gained popularity, with significant contributions and funding. It is used for document analysis and summarization, chatbots, and code analysis.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is LangChain?',\n",
       " 'output': 'LangChain is a deployment tool introduced in October 2023 that facilitates the transition from LCEL prototypes to production-ready applications. It includes integrations with various systems such as cloud storage services, API wrappers for news, movie information, and weather, Bash for summarization and execution of shell scripts, web scraping subsystems, few-shot learning prompt generation support, and more. LangChain was launched in October 2022 as an open source project and quickly gained popularity, with significant contributions and funding. It is used for document analysis and summarization, chatbots, and code analysis.'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "structured_prompt = hub.pull(\"hwchase17/structured-chat-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
      "\n",
      "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
      "\n",
      "Provide only ONE action per $JSON_BLOB, as shown:\n",
      "\n",
      "```\n",
      "{{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}}\n",
      "```\n",
      "\n",
      "Follow this format:\n",
      "\n",
      "Question: input question to answer\n",
      "Thought: consider previous and subsequent steps\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: action result\n",
      "... (repeat Thought/Action/Observation N times)\n",
      "Thought: I know what to respond\n",
      "Action:\n",
      "```\n",
      "{{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Final response to human\"\n",
      "}}\n",
      "\n",
      "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\n"
     ]
    }
   ],
   "source": [
    "print(structured_prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "react_prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(react_prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "agent = create_react_agent(llm, tools, react_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'tools': 'tavily_search_results_json: A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'tool_names': 'tavily_search_results_json'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001E764A1B290>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001E7649EE050>, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'stop': ['\\nObservation']})\n",
       "| ReActSingleInputOutputParser()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "get_word_length.invoke(\"abc\")\n",
    "\n",
    "tools = [get_word_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but don't know current events\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save(\"testing_save.agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't ice creams ever get stressed?\\n\\nBecause they always know how to chill out!\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-4\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'StrOutputParserInput',\n",
       " 'anyOf': [{'type': 'string'},\n",
       "  {'$ref': '#/definitions/AIMessage'},\n",
       "  {'$ref': '#/definitions/HumanMessage'},\n",
       "  {'$ref': '#/definitions/ChatMessage'},\n",
       "  {'$ref': '#/definitions/SystemMessage'},\n",
       "  {'$ref': '#/definitions/FunctionMessage'},\n",
       "  {'$ref': '#/definitions/ToolMessage'}],\n",
       " 'definitions': {'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'Message from an AI.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'Message from a human.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'Message for priming AI behavior, usually passed in as the first of a sequence\\nof input messages.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'Message for passing the result of executing a function back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id']}}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatOpenAIInput',\n",
       " 'anyOf': [{'type': 'string'},\n",
       "  {'$ref': '#/definitions/StringPromptValue'},\n",
       "  {'$ref': '#/definitions/ChatPromptValueConcrete'},\n",
       "  {'type': 'array',\n",
       "   'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "     {'$ref': '#/definitions/HumanMessage'},\n",
       "     {'$ref': '#/definitions/ChatMessage'},\n",
       "     {'$ref': '#/definitions/SystemMessage'},\n",
       "     {'$ref': '#/definitions/FunctionMessage'},\n",
       "     {'$ref': '#/definitions/ToolMessage'}]}}],\n",
       " 'definitions': {'StringPromptValue': {'title': 'StringPromptValue',\n",
       "   'description': 'String prompt value.',\n",
       "   'type': 'object',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'StringPromptValue',\n",
       "     'enum': ['StringPromptValue'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['text']},\n",
       "  'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'Message from an AI.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'Message from a human.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'Message for priming AI behavior, usually passed in as the first of a sequence\\nof input messages.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'Message for passing the result of executing a function back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id']},\n",
       "  'ChatPromptValueConcrete': {'title': 'ChatPromptValueConcrete',\n",
       "   'description': 'Chat prompt value which explicitly lists out the message types it accepts.\\nFor use in external schemas.',\n",
       "   'type': 'object',\n",
       "   'properties': {'messages': {'title': 'Messages',\n",
       "     'type': 'array',\n",
       "     'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "       {'$ref': '#/definitions/HumanMessage'},\n",
       "       {'$ref': '#/definitions/ChatMessage'},\n",
       "       {'$ref': '#/definitions/SystemMessage'},\n",
       "       {'$ref': '#/definitions/FunctionMessage'},\n",
       "       {'$ref': '#/definitions/ToolMessage'}]}},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ChatPromptValueConcrete',\n",
       "     'enum': ['ChatPromptValueConcrete'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['messages']}}}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'StrOutputParserOutput', 'type': 'string'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.output_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatOpenAIOutput',\n",
       " 'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "  {'$ref': '#/definitions/HumanMessage'},\n",
       "  {'$ref': '#/definitions/ChatMessage'},\n",
       "  {'$ref': '#/definitions/SystemMessage'},\n",
       "  {'$ref': '#/definitions/FunctionMessage'},\n",
       "  {'$ref': '#/definitions/ToolMessage'}],\n",
       " 'definitions': {'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'Message from an AI.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'Message from a human.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'Message for priming AI behavior, usually passed in as the first of a sequence\\nof input messages.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'Message for passing the result of executing a function back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id']}}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_schema.schema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localpreter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
