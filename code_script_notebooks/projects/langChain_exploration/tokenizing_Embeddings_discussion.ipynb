{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZH9AFhTOzFz"
      },
      "outputs": [],
      "source": [
        "!pip -q install huggingface chromadb transformers langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install InstructorEmbedding"
      ],
      "metadata": {
        "id": "l-Y7soQDSSeu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a611bfb2-d55d-4b4f-d563-5f304d5b265a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting InstructorEmbedding\n",
            "  Downloading InstructorEmbedding-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: InstructorEmbedding\n",
            "Successfully installed InstructorEmbedding-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "OYAoWNlJPB-j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceInstructEmbeddings"
      ],
      "metadata": {
        "id": "y-wf6eSePB8T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
        "\n",
        "The base Embedding class in LangChain exposes two methods: embed_documents and embed_query. The largest difference is that these two methods have different interfaces: one works over multiple documents, while the other works over a single document. Besides this, another reason for having these as two separate methods is that some embedding providers have different embedding methods for documents (to be searched over) vs queries (the search query itself)."
      ],
      "metadata": {
        "id": "EuimeBBeP3xI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hfEmbed = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "id": "iE0bT8plPB6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hfEmbed.model_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gqQ9yqS3Ww6E",
        "outputId": "5916a979-5c45-4733-b3df-1543318e9872"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sentence-transformers/all-mpnet-base-v2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hfInstructEmbed = HuggingFaceInstructEmbeddings(\n",
        " query_instruction=\"Represent the query for retrieval: \"   \n",
        ")"
      ],
      "metadata": {
        "id": "oM5drg0zPB4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hfInstructEmbed.model_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gCRGIl-7W2Q7",
        "outputId": "7c92e750-e256-4c31-91a9-b650f823fb72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hkunlp/instructor-large'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is a test document.\""
      ],
      "metadata": {
        "id": "zWNxTOdLPB1N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_result = hfEmbed.embed_query(text)"
      ],
      "metadata": {
        "id": "_M8aJZjfPBwt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_result"
      ],
      "metadata": {
        "id": "UgvxbGQ1PBp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_result = hfEmbed.embed_documents([text])"
      ],
      "metadata": {
        "id": "StRXFfkwTWqo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_result"
      ],
      "metadata": {
        "id": "SA_9mLLrTWhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instructor_result = hfInstructEmbed.embed_query(text)"
      ],
      "metadata": {
        "id": "E6701d0sTWXJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instructor_result"
      ],
      "metadata": {
        "id": "wzRLRZsDUIo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader"
      ],
      "metadata": {
        "id": "HHq65TfaUImf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spaceLoad = TextLoader('/content/linux_play.txt')"
      ],
      "metadata": {
        "id": "gEYiQXy_UIjs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "59uwvszoUIiA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = spaceLoad.load()"
      ],
      "metadata": {
        "id": "CXBzs9jhVwHj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "PMDMUc-r6N-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plainCharSplitter = CharacterTextSplitter(separator='\\n\\n',\n",
        "                                          chunk_size=500,\n",
        "                                          chunk_overlap=0,\n",
        "                                          length_function=len)"
      ],
      "metadata": {
        "id": "xI-SU-cl-Qmu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hfCharSplitter = CharacterTextSplitter.from_huggingface_tokenizer(tokenizer, \n",
        "                                                                  chunk_size=100,\n",
        "                                                                  chunk_overlap=0)"
      ],
      "metadata": {
        "id": "LeXn2OPS8Kmw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "recurSplitter = RecursiveCharacterTextSplitter(chunk_size=100,\n",
        "                                               chunk_overlap=20,\n",
        "                                               length_function=len)"
      ],
      "metadata": {
        "id": "wwSkdV5J8M1Z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plain_docs = plainCharSplitter.split_documents(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqrTafwo-k59",
        "outputId": "cfa4ca0c-b916-4ce5-bafb-0a5eb628250c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Created a chunk of size 1137, which is longer than the specified 500\n",
            "WARNING:root:Created a chunk of size 1181, which is longer than the specified 500\n",
            "WARNING:root:Created a chunk of size 1231, which is longer than the specified 500\n",
            "WARNING:root:Created a chunk of size 1789, which is longer than the specified 500\n",
            "WARNING:root:Created a chunk of size 532, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plain_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS2rP2Vp-rqv",
        "outputId": "39429b20-dd35-4474-a9ea-e7ff3677d4a5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='BEGIN;\\nLinux Playbook\\n\\nThe command and scenarios has to be executed inside the\\nKali Docker image. The docker image is called linux_playg.\\nThe docker will be contain the\\nset of set of files, prepared for this plabook and\\nuploaded on to dockerhub.', metadata={'source': '/content/linux_play.txt'})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_documents = hfCharSplitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "hLTs-jCob0lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_documents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ki8wrIN9ZwE",
        "outputId": "b94cfd46-15ec-4f9d-f964-1efd37348da1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='BEGIN;\\nLinux Playbook\\n\\nThe command and scenarios has to be executed inside the\\nKali Docker image. The docker image is called linux_playg.\\nThe docker will be contain the\\nset of set of files, prepared for this plabook and\\nuploaded on to dockerhub.', metadata={'source': '/content/linux_play.txt'})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/linux_play.txt') as lin:\n",
        "  txt_lin = lin.read()\n",
        "\n",
        "recurse_documents = recurSplitter.create_documents([txt_lin])"
      ],
      "metadata": {
        "id": "N7C1ZxlV9D0O"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recurse_documents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9DeCMcn9dAO",
        "outputId": "2d61d474-e789-49f9-9e17-222d2ffc2a15"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='BEGIN;\\nLinux Playbook', metadata={})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now work on embedding"
      ],
      "metadata": {
        "id": "gt8mfh9S-yA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hfEmbed_recurse = hfEmbed.embed_query(\"BEGIN;\\nLinux Playbook\")"
      ],
      "metadata": {
        "id": "6LfLyXVP-5RP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hfEmbed_recurse"
      ],
      "metadata": {
        "id": "FbxgaM4P-5Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hfEmbed_charSplit = hfEmbed.embed_query(\"BEGIN;\\nLinux Playbook\\n\\nThe command and scenarios has to be executed inside the\\nKali Docker image. The docker image is called linux_playg.\\nThe docker will be contain the\\nset of set of files, prepared for this plabook and\\nuploaded on to dockerhub.\")"
      ],
      "metadata": {
        "id": "QKfe_ATC-4_m"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hfEmbed_charSplit"
      ],
      "metadata": {
        "id": "BgDoB299-4nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Try for the plain here"
      ],
      "metadata": {
        "id": "368bjTxn_v3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "\n",
        "plain_directory = 'plain_db'\n",
        "\n",
        "plain_chroma = Chroma.from_documents(documents=plain_docs,\n",
        "                                     embeddings=hfEmbed,\n",
        "                                     persist_directory=plain_directory)"
      ],
      "metadata": {
        "id": "n7RkHpb4UIYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "\n",
        "charSplit_directory = 'charSplit_db'\n",
        "\n",
        "plain_chroma = Chroma.from_documents(documents=char_documents,\n",
        "                                     embeddings=hfEmbed,\n",
        "                                     persist_directory=charSplit_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRcQOM6OAgr3",
        "outputId": "c44ab76f-22b6-4370-ebf9-292292bde978"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: charSplit_db\n",
            "WARNING:chromadb.api.models.Collection:No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "\n",
        "recurse_directory = 'recurse_db'\n",
        "\n",
        "recurse_chroma = Chroma.from_documents(documents=recurse_documents,\n",
        "                                     embeddings=hfEmbed,\n",
        "                                     persist_directory=recurse_directory)"
      ],
      "metadata": {
        "id": "Us5fceNYUISu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ce72b01-ff9d-4407-cba4-9c8726be0c5f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: recurse_db\n",
            "WARNING:chromadb.api.models.Collection:No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FtuawpFWaRJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yXTfk7rZaRAu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}