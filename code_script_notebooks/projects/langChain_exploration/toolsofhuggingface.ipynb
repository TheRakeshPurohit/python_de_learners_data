{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PMUYb_0WMVT"
      },
      "outputs": [],
      "source": [
        "!pip -q install transformers sentence_transformers\n",
        "!pip -q install huggingface_hub langchain\n",
        "!pip -q install configparser\n",
        "!pip -q install google-search-results openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import configparser\n",
        "\n",
        "data = configparser.ConfigParser()\n",
        "data.read_file(open('/content/apidata.config'))"
      ],
      "metadata": {
        "id": "V7INMG_6XQnT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = data[\"OPENAI\"][\"HFREAD\"]\n",
        "os.environ['SERPAPI_API_KEY'] = data[\"OPENAI\"][\"SERPAPI_KEY\"]\n",
        "os.environ['OPENAI_API_KEY'] = data[\"OPENAI\"][\"KEY\"]"
      ],
      "metadata": {
        "id": "JqYJf-5qXRh7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, HuggingFaceHub, LLMChain"
      ],
      "metadata": {
        "id": "gQcOMl8CYFJf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Classify the Sentence: {sentence}\n",
        "Answer: The classification is.\"\"\"\n",
        "\n",
        "prompt_sbs = PromptTemplate(template=template, input_variables=[\"sentence\"])"
      ],
      "metadata": {
        "id": "PwR8pZPUYGo_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "text_gen = pipeline('text-generation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvCKfzPAD73w",
        "outputId": "e1c995e9-758a-423d-e253-95c49854b8f3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_classifier = HuggingFacePipeline(pipeline=text_gen)"
      ],
      "metadata": {
        "id": "KjCxuPcvEkam"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import things that are needed generically\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import LLMMathChain, SerpAPIWrapper"
      ],
      "metadata": {
        "id": "ga0NnA1HYHH0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support_llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "RH1k3k17GIe9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_func = SerpAPIWrapper()\n",
        "classifier_chain = LLMChain(llm=llm_classifier,prompt=prompt_sbs, \n",
        "                              verbose=True)"
      ],
      "metadata": {
        "id": "quRmkX6PYHOU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Google Search\",\n",
        "        func=search_func.run,\n",
        "        description=\"useful for when you need to answer questions about current events\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"Classifier\",\n",
        "         func=classifier_chain.run,\n",
        "         description=\"useful for when you need to Classify the sentences\"\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "r0cdGeUeZdKT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Creating Custom Tools using python function"
      ],
      "metadata": {
        "id": "YE5HV0p8hRmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_classifier = initialize_agent(tools,support_llm,\n",
        "                            agent='zero-shot-react-description',\n",
        "                            verbose=True)"
      ],
      "metadata": {
        "id": "XhGBVMnghRZJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_classifier.run(\"\"\"Get the recent news on World Economic forum. And classify it as positive or \n",
        "negative\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "67fce5a7-e73c-4b6c-9bcc-9d732f93ff55",
        "id": "JF4H7mFIlKmm"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find recent news and then classify it\n",
            "Action: Google Search\n",
            "Action Input: Recent news on World Economic Forum\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPress releases · From AI Researchers to TV Producers: Discover the Young Global Leaders Class of 2023 · World Economic Forum's Blue Food Partnership Launches ...\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to classify the news\n",
            "Action: Classifier\n",
            "Action Input: Press releases · From AI Researchers to TV Producers: Discover the Young Global Leaders Class of 2023 · World Economic Forum's Blue Food Partnership Launches ...\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mClassify the Sentence: Press releases · From AI Researchers to TV Producers: Discover the Young Global Leaders Class of 2023 · World Economic Forum's Blue Food Partnership Launches ...\n",
            "Answer: The classification is.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "So you just made it\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The news on World Economic Forum is positive.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The news on World Economic Forum is positive.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import tool\n",
        "\n",
        "### The function below returns the length of the queries\n",
        "\n",
        "\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "\n",
        "@tool(\"classifier\",return_direct=True)\n",
        "def classify_query(sentence: str) -> str:\n",
        "    \"\"\"Classifies the sentence.\"\"\"\n",
        "    reply = classifier(sentence)    \n",
        "    return reply[0]['label']"
      ],
      "metadata": {
        "id": "Cmdj2Uu7oyhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d583839-ec1a-45c9-be28-ff3e1f99fd23"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classify_query.run(\"I am super fond of that fruit.\")"
      ],
      "metadata": {
        "id": "bmtsBPKDoydp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9bd6a62e-1603-4f06-e97e-3f2cecfb8ca7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools_01 = [\n",
        "    Tool(\n",
        "        name = \"Google Search\",\n",
        "        func=search_func.run,\n",
        "        description=\"useful for when you need to answer questions about current events\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"Classifier\",\n",
        "         func=classify_query.run,\n",
        "         description=\"useful for when you need to Classify the sentences\"\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "D4G69YX_oyVZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_classifier = initialize_agent(tools_01,support_llm,\n",
        "                            agent='zero-shot-react-description',\n",
        "                            verbose=True)"
      ],
      "metadata": {
        "id": "9_JMIWqDMBW3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_classifier.run(\"\"\"Get the recent news on World Economic forum. And classify it as positive or \n",
        "negative\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "OkY9mCtaMBNC",
        "outputId": "78e5e716-52c9-42bf-90d3-90d2947d6897"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find recent news and then classify it\n",
            "Action: Google Search\n",
            "Action Input: Recent news on World Economic Forum\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPress releases · From AI Researchers to TV Producers: Discover the Young Global Leaders Class of 2023 · World Economic Forum's Blue Food Partnership Launches ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to classify the news\n",
            "Action: Classifier\n",
            "Action Input: Press releases · From AI Researchers to TV Producers: Discover the Young Global Leaders Class of 2023 · World Economic Forum's Blue Food Partnership Launches ...\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mPOSITIVE\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The recent news on World Economic Forum is classified as positive.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The recent news on World Economic Forum is classified as positive.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}