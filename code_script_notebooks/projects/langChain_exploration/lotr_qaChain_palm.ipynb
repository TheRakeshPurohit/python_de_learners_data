{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzCF__oCm1bJ"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain openai faiss-cpu google-generativeai sentence-transformers > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2duN4Dwm51g"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.tools import BaseTool\n",
        "from langchain import LLMMathChain, SerpAPIWrapper\n",
        "from langchain.llms import GooglePalm\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6oMQ_UzDkMz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY']='AIzaSyDvs4J9m-QiedPM-WAXC4RZpDBTY9Ckn_4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydAQ606nlRZt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import date\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.embeddings import GooglePalmEmbeddings\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhWlOMWRnm5B"
      },
      "outputs": [],
      "source": [
        "chatllm = GooglePalm(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z12cUo1DkNP"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAwvqMPcDkNQ"
      },
      "outputs": [],
      "source": [
        "embeddings = GooglePalmEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thingsnotstrings = \"\"\"\n",
        "https://blog.google/products/search/introducing-knowledge-graph-things-not/\n",
        "Search is a lot about discovery—the basic human need to learn and broaden your horizons. But searching still requires a lot of hard work by you, the user. So today I’m really excited to launch the Knowledge Graph, which will help you discover new information quickly and easily.\n",
        "Take a query like [taj mahal]. For more than four decades, search has essentially been about matching keywords to queries. To a search engine the words [taj mahal] have been just that—two words.\n",
        "But we all know that [taj mahal] has a much richer meaning. You might think of one of the world’s most beautiful monuments, or a Grammy Award-winning musician, or possibly even a casino in Atlantic City, NJ. Or, depending on when you last ate, the nearest Indian restaurant. It’s why we’ve been working on an intelligent model—in geek-speak, a “graph”—that understands real-world entities and their relationships to one another: things, not strings.\n",
        "The Knowledge Graph enables you to search for things, people or places that Google knows about—landmarks, celebrities, cities, sports teams, buildings, geographical features, movies, celestial objects, works of art and more—and instantly get information that’s relevant to your query. This is a critical first step towards building the next generation of search, which taps into the collective intelligence of the web and understands the world a bit more like people do.\n",
        "Google’s Knowledge Graph isn’t just rooted in public sources such as Freebase, Wikipedia and the CIA World Factbook. It’s also augmented at a much larger scale—because we’re focused on comprehensive breadth and depth. It currently contains more than 500 million objects, as well as more than 3.5 billion facts about and relationships between these different objects. And it’s tuned based on what people search for, and what we find out on the web.\n",
        "The Knowledge Graph enhances Google Search in three main ways to start:\n",
        "1. Find the right thing\n",
        "Language can be ambiguous—do you mean Taj Mahal the monument, or Taj Mahal the musician? Now Google understands the difference, and can narrow your search results just to the one you mean—just click on one of the links to see that particular slice of results:\n",
        "Taj Mahal\n",
        "This is one way the Knowledge Graph makes Google Search more intelligent—your results are more relevant because we understand these entities, and the nuances in their meaning, the way you do.\n",
        "2. Get the best summary\n",
        "With the Knowledge Graph, Google can better understand your query, so we can summarize relevant content around that topic, including key facts you’re likely to need for that particular thing. For example, if you’re looking for Marie Curie, you’ll see when she was born and died, but you’ll also get details on her education and scientific discoveries:\n",
        "Marie Curie\n",
        "How do we know which facts are most likely to be needed for each item? For that, we go back to our users and study in aggregate what they’ve been asking Google about each item. For example, people are interested in knowing what books Charles Dickens wrote, whereas they’re less interested in what books Frank Lloyd Wright wrote, and more in what buildings he designed.\n",
        "The Knowledge Graph also helps us understand the relationships between things. Marie Curie is a person in the Knowledge Graph, and she had two children, one of whom also won a Nobel Prize, as well as a husband, Pierre Curie, who claimed a third Nobel Prize for the family. All of these are linked in our graph. It’s not just a catalog of objects; it also models all these inter-relationships. It’s the intelligence between these different entities that’s the key.\n",
        "3. Go deeper and broader\n",
        "Finally, the part that’s the most fun of all—the Knowledge Graph can help you make some unexpected discoveries. You might learn a new fact or new connection that prompts a whole new line of inquiry. Do you know where Matt Groening, the creator of the Simpsons (one of my all-time favorite shows), got the idea for Homer, Marge and Lisa’s names? It’s a bit of a surprise:\n",
        "Matt Groening\n",
        "We’ve always believed that the perfect search engine should understand exactly what you mean and give you back exactly what you want. And we can now sometimes help answer your next question before you’ve asked it, because the facts we show are informed by what other people have searched for. For example, the information we show for Tom Cruise answers 37 percent of next queries that people ask about him. In fact, some of the most serendipitous discoveries I’ve made using the Knowledge Graph are through the magical “People also search for” feature. One of my favorite books is The White Tiger, the debut novel by Aravind Adiga, which won the prestigious Man Booker Prize. Using the Knowledge Graph, I discovered three other books that had won the same prize and one that won the Pulitzer. I can tell you, this suggestion was spot on!\n",
        "We’ve begun to gradually roll out this view of the Knowledge Graph to U.S. English users. It’s also going to be available on smartphones and tablets—read more about how we’ve tailored this to mobile devices. And watch our video (also available on our site about the Knowledge Graph) that gives a deeper dive into the details and technology, in the words of people who've worked on this project:\n",
        "We hope this added intelligence will give you a more complete picture of your interest, provide smarter search results, and pique your curiosity on new topics. We’re proud of our first baby step—the Knowledge Graph—which will enable us to make search more intelligent, moving us closer to the \"Star Trek computer\" that I've always dreamt of building. Enjoy your lifelong journey of discovery, made easier by Google Search, so you can spend less time searching and more time doing what you love.\"\"\""
      ],
      "metadata": {
        "id": "3p1cWSv9FWwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atlasdocs=\"\"\"How Atlas Works\n",
        "Atlas is a platform for visually and programmatically interacting with massive unstructured datasets of text documents, images and embeddings.\n",
        "Data model\n",
        "Atlas lets you store and manipulate data like a standard noSQL document engine. On upload, your data is stored in an abstraction called a Project. You can add, update, read and delete (CRUD) data in a project via API calls from the Atlas Python client.\n",
        "What kind of data can I store in Atlas?\n",
        "Atlas can natively store:\n",
        "    Embedding vectors\n",
        "    Text Documents\n",
        "Our roadmap includes first class support for data modalities such as images, audio and video. You can still store images, audio and video in Atlas now but you must generate embeddings for it yourself.\n",
        "Data stored in an Atlas Project is semantically indexed by Atlas. This indexing allows you to interact, view and search through your dataset via meaning instead of matching on words.\n",
        "How does Atlas semantically index data?\n",
        "Atlas semantically indexes unstructured data by:\n",
        "    Converting data points into embedding vectors (if they aren't embeddings already)\n",
        "    Organizing the embedding vectors for fast semantic search and human interpretability\n",
        "If you have embedding vectors of your data from an embedding API such as OpenAI or Cohere, you can attach them during upload.\n",
        "If you don't already have embedding vectors for your data points, Atlas will create them by running your data through neural networks that semantically encode your data points. For example, if you upload text documents Atlas will run them through neural networks that semantically encode text. It is often cheaper and faster to use Atlas' internal embedding models as opposed to an external model APIs.\n",
        "How is Atlas different from a noSQL database?\n",
        "Unlike existing data stores, Atlas is built with embedding vectors as first class citizens. Embedding vectors are representations of data that computers can semantically manipulate. Most operations you do in Atlas, under the hood, are performed on embeddings.\n",
        "Atlas makes embeddings human interpretable\n",
        "Despite their utility, embeddings cannot be easily interpreted because they reside in high dimensions.\n",
        "During indexing, Atlas builds a contextual two-dimensional data map of embeddings. This map preserves high-dimensional relationships present between embeddings in a two-dimensional, human interpretable view.\n",
        "Reading an Atlas Map\n",
        "Atlas Maps lay out your dataset contextually. We will use the above map of news articles generated by Atlas to describe how to read Maps.\n",
        "An Atlas Map has the following properties:\n",
        "    Points close to each other on the map are semantically similar/related. For example, all news articles about sports are at the bottom of the map. Inside the sports region, the map breaks down by type of sport because news articles about a fixed sport (e.g. baseball) have more similarity to each other than with news articles about other types of sports (e.g. tennis).\n",
        "    Relative distances between points correlate with semantic relatedness but the numerical distance between 2D point positions does not have meaning. For example, the observation that the Tennis and Golf news article clusters are adjacent signify a relationships between Tennis and Golf in the embedding space. You should not, however, make claims or draw conclusions using the Euclidean distance between points in the two clusters. Distance information is only meaningful in the ambient embedding space and can be retrieved with vector_search.\n",
        "    Floating labels correspond to distinct topics in your data. For example, the Golf cluster has the label 'Ryder Cup'. Labels are automatically determined from the textual contents of your data and are crucial for navigating the Map.\n",
        "    Topics have a hierarchy. As you zoom around the Map, more granular versions of topics will emerge.\n",
        "    Maps update as your data updates. When new data enters your project, Atlas can reindex the map to reflect how the new data relates to existing data.\n",
        "All information and operations that are visually presented on an Atlas map have a programmatic analog. For example, you can access topic information and vector search through the Python client.\n",
        "Technical Details\n",
        "Atlas visualizes your embeddings in two-dimensions using a non-linear dimensionality reduction algorithm. Atlas' dimensionality reduction algorithm is custom-built for scale, speed and dynamic updates. Nomic cannot share the technical details of the algorithm at this time.\n",
        "Data Formats and Integrity\n",
        "Atlas stores and transfers data using a subset of the Apache Arrow standard.\n",
        "pyarrow is used to convert python, pandas, and numpy data types to Arrow types; you can also pass any Arrow table (created by polars, duckdb, pyarrow, etc.) directly to Atlas and the types will be automatically converted.\n",
        "Before being uploaded, all data is converted with the following rules:\n",
        "    Strings are converted to Arrow strings and stored as UTF-8.\n",
        "    Integers are converted to 32-bit integers. (In the case that you have larger integers, they are probably either IDs, in which case you should convert them to strings; or they are a field that you want perform analysis on, in which case you should convert them to floats.)\n",
        "    Floats are converted to 32-bit (single-precision) floats.\n",
        "    Embeddings, regardless of precision, are uploaded as 16-bit (half-precision) floats, and stored in Arrow as FixedSizeList.\n",
        "    All dates and datetimes are converted to Arrow timestamps with millisecond precision and no time zone. (If you have a use case that requires timezone information or micro/nanosecond precision, please let us know.)\n",
        "    Categorical types (called 'dictionary' in Arrow) are supported, but values stored as categorical must be strings.\n",
        "Other data types (including booleans, binary, lists, and structs) are not supported. Values stored as a dictionary must be strings.\n",
        "All fields besides embeddings and the user-specified ID field are nullable\"\"\""
      ],
      "metadata": {
        "id": "MAO2b8KLFknc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ43N7ZlDkNR"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitFunc = RecursiveCharacterTextSplitter(separators='\\n',\n",
        "                                           chunk_size=50,\n",
        "                                           chunk_overlap=10,\n",
        "                                           length_function=len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu4TA1MoDkNS",
        "outputId": "b90abb56-b260-4086-d707-f00e8e81308f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "splitTnS = splitFunc.create_documents(texts=[thingsnotstrings])\n",
        "len(splitTnS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitAD = splitFunc.create_documents(texts=[atlasdocs])\n",
        "len(splitAD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oArUBfi7IzTR",
        "outputId": "64d96302-82d9-4693-8431-08beb207a6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 3 diff embeddings.\n",
        "embeddings1 = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "embeddings2 = HuggingFaceEmbeddings(model_name=\"multi-qa-MiniLM-L6-dot-v1\")"
      ],
      "metadata": {
        "id": "5iyHv2-RLHiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xa19IZ_o_Gt"
      },
      "outputs": [],
      "source": [
        "dataTnS = FAISS.from_documents(documents=splitTnS,\n",
        "                               embedding=embeddings1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataAD = FAISS.from_documents(documents=splitAD,\n",
        "                               embedding=embeddings2)"
      ],
      "metadata": {
        "id": "X_mNcwrBJSvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataTnS.save_local(\"tns\")"
      ],
      "metadata": {
        "id": "SYrlDpxEJWoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataAD.save_local(\"AD\")"
      ],
      "metadata": {
        "id": "UirkPBgYJbRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r tns.zip /content/tns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYix65AbJgOI",
        "outputId": "1376b5cc-e5d9-4709-b886-7777f741feda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/tns/ (stored 0%)\n",
            "  adding: content/tns/index.pkl (deflated 52%)\n",
            "  adding: content/tns/index.faiss (deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r AD.zip /content/AD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIu4H4AMKGz2",
        "outputId": "02d2b34b-c10d-4b3e-865d-35fe042cbc20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/AD/ (stored 0%)\n",
            "  adding: content/AD/index.pkl (deflated 56%)\n",
            "  adding: content/AD/index.faiss (deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwDxTpP1DkNU"
      },
      "outputs": [],
      "source": [
        "retriever_tns = dataTnS.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 5,\n",
        "                   \"include_metadata\": False})\n",
        "\n",
        "retriever_ad = dataAD.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 5,\n",
        "                   \"include_metadata\": False})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DSwwAqODkNV"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.merger_retriever import MergerRetriever\n",
        "from langchain.document_transformers import EmbeddingsRedundantFilter\n",
        "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
        "from langchain.retrievers import ContextualCompressionRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcmMNFtdDkNW"
      },
      "outputs": [],
      "source": [
        "lotr = MergerRetriever(retrievers=[retriever_tns,\n",
        "                                   retriever_ad])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VbvO1RLDkNX"
      },
      "outputs": [],
      "source": [
        "# We can remove redundant results from both retrievers using yet another embedding.\n",
        "# Using multiples embeddings in diff steps could help reduce biases.\n",
        "filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
        "\n",
        "pipeline = DocumentCompressorPipeline(transformers=[filter])\n",
        "\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=pipeline, base_retriever=lotr\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OQq6fCpgDkNY"
      },
      "outputs": [],
      "source": [
        "query = \"Explain about embeddings\"\n",
        "\n",
        "compression_retriever.get_relevant_documents(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ahMXQeiHm8CM"
      },
      "outputs": [],
      "source": [
        "qa_endpoint = RetrievalQA.from_chain_type(llm=chatllm,\n",
        "                                          chain_type='stuff',\n",
        "                                          retriever=compression_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TshTlwPpn_at"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"User question: {question}\n",
        "\n",
        "possible Answer: Provide the best answer refering to the context.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template,\n",
        "                        input_variables=[\"question\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt,\n",
        "                     llm=GooglePalm(temperature=0),\n",
        "                     verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svMB30F7DkNf",
        "outputId": "706378b9-82d8-40bd-eb8b-9f300eaa394f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUser question: Explain about embeddings\n",
            "\n",
            "possible Answer: Provide the best answer refering to the context.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Explain about embeddings',\n",
              " 'text': 'Embeddings are a way of representing words or phrases in a vector space, where the distance between two vectors corresponds to the semantic similarity of the words or phrases. This allows for more efficient and effective natural language processing tasks, such as machine translation, question answering, and sentiment analysis.'}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "llm_chain(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnTiZuGLm8Je",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34db815f-9d49-4e87-f174-073fbac00ce1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Explain about embeddings',\n",
              " 'result': 'Embedding vectors are representations of data that computers can semantically manipulate.'}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "qa_endpoint(query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = \"What are knowledge graphs?\"\n",
        "llm_chain(query1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhTOihQ_OYxp",
        "outputId": "b94c49a3-fd48-4298-8624-ff2f0c4ee914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUser question: What are knowledge graphs?\n",
            "\n",
            "possible Answer: Provide the best answer refering to the context.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What are knowledge graphs?', 'text': 'a semantic network'}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_endpoint(query1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V81Knz2dOdl7",
        "outputId": "e9053625-2d75-4aa2-d2b6-288e653a6e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What are knowledge graphs?',\n",
              " 'result': 'Knowledge graphs are semantic models of the world that represent entities and their relationships.'}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAh-K2D4m8Of",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d385b145-1be2-4bac-915a-91bc87d73090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUser question: What is difference between knowledge graph and embedding\n",
            "\n",
            "possible Answer: Provide the best answer refering to the context.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What is difference between knowledge graph and embedding',\n",
              " 'text': 'Knowledge graphs are structured representations of information, while embeddings are vector representations of information.'}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "query2 = \"What is difference between knowledge graph and embedding\"\n",
        "llm_chain(query2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqUTHZ1Bp97Z",
        "outputId": "091065dc-6336-402c-9783-45dceae36891"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What is difference between knowledge graph and embedding',\n",
              " 'result': 'Knowledge graph is a structured data model that represents entities and their relationships. Embedding is a vector representation of data that can be used for semantic search and other tasks.'}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "qa_endpoint(query2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "8JQNExWNtGRd"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\",\n",
        "                                  return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_withmemory = ConversationalRetrievalChain.from_llm(chatllm,\n",
        "                                           compression_retriever,\n",
        "                                           memory=memory)"
      ],
      "metadata": {
        "id": "m7AZUNHoQNMQ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_withmemory(query)"
      ],
      "metadata": {
        "id": "pZeWak2bQNJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2c6e22-2464-4952-8e75-7470001f5557"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Explain about embeddings',\n",
              " 'chat_history': [HumanMessage(content='Explain about embeddings', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='Embedding vectors are representations of data that computers can semantically manipulate.', additional_kwargs={}, example=False)],\n",
              " 'answer': 'Embedding vectors are representations of data that computers can semantically manipulate.'}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_withmemory(query1)"
      ],
      "metadata": {
        "id": "OKmTunQ-QNF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2854987-5dbf-470b-9b20-4cbc40229dbd"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What are knowledge graphs?',\n",
              " 'chat_history': [HumanMessage(content='Explain about embeddings', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='Embedding vectors are representations of data that computers can semantically manipulate.', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='What are knowledge graphs?', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='Knowledge graphs are semantic models of the world that represent entities and their relationships.', additional_kwargs={}, example=False)],\n",
              " 'answer': 'Knowledge graphs are semantic models of the world that represent entities and their relationships.'}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_withmemory(query2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSHv_6VtWTK2",
        "outputId": "96a82094-29a5-485c-da9b-ca72f01ed5a6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What is difference between knowledge graph and embedding',\n",
              " 'chat_history': [HumanMessage(content='Explain about embeddings', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='Embedding vectors are representations of data that computers can semantically manipulate.', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='What are knowledge graphs?', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='Knowledge graphs are semantic models of the world that represent entities and their relationships.', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='What is difference between knowledge graph and embedding', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='A knowledge graph is a structured representation of information, while an embedding is a vector representation of data.', additional_kwargs={}, example=False)],\n",
              " 'answer': 'A knowledge graph is a structured representation of information, while an embedding is a vector representation of data.'}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query3= 'Summarize our discussion'\n",
        "\n",
        "qa_withmemory(query3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "simCZA-JWVvL",
        "outputId": "c204fd9c-c091-4a34-96ab-defa7178a95f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Summarize our discussion',\n",
              " 'chat_history': [HumanMessage(content='Explain about embeddings', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='Embedding vectors are representations of data that computers can semantically manipulate.', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='What are knowledge graphs?', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='Knowledge graphs are semantic models of the world that represent entities and their relationships.', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='What is difference between knowledge graph and embedding', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='A knowledge graph is a structured representation of information, while an embedding is a vector representation of data.', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='Summarize our discussion', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='The assistant explained to the human that embeddings are vector representations of words or phrases that can be used to understand the relationships between them. The assistant then showed the human how to use the Knowledge Graph to search for information about a topic and how to explore the relationships between different entities.', additional_kwargs={}, example=False)],\n",
              " 'answer': 'The assistant explained to the human that embeddings are vector representations of words or phrases that can be used to understand the relationships between them. The assistant then showed the human how to use the Knowledge Graph to search for information about a topic and how to explore the relationships between different entities.'}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fMBvWZQ2W-M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BottM_TEW-Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0sP7V_ugW-Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tj_X3a-HW96T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}