{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Install Package"
      ],
      "metadata": {
        "id": "nhKRx0RNeOvu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Hu74s0OdmQ3"
      },
      "outputs": [],
      "source": [
        "!pip install ctransformers langchain transformers huggingface_hub > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Model"
      ],
      "metadata": {
        "id": "d-jpwEUReVSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ctransformers import AutoModelForCausalLM\n",
        "from langchain.llms import CTransformers\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "llm = AutoModelForCausalLM.from_pretrained('marella/gpt-2-ggml')"
      ],
      "metadata": {
        "id": "dU_8RrFueeYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate Text"
      ],
      "metadata": {
        "id": "4HwKRsrfeokq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm('How to create json file from python dictionaries?')"
      ],
      "metadata": {
        "id": "SPxxmNb1eptT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = CTransformers(model='marella/gpt-2-ggml', \n",
        "                    callbacks=[StreamingStdOutCallbackHandler()])"
      ],
      "metadata": {
        "id": "sT2XRwh_2EU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm('AI is going to')"
      ],
      "metadata": {
        "id": "9j4NaLAw2tiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "response = llm_chain.run('Why will AI takeover our jobs?')"
      ],
      "metadata": {
        "id": "ln-hHnuF2tfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin"
      ],
      "metadata": {
        "id": "cS-4XaJx2taA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = CTransformers(model='/content/ggml-gpt4all-j-v1.3-groovy.bin',\n",
        "                    model_type='gptj', \n",
        "                    callbacks=[StreamingStdOutCallbackHandler()])"
      ],
      "metadata": {
        "id": "JiN0TR8D3vrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UJcgisQs3voQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lwn1n4SY3vj0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}