{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZH9AFhTOzFz"
      },
      "outputs": [],
      "source": [
        "!pip -q install huggingface chromadb transformers langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install configparser"
      ],
      "metadata": {
        "id": "IpwpxxsK_suO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-J7B46l3d8s",
        "outputId": "5ba4e7ec-121e-4895-bd4c-36011857d63b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.1 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install unstructured[local-inference]"
      ],
      "metadata": {
        "id": "PtwXDltHMF9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import configparser\n",
        "\n",
        "data = configparser.ConfigParser()\n",
        "data.read_file(open('/content/apidata.config'))\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = data[\"OPENAI\"][\"HFREAD\"]\n",
        "os.environ['SERPAPI_API_KEY'] = data[\"OPENAI\"][\"SERPAPI_KEY\"]\n",
        "os.environ['OPENAI_API_KEY'] = data[\"OPENAI\"][\"KEY\"]"
      ],
      "metadata": {
        "id": "mJwBTZzeI-SX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import UnstructuredPDFLoader"
      ],
      "metadata": {
        "id": "HHq65TfaUImf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testLoad = UnstructuredPDFLoader(\"/content/test_pdf.pdf\",mode=\"elements\")"
      ],
      "metadata": {
        "id": "gEYiQXy_UIjs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = testLoad.load_and_split()"
      ],
      "metadata": {
        "id": "CXBzs9jhVwHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47818c01-ed0e-4d66-e767-358003e8cd1e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "id": "1Jf9RAL9NbjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now work on embedding"
      ],
      "metadata": {
        "id": "gt8mfh9S-yA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "\n",
        "charSplit_directory = 'charSplit_db'\n",
        "\n",
        "plain_chroma = Chroma.from_documents(documents=documents,\n",
        "                                     embeddings=OpenAIEmbeddings(),\n",
        "                                     persist_directory=charSplit_directory)"
      ],
      "metadata": {
        "id": "HRcQOM6OAgr3",
        "outputId": "e4cbb17c-ea9d-4a5c-d73b-4d3b22568b11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: charSplit_db\n",
            "WARNING:chromadb.api.models.Collection:No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Startin to use LLMs and Chains"
      ],
      "metadata": {
        "id": "1RbF4aq_8A5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains import AnalyzeDocumentChain\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "QGl3KLSq8AYI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factLLM = OpenAI(temperature=0)\n",
        "\n",
        "document_QA = RetrievalQA.from_chain_type(llm=factLLM, \n",
        "                                 chain_type=\"stuff\", \n",
        "                                 retriever=plain_chroma.as_retriever())"
      ],
      "metadata": {
        "id": "mAMM04rnb0un"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_QA.run(\"What is Langchain Library?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "zKjBTD7pcNJR",
        "outputId": "0cc8eb97-482d-4619-edd2-6bfa3bb4bf14"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' LangChain is a library that can be installed using the command \"pip install langchain\". It is designed to help with six main areas of evaluation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jL7rGIN-wE7S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}