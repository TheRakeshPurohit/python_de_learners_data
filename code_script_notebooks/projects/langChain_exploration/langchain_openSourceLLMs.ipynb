{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0RkCwXV-ZPr1"
      },
      "outputs": [],
      "source": [
        "!pip install langchain huggingface_hub > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"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\""
      ],
      "metadata": {
        "id": "sSxRNzTeAyJ7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub\n",
        "\n",
        "repo_id = \"stabilityai/stablelm-tuned-alpha-7b\" # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options\n"
      ],
      "metadata": {
        "id": "DWNWZs21Ax8a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(repo_id=repo_id, \n",
        "                     model_kwargs={\"temperature\":0, \n",
        "                                                    \"max_length\":64})"
      ],
      "metadata": {
        "id": "palmP9crBJ13"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"Your name is\")"
      ],
      "metadata": {
        "id": "fsLCa0eYBgYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "template = \"\"\"Use the given context and answer\n",
        "the question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, \n",
        "                        input_variables=[\"question\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ],
      "metadata": {
        "id": "MzynJTsGB0Hk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Where is the leaning tower? \"\n",
        "\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "id": "cR5R7rZUB0Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "camel_llm = HuggingFaceHub(repo_id=\"Writer/camel-5b-hf\", \n",
        "                     model_kwargs={\"temperature\":0, \n",
        "                                    \"max_length\":64})"
      ],
      "metadata": {
        "id": "c2ocEnhXB0AP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "camel_llm(\"You are from\")"
      ],
      "metadata": {
        "id": "ZOIA82YqBz7a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}