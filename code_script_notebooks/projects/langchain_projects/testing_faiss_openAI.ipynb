{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZH9AFhTOzFz"
      },
      "outputs": [],
      "source": [
        "!pip -q install huggingface chromadb transformers langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install configparser unstructured[local-inference]"
      ],
      "metadata": {
        "id": "IpwpxxsK_suO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai tiktoken"
      ],
      "metadata": {
        "id": "I-J7B46l3d8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import configparser\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = \"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\""
      ],
      "metadata": {
        "id": "mJwBTZzeI-SX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import UnstructuredPDFLoader"
      ],
      "metadata": {
        "id": "HHq65TfaUImf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob \n",
        "\n",
        "document = []\n",
        "\n",
        "for file in glob.glob(\"/content/*.pdf\"):\n",
        "  spaceLoad = UnstructuredPDFLoader(file, mode=\"elements\")\n",
        "  document.extend(spaceLoad.load_and_split())"
      ],
      "metadata": {
        "id": "gEYiQXy_UIjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z_yGxT4vrhXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjpHQHDjuabx",
        "outputId": "35a26796-403e-4fd0-a5cd-04bb09331b00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "MP-JU4TRrHFA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = FAISS.from_documents(document, OpenAIEmbeddings())\n",
        "\n",
        "docs = db.similarity_search(query)"
      ],
      "metadata": {
        "id": "YwESjblUzRjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL9ZT-b-rHAw",
        "outputId": "0389084c-fcf3-48e7-c70e-457554f2e18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='SELF-ASK', metadata={'source': '/content/self-ask-3-6.pdf', 'filename': '/content/self-ask-3-6.pdf', 'page_number': 3, 'category': 'Title'}),\n",
              " Document(page_content='Self-ask (depicted in Figure 3) requires a one- or few-shot prompt that demonstrates how to answer', metadata={'source': '/content/self-ask-3-6.pdf', 'filename': '/content/self-ask-3-6.pdf', 'page_number': 3, 'category': 'NarrativeText'}),\n",
              " Document(page_content='Code and data at: https://github.com/ofirpress/self-ask', metadata={'source': '/content/self-ask-1-3.pdf', 'filename': '/content/self-ask-1-3.pdf', 'page_number': 1, 'category': 'Title'}),\n",
              " Document(page_content='swering the initial question. We ﬁnally show that self-ask’s structured prompting', metadata={'source': '/content/self-ask-1-3.pdf', 'filename': '/content/self-ask-1-3.pdf', 'page_number': 1, 'category': 'NarrativeText'})]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faiss_obj = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
        "                                     chain_type=\"stuff\", \n",
        "                                     retriever=db.as_retriever())"
      ],
      "metadata": {
        "id": "dkehHZknrG-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faiss_obj.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ixLYbCfwutue",
        "outputId": "4085fc22-7514-4ce9-e2f2-7c16418cb692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nSelf-ask is a method of prompting for one or few-shot answers to questions. It requires an initial question to be answered, and the data and code for self-ask is available on GitHub.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db.save_local(\"pdf_index\")"
      ],
      "metadata": {
        "id": "QG-W19tKuxF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_db = FAISS.load_local(\"pdf_index\", \n",
        "                          OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "dbgZqgsPvtXu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_db.add_documents()"
      ],
      "metadata": {
        "id": "M9seY3_KYtGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_obj = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
        "                                     chain_type=\"stuff\", \n",
        "                                     retriever=new_db.as_retriever())"
      ],
      "metadata": {
        "id": "Y3OtQBbZu_wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is self-ask?\""
      ],
      "metadata": {
        "id": "Ov1Fjj7bzZlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_obj.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "lI99BqJYu_tA",
        "outputId": "02585d4e-ac4e-49c5-9ff5-a45e15d31522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSelf-ask is a technique for answering questions that requires a one- or few-shot prompt to demonstrate how to answer the initial question. It uses structured prompting to facilitate this process.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_obj.run(\"What is Langchain?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "FjGRl99Ju_l0",
        "outputId": "2a2819ba-5286-47dc-e756-969b4623f341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Langchain is a tool designed to assist in the evaluation of end-to-end examples like Chat-LangChain. It provides prompts and chains to help with the evaluation process and can be installed using the pip install command.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}