{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgXVhqWSFg3z"
      },
      "outputs": [],
      "source": [
        "!pip install langchain google-cloud-aiplatform google-auth > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/generativeaitrial-trialLC.json'"
      ],
      "metadata": {
        "id": "F-ccpWCvLcUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import VertexAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatVertexAI\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "yBShLql7LcPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = VertexAI(temperature=0.7)"
      ],
      "metadata": {
        "id": "gF5_romzVEbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatLLM = ChatVertexAI(temperature=0.7)"
      ],
      "metadata": {
        "id": "MB7kqXoIVOom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(system_prompt, \n",
        "                      user_prompt,model=chatLLM):\n",
        "    messages = []\n",
        "    messages.append(SystemMessage(content=system_prompt))\n",
        "    messages.append(HumanMessage(content=user_prompt))\n",
        "\n",
        "    # Send the API request\n",
        "    response = model(messages)\n",
        "\n",
        "    # Get the reply from the API response\n",
        "    return response"
      ],
      "metadata": {
        "id": "BGHXK1hqF41-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_file(filename, \n",
        "                  model=chatLLM, \n",
        "                  filepaths_string=None, \n",
        "                  shared_dependencies=None, \n",
        "                  prompt=None):\n",
        "    \n",
        "    filecode = generate_response(model, \n",
        "        f\"\"\"You are an AI developer who is trying to write a program that will generate code for the user based on their intent.\n",
        "        \n",
        "    the app is: {prompt}\n",
        "\n",
        "    the files we have decided to generate are: {filepaths_string}\n",
        "\n",
        "    the shared dependencies (like filenames and variable names) we have decided on are: {shared_dependencies}\n",
        "    \n",
        "    only write valid code for the given filepath and file type, and return only the code.\n",
        "    do not add any other explanation, only return valid code for that file type.\n",
        "    \"\"\",\n",
        "        f\"\"\"\n",
        "    We have broken up the program into per-file generation. \n",
        "    Now your job is to generate only the code for the file {filename}. \n",
        "    Make sure to have consistent filenames if you reference other files we are also generating.\n",
        "    \n",
        "    Remember that you must obey 3 things: \n",
        "       - you are generating code for the file {filename}\n",
        "       - do not stray from the names of the files and the shared dependencies we have decided on\n",
        "       - MOST IMPORTANT OF ALL - the purpose of our app is {prompt} - every line of code you generate must be valid code. Do not include code fences in your response, for example\n",
        "    \n",
        "    Bad response:\n",
        "    ```python \n",
        "    print(\"hello world\")\n",
        "    ```\n",
        "    \n",
        "    Good response:\n",
        "    print(\"hello world\")\n",
        "    \n",
        "    Begin generating the code now.\n",
        "\n",
        "    \"\"\",\n",
        "    )\n",
        "\n",
        "    return filename, filecode"
      ],
      "metadata": {
        "id": "oW6wt3Z8Fk61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt =\"\"\"A Python script that creates GUI which has text boxes that accepts the \n",
        "name of the item purchased, and the quantity. \n",
        "- When submit button is then it calculates the \n",
        "total cost based on the price of the item. Locate the submit button at the bottom of the gui. \n",
        "- Write the code to connect with the price database to get the price of the item that is purchased.\n",
        "- GUI also has button to create invoice copy based on the item, quantity purchased and price. \n",
        "- Then there is a close button, which ask where invoice copy is required by creating a popup. \n",
        "After getting the user input, either closes or prints the invoice and then closes.\n",
        "Important Details:\n",
        "- Code has to run in a gui environment\n",
        "- Write the test code for checking if the cost calculation and the \n",
        "invoice is generated correctly.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "v44N4Rr5Zzfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_file(filename, filecode, directory):\n",
        "    # Output the filename in blue color\n",
        "    print(\"\\033[94m\" + filename + \"\\033[0m\")\n",
        "    print(filecode)\n",
        "    \n",
        "    file_path = os.path.join(directory, filename)\n",
        "    dir = os.path.dirname(file_path)\n",
        "\n",
        "    # Check if the filename is actually a directory\n",
        "    if os.path.isdir(file_path):\n",
        "        print(f\"Error: {filename} is a directory, not a file.\")\n",
        "        return\n",
        "\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "    # Open the file in write mode\n",
        "    with open(file_path, \"w\") as file:\n",
        "        # Write content to the file\n",
        "        file.write(filecode)"
      ],
      "metadata": {
        "id": "VHrOhZI2a6AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_dir(directory):\n",
        "    # Check if the directory exists\n",
        "    if os.path.exists(directory):\n",
        "        # If it does, iterate over all files and directories\n",
        "        for dirpath, _, filenames in os.walk(directory):\n",
        "            for filename in filenames:\n",
        "              os.remove(os.path.join(dirpath, filename))\n",
        "    else:\n",
        "        os.makedirs(directory, exist_ok=True)"
      ],
      "metadata": {
        "id": "C_mW3fA_vDsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths_string = generate_response(system_prompt=\"\"\"You are an AI developer who is trying to write a program that will generate code for the user based on their intent.\n",
        "        \n",
        "    When given their intent, create a complete, exhaustive list of filepaths that the user would write to make the program.\n",
        "    \n",
        "    only list the filepaths you would write, and return them as a python list of strings. \n",
        "    do not add any other explanation, only return a python list of strings.\n",
        "    \"\"\",user_prompt = prompt,model=chatLLM\n",
        "    )"
      ],
      "metadata": {
        "id": "R5qjOrbHFk_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths_string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_C15i91FlEn",
        "outputId": "6238078b-7917-4d89-c178-e5e7f94cc9aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Here is a Python script that creates a GUI with text boxes that accept the name of the item purchased, and the quantity. When the submit button is clicked, it calculates the total cost based on the price of the item. The code to connect with the price database to get the price of the item that is purchased is also written. The GUI also has a button to create an invoice copy based on the item, quantity purchased, and price. Then there is a close button, which asks where the invoice copy is required by creating a popup. After getting the user input, either closes or prints the invoice and then closes.\\n\\n```', additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast \n",
        "\n",
        "example_reply = \"\"\"[\n",
        "\"main.py\",\n",
        "\"gui.py\",\n",
        "\"database.py\",\n",
        "\"invoice.py\"\n",
        "]\"\"\"\n",
        "\n",
        "ast.literal_eval(example_reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lfeHUNFv6rz",
        "outputId": "89e3e4fb-10c2-4bce-fb18-3fdb46753484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['main.py', 'gui.py', 'database.py', 'invoice.py']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "default_dir = 'generated'\n",
        "file = None\n",
        "\n",
        "list_actual = []\n",
        "\n",
        "try:\n",
        "    list_actual = ast.literal_eval(filepaths_string)\n",
        "\n",
        "    # if shared_dependencies.md is there, read it in, else set it to None\n",
        "    shared_dependencies = None\n",
        "    if os.path.exists(\"shared_dependencies.md\"):\n",
        "        with open(\"shared_dependencies.md\", \"r\") as shared_dependencies_file:\n",
        "            shared_dependencies = shared_dependencies_file.read()\n",
        "\n",
        "    if file is not None:\n",
        "        # check file\n",
        "        print(\"file\", file)\n",
        "        filename, filecode = generate_file(file, \n",
        "                                           model=chatLLM, \n",
        "                                           filepaths_string=filepaths_string, shared_dependencies=shared_dependencies, prompt=prompt)\n",
        "        write_file(filename, filecode, default_dir)\n",
        "    else:\n",
        "        clean_dir(default_dir)\n",
        "\n",
        "        # understand shared dependencies\n",
        "        shared_dependencies = generate_response.call(model, \n",
        "            \"\"\"You are an AI developer who is trying to write a program that will generate code for the user based on their intent.\n",
        "            \n",
        "        In response to the user's prompt:\n",
        "\n",
        "        ---\n",
        "        the app is: {prompt}\n",
        "        ---\n",
        "        \n",
        "        the files we have decided to generate are: {filepaths_string}\n",
        "\n",
        "        Now that we have a list of files, we need to understand what dependencies they share.\n",
        "        Please name and briefly describe what is shared between the files we are generating, including exported variables, data schemas, id names of every DOM elements that javascript functions will use, message names, and function names.\n",
        "        Exclusively focus on the names of the shared dependencies, and do not add any other explanation.\n",
        "        \"\"\",\n",
        "            prompt,\n",
        "        )\n",
        "        print(shared_dependencies)"
      ],
      "metadata": {
        "id": "BoFTtUGiFlJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b7s5_hIwFlOL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}