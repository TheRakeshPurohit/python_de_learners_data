{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VUJDi1ZCKoXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eb30d34-e9ad-46fe-9084-e57acc952aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain lark chromadb pypdf google-cloud-aiplatform google-auth > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many PDFs and papers in below location, which will be used for embedding and further querying it.\n",
        "\n",
        "https://github.com/insightbuilder/python_de_learners_data/tree/main/resources"
      ],
      "metadata": {
        "id": "je0FdYFfOrry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the documents from langchain resources folder\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def load_pdf(path_pdf):\n",
        "  get_text = PyPDFLoader(path_pdf)\n",
        "  \n",
        "  get_pages = get_text.load()\n",
        "\n",
        "  final_text = []\n",
        "\n",
        "  shredder = RecursiveCharacterTextSplitter(chunk_size=350,\n",
        "                                            chunk_overlap=20,\n",
        "                                            length_function=len) \n",
        "  \n",
        "  final_shred = shredder.split_documents(get_pages)\n",
        "\n",
        "  return final_shred\n"
      ],
      "metadata": {
        "id": "5T1CYdRWLdSQ"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Just to test the function\n",
        "agent_pg = load_pdf(\"/content/Agents.pdf\")"
      ],
      "metadata": {
        "id": "B6GJHVuDXEtQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_pg[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsuoROkX_dyA",
        "outputId": "75ad3335-8253-4c1d-dd5f-a15b15210f69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='5/31/23, 6:16 AM Agents — \\x00\\x00 LangChain 0.0.186\\nhttps://python.langchain.com/en/stable/modules/agents.html 1/3Agents\\nContents\\nAction Agents', metadata={'source': '/content/Agents.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "file_list = glob.glob(\"/content/*.pdf\")\n",
        "all_docs = []\n",
        "for file in file_list:\n",
        "  temp_docs = load_pdf(file)\n",
        "  all_docs.extend(temp_docs)"
      ],
      "metadata": {
        "id": "XwqBB1lXW1uU"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_docs)"
      ],
      "metadata": {
        "id": "XseMT6DpLdHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cea72e0-0dd0-4c86-def3-43a02627217e"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS']=\"/content/generativeaitrial-trialLC.json\""
      ],
      "metadata": {
        "id": "WaoiXQ3CLdDS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "embeddings = VertexAIEmbeddings()"
      ],
      "metadata": {
        "id": "W3JflMRE-ZkZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = ''"
      ],
      "metadata": {
        "id": "JNShfhh0YCtE"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = 'lc_documentdb'\n",
        "vectordb = Chroma.from_documents(documents=all_docs,\n",
        "                  persist_directory=persist_directory, \n",
        "                  embedding=embeddings)"
      ],
      "metadata": {
        "id": "SsSIC2GVBikK"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.persist()"
      ],
      "metadata": {
        "id": "j2a9WmIDMzj2"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma(persist_directory=persist_directory, \n",
        "                  embedding_function=embeddings)"
      ],
      "metadata": {
        "id": "hQ_vihLyOPhY"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vectordb.add_documents(all_docs[351:407])"
      ],
      "metadata": {
        "id": "6tPBjSzwOltt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vectordb.persist()"
      ],
      "metadata": {
        "id": "_f6t6TLWQqh2"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_retriever = vectordb.as_retriever()\n",
        "db_retriever.get_relevant_documents(\"langchain concepts\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-VZGuDOB6D3",
        "outputId": "5f8da44c-fae1-49b7-dc8d-f1cdde984077"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='5/31/23, 6:13 AM Concepts — \\x00\\x00 LangChain 0.0.186\\nhttps://python.langchain.com/en/stable/getting_started/concepts.html 1/3Concepts\\nContents\\nChain of Thought\\nAction Plan Generation\\nReAct\\nSelf-ask\\nPrompt Chaining\\nMemetic Proxy\\nSelf Consistency\\nInception\\nMemPrompt\\nThese are concepts and terminology commonly used when developing LLM applications. It', metadata={'source': '/content/Concepts.pdf', 'page': 0}),\n",
              " Document(page_content='This is the Python specific portion of the documentation. For a purely conceptual guide to\\nLangChain, see here. For the JavaScript documentation, see here.\\nGetting Started\\nHow to get started using LangChain to create an Language Model application.\\nQuickstart Guide\\nConcepts and terminology .\\nConcepts and terminology', metadata={'source': '/content/WelcometoLangChain.pdf', 'page': 0}),\n",
              " Document(page_content='contains reference to external papers or sources where the concept was first introduced, as\\nwell as to places in LangChain where the concept is used.\\nChain of Thought\\nChain of Thought (CoT)  is a prompting technique used to encourage the model to generate', metadata={'source': '/content/Concepts.pdf', 'page': 0}),\n",
              " Document(page_content='Chains: Combine LLMs and prompts in multi-\\nstep workflows\\nUp until now , we’ve worked with the PromptT emplate and LLM primitives by themselves. But of\\ncourse, a real application is not just one primitive, but rather a combination of them.\\nA chain in LangChain is made up of links, which can be either primitives like LLMs or other\\nchains.', metadata={'source': '/content/QuickstartGuide.pdf', 'page': 3})]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r lc_documentdb.zip /content/lc_documentdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8TdwRc3Cdte",
        "outputId": "c089ce06-46ba-40a7-d24f-646e70b82359"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/lc_documentdb/ (stored 0%)\n",
            "  adding: content/lc_documentdb/chroma-embeddings.parquet (deflated 19%)\n",
            "  adding: content/lc_documentdb/index/ (stored 0%)\n",
            "  adding: content/lc_documentdb/index/uuid_to_id_b973adbd-91f7-4c95-b071-c5aabdbd5ab7.pkl (deflated 39%)\n",
            "  adding: content/lc_documentdb/index/id_to_uuid_b973adbd-91f7-4c95-b071-c5aabdbd5ab7.pkl (deflated 34%)\n",
            "  adding: content/lc_documentdb/index/index_b973adbd-91f7-4c95-b071-c5aabdbd5ab7.bin (deflated 10%)\n",
            "  adding: content/lc_documentdb/index/index_metadata_b973adbd-91f7-4c95-b071-c5aabdbd5ab7.pkl (deflated 14%)\n",
            "  adding: content/lc_documentdb/chroma-collections.parquet (deflated 50%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "\n",
        "metadata_field_info=[\n",
        "    AttributeInfo(\n",
        "        name=\"source\",\n",
        "        description=\"Filename and location of the source file\", \n",
        "        type=\"string\", \n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"page\",\n",
        "        description=\"Page number on which the document is found\", \n",
        "        type=\"integer\", \n",
        "    )\n",
        "]\n",
        "document_content_description = \"Text documents from Langchain help and concept documentation\""
      ],
      "metadata": {
        "id": "WeTn-3gcCohs"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import VertexAI\n",
        "\n",
        "llm = VertexAI(temperature=0)\n",
        "\n",
        "retriever = SelfQueryRetriever.from_llm(llm, \n",
        "                                        vectordb, \n",
        "                                        document_content_description, \n",
        "                                        metadata_field_info, \n",
        "                                        verbose=True,\n",
        "                                        )"
      ],
      "metadata": {
        "id": "qhGnYotMCvl_"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.get_relevant_documents(\"What are some concepts of Agents\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjXWO8lbF3-o",
        "outputId": "fffa5ae8-5a78-4b94-855e-26bd4acb0a29"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query='Agents' filter=None limit=None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='1. “Action Agents”: these agents decide an action to take and take that action one step at a\\ntime\\n2. “Plan-and-Execute Agents”: these agents first decide a plan of actions to take, and then\\nexecute those actions one at a time.\\nWhen should you use each one? Action Agents are more conventional, and good for small', metadata={'source': '/content/Agents.pdf', 'page': 0}),\n",
              " Document(page_content='Chains : Chains are structured sequences of calls (to an LLM or to a dif ferent utility).\\nAgents : An agent is a Chain in which an LLM, given a high-level directive and a set of\\ntools, repeatedly decides an action, executes the action and observes the outcome until\\nthe high-level directive is complete.', metadata={'source': '/content/WelcometoLangChain.pdf', 'page': 1}),\n",
              " Document(page_content='5/31/23, 6:16 AM Agents — \\x00\\x00 LangChain 0.0.186\\nhttps://python.langchain.com/en/stable/modules/agents.html 1/3Agents\\nContents\\nAction Agents\\nPlan-and-Execute Agents\\nConceptual Guide\\nSome applications will require not just a predetermined chain of calls to LLMs/other tools, but', metadata={'source': '/content/Agents.pdf', 'page': 0}),\n",
              " Document(page_content='cover how to modify and create your own agents.\\nToolkits\\nIn this section we go over the various toolkits that LangChain supports out of the box, and how\\nto create an agent from them.\\nAgent Executor\\nIn this section we go over the Agent Executor class, which is responsible for calling the agent', metadata={'source': '/content/Agents.pdf', 'page': 2})]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = SelfQueryRetriever.from_llm(llm, \n",
        "                                        vectordb, \n",
        "                                        document_content_description, \n",
        "                                        metadata_field_info, \n",
        "                                        verbose=True,\n",
        "                                        enable_limit=True)"
      ],
      "metadata": {
        "id": "6HkXINt4-ZhG"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.get_relevant_documents(\"Explain 3 concepts of Chains\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKCFoI-gGh3-",
        "outputId": "59e0ab2a-82e9-4193-8f3a-517a1ce61b7a"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query='explain 3 concepts of chains' filter=None limit=3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='but understanding how it works will set you up well for working with more complex chains.\\nFor more details, check out the getting started guide for chains.\\nAgents: Dynamically Call Chains Based on\\nUser Input\\nSo far the chains we’ve looked at run in a predetermined order .', metadata={'source': '/content/QuickstartGuide.pdf', 'page': 4}),\n",
              " Document(page_content='Chains: Combine LLMs and prompts in multi-\\nstep workflows\\nUp until now , we’ve worked with the PromptT emplate and LLM primitives by themselves. But of\\ncourse, a real application is not just one primitive, but rather a combination of them.\\nA chain in LangChain is made up of links, which can be either primitives like LLMs or other\\nchains.', metadata={'source': '/content/QuickstartGuide.pdf', 'page': 3}),\n",
              " Document(page_content='5/31/23, 6:13 AM Concepts — \\x00\\x00 LangChain 0.0.186\\nhttps://python.langchain.com/en/stable/getting_started/concepts.html 1/3Concepts\\nContents\\nChain of Thought\\nAction Plan Generation\\nReAct\\nSelf-ask\\nPrompt Chaining\\nMemetic Proxy\\nSelf Consistency\\nInception\\nMemPrompt\\nThese are concepts and terminology commonly used when developing LLM applications. It', metadata={'source': '/content/Concepts.pdf', 'page': 0})]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.get_relevant_documents(\"Give 2 example of autonomous agent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMFurIYUJsKw",
        "outputId": "aa5238e7-4019-46b3-956d-997b8d2f866a"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query='autonomous agent' filter=None limit=2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='The most important abstraction of the four above to understand is that of the agent. Although\\nan agent can be defined in whatever way one chooses, the typical way to construct an agent is\\nwith:\\nPromptT emplate: this is responsible for taking the user input and previous steps and\\nconstructing a prompt to send to the language model', metadata={'source': '/content/Agents.pdf', 'page': 1}),\n",
              " Document(page_content='potentially an unknown chain that depends on the user ’s input. In these types of chains, there\\nis a “agent” which has access to a suite of tools. Depending on the user input, the agent can\\nthen decide which, if any , of these tools to call.\\nAt the moment, there are two main types of agents:', metadata={'source': '/content/Agents.pdf', 'page': 0})]"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(llm, \n",
        "                                                    chain_type=\"stuff\", \n",
        "                                                    retriever=retriever)"
      ],
      "metadata": {
        "id": "O58NHGIYJsIU"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain({\"question\":\"Give 2 types of agents\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezn7ONilJr8D",
        "outputId": "d5f35f7e-cf99-42ae-eb6d-b1ddb9800039"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query='types of agents' filter=None limit=2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Give 2 types of agents',\n",
              " 'answer': '1. “Action Agents”: these agents decide an action to take and take that action one step at a\\ntime\\n2. “Plan-and-Execute Agents”: these agents first decide a plan of actions to take, and then\\nexecute those actions one at a time.\\n',\n",
              " 'sources': '/content/Agents.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain({\"question\":\"Give 2 examples of agents\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0l2A5GUar6I",
        "outputId": "55c68cbb-3359-49dd-e677-c512bb48dbaf"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query='agent' filter=None limit=2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Give 2 examples of agents',\n",
              " 'answer': 'The two main types of agents are:\\n1. Sequential agent\\n2. Random agent\\n',\n",
              " 'sources': '/content/Agents.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain({\"question\":\"How to combine LLMs\"},\n",
        "      return_only_outputs=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW0qwa2G-ZVL",
        "outputId": "72b6d720-fccc-414d-94cd-3f35eaad66e4"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query='combine LLMs' filter=None limit=None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'How to combine LLMs',\n",
              " 'answer': 'To combine LLMs, you can use the LangChain library. A chain in LangChain is made up of links, which can be either primitives like LLMs or other chains.\\n',\n",
              " 'sources': '/content/QuickstartGuide.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain({\"question\":\"Provide 2 examples of combining LLMs\"},\n",
        "      return_only_outputs=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AebHsF1oWgU2",
        "outputId": "d68a6296-f4dc-481a-a371-208511d0ca20"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query='combine LLMs' filter=None limit=2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Provide 2 examples of combining LLMs',\n",
              " 'answer': 'Prompt Chaining and Memetic Proxy\\n',\n",
              " 'sources': '/content/Concepts.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain({\"question\":\"4 Concepts in langchain\"},\n",
        "      return_only_outputs=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmgtiqA-WgO-",
        "outputId": "f3415fd8-ad80-4c3f-b5c3-403b1599eb2b"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query='4 Concepts in langchain' filter=None limit=4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': '4 Concepts in langchain',\n",
              " 'answer': 'Chain of Thought, Action Plan Generation, ReAct, Self-ask\\n',\n",
              " 'sources': '/content/Concepts.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain({\"question\":\"Explain consistency in langchain.\"},\n",
        "      return_only_outputs=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E1udSMIXuNh",
        "outputId": "a5abc2cd-39cd-4533-925a-60f033834b86"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query='explain consistency in langchain' filter=None limit=None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Explain consistency in langchain.',\n",
              " 'answer': 'Self Consistency is a decoding strategy that samples a diverse set of reasoning paths and then selects the most consistent answer. Is most effective when combined with Chain-of-thought prompting.\\n',\n",
              " 'sources': '/content/Concepts.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    }
  ]
}